{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W261 Final Project\n",
    "\n",
    "### By Alexander Herring, Jayanth Srinivasa, and Saurav Datta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Question Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final project we seek to perform Click Through Rate (CTR) prediction on a large public dataset of Criteo advertising data.  This data was made available as part of a Kaggle competition several years ago.  CTR is an important and commonly used metric in Internet marketing.  It measures the number of clicks advertisers receive on their ads per number of impressions ((Total Clicks on Ad) / (Total Impressions) = Click Through Rate).  In simple terms, a  high CTR means that a high percentage of people who see an ad click on it.  Thus, ads with a high CTR can be thought of as high performing, and the companies serving these ads can charge more for them.\n",
    "\n",
    "The winner of the Criteo Kaggle competition achieved a log-loss score of 0.445.  With 718 competition entries, all entries performing above the 90th percentile achieved a log-loss score of 0.46 or less.  While reaching a score this low would be ideal, our model could still be practically useful (especially if it was applied to other datasets) with a slightly higher log-loss score, such as around 0.50.\n",
    "\n",
    "In pursuit of our ultimate goal of performing CTR prediction on a public dataset of Criteo advertising data, we will perform an exploratory data analysis (EDA), and from this EDA determine if binary logistic regression is an appropriate algorithm to use for CTR prediction.  This will include thoroughly testing its assumptions.  If we determine it is appropriate, we will then apply binary logistic regression to a toy example (an artificial example) to test our general algorithm implementation before applying the same algorithm to a full test and train split.  Our target variable will take a binary value (0 or 1) corresponding whether or not a display ad served was clicked.  We will seek to optimize our implementation of the algorithm to achieve a log-loss score of 0.50 or lower.\n",
    "\n",
    "As we will explain in more detail in the sections that follow, one limitation of the dataset includes the fact that many of the columns in it are categorical in nature.  To be able to use them with binary logistic regression, which only accepts numerical values, we will have to use a process known as one-hot encoding (OHE) to turn the values in each of the categorical columns into indicator variable.  If we do not do this, we will be unable to use the columns, which would likely lower the predictive power of our model.  We will also go into more depth on other technique used to implement our chosen algrorithm on the toy and Criteo datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installation of necessary packages\n",
    "\n",
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade pandas\n",
    "# !pip install --upgrade google-api-python-client\n",
    "# !pip install --upgrade seaborn\n",
    "# !pip install --upgrade networkx\n",
    "# !pip install --upgrade matplotlib\n",
    "# !pip install --upgrade pyspark\n",
    "# !pip install --upgrade pyspark_dist_explore\n",
    "# !pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Main Imports\n",
    "\n",
    "from IPython.display import display, HTML, display_html #usefull to display wide tables\n",
    "from pyspark_dist_explore import Histogram, hist, distplot, pandas_histogram\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "#from pyspark.mllib.linalg import VectorUDT\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.sql import functions as F, types\n",
    "from pyspark.sql.functions import (explode, col)\n",
    "from pyspark.sql.functions import col, row_number, concat, lit\n",
    "from pyspark.sql.functions import trim\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, LongType, StringType\n",
    "from pyspark.sql.types import Row\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "import ast\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import seaborn as sns\n",
    "import time\n",
    "import statsmodels.formula.api as smf\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To better display plots from matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://w266finalprojectajh6-m.c.w266-203601.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3d50db6e10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Spark Session - ensure that kernel is PySpark and not Python 2 or Python 3\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Spark Context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) EDA & Discussion of Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin modeling an alogrithm for Click Through Rate prediction, we should first examine the Criteo dataset that we will be using.  To do this, we will examine the initial format and structure of the dataset, the size of the dataset, examine it for missing values and outliers, and capture several summary statistics that will inform us of the distribution of the dataset.  To aid in our analysis, we will plot several graphs that will augment our understanding of the distribution of the dataset.\n",
    "\n",
    "Furthermore, as mentioned in our question formulation, we would like to use binary logistic regression as the main algorithm in our Click Through Rate prediction.  However, logistic regression models have several assumptions that must be met before they can be used.\n",
    "\n",
    "The assumptions for logistic regression include:\n",
    "\n",
    "1)  The outcome is a binary or dichotomous variable (e.g. “yes” or “no”, “positive” or “negative”, 1 or 0).\n",
    "\n",
    "2)  There is a linear relationship between the logit of the outcome and each predictor variables.  The logit function is $logit(p) = log(p/(1-p))$, where p is the probability of the outcome.\n",
    "\n",
    "3) Independence of observations.\n",
    "\n",
    "4) There is no multicollinearity among the independent variables.\n",
    "\n",
    "5) There are a large number of observations.\n",
    "\n",
    "Before completing the EDA, we know in advance that the data meets two of the conditions needed for logistic regression.  The target variable of whether or not ad is clicked is binary as it is either a 0 or 1.  Additionally, though it is not explicitly stated, we can assume independence of observations.  Each row in the dataset corresponds to a separately presented display ad, thus making the assumption of independence reasonable.\n",
    "\n",
    "In the EDA that follows, we will show how the Criteo dataset meets the remaining assumptions necessary for logistic regression, thus allowing us to comfortably use it as our prediction algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) The Dataset is Large and Needs to be Parsed\n",
    "\n",
    "After loading the data and performing a row count, we can observe that the Criteo dataset is quite large.  It contains 45,840,617 rows (display ads served).  Thus, the assumption needed for logistic regression of using a large number of observations has been met.\n",
    "\n",
    "Additionally, we can observe that each row in the dataset is initally a single, long string with tab-delimited columns.  These will need to be parsed before any further analysis can be performed.  We wrote code that performs this task, and separates all of these columns into numerical values or strings as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45840617\n"
     ]
    }
   ],
   "source": [
    "rawDF = sqlContext.read.text('gs://w261_final_project_ajh_bucket/data/train.txt').withColumnRenamed(\"value\", \"text\")\n",
    "rawDF.cache()\n",
    "rawDF_count = rawDF.count()\n",
    "print(rawDF_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(text='0\\t1\\t1\\t5\\t0\\t1382\\t4\\t15\\t2\\t181\\t1\\t2\\t\\t2\\t68fd1e64\\t80e26c9b\\tfb936136\\t7b4723c4\\t25c83c98\\t7e0ccccf\\tde7995b8\\t1f89b562\\ta73ee510\\ta8cd5504\\tb2cb9c98\\t37c9c164\\t2824a5f6\\t1adce6ef\\t8ba8b39a\\t891b62e7\\te5ba7672\\tf54016b9\\t21ddcdc9\\tb1252a9d\\t07b5194c\\t\\t3a171ecb\\tc5c50484\\te8b83407\\t9727dd16')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDF.printSchema()\n",
    "rawDF.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text: string]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullWithColsDF = rawDF.withColumn('tmp', split('text', '\\t')).\\\n",
    "                    select( col(\"tmp\").getItem(0).cast(\"double\").alias(\"label\")\n",
    "                    , col(\"tmp\").getItem(1).cast(\"double\").alias(\"int_1\")\n",
    "                    , col(\"tmp\").getItem(2).cast(\"double\").alias(\"int_2\")\n",
    "                    , col(\"tmp\").getItem(3).cast(\"double\").alias(\"int_3\")\n",
    "                    , col(\"tmp\").getItem(4).cast(\"double\").alias(\"int_4\")\n",
    "                    , col(\"tmp\").getItem(5).cast(\"double\").alias(\"int_5\")\n",
    "                    , col(\"tmp\").getItem(6).cast(\"double\").alias(\"int_6\")\n",
    "                    , col(\"tmp\").getItem(7).cast(\"double\").alias(\"int_7\")\n",
    "                    , col(\"tmp\").getItem(8).cast(\"double\").alias(\"int_8\")\n",
    "                    , col(\"tmp\").getItem(9).cast(\"double\").alias(\"int_9\")\n",
    "                    , col(\"tmp\").getItem(10).cast(\"double\").alias(\"int_10\")\n",
    "                    , col(\"tmp\").getItem(11).cast(\"double\").alias(\"int_11\")\n",
    "                    , col(\"tmp\").getItem(12).cast(\"double\").alias(\"int_12\")\n",
    "                    , col(\"tmp\").getItem(13).cast(\"double\").alias(\"int_13\")\n",
    "                    , col(\"tmp\").getItem(14).alias(\"categ_1\")\n",
    "                    , col(\"tmp\").getItem(15).alias(\"categ_2\")\n",
    "                    , col(\"tmp\").getItem(16).alias(\"categ_3\")\n",
    "                    , col(\"tmp\").getItem(17).alias(\"categ_4\")\n",
    "                    , col(\"tmp\").getItem(18).alias(\"categ_5\")\n",
    "                    , col(\"tmp\").getItem(19).alias(\"categ_6\")\n",
    "                    , col(\"tmp\").getItem(20).alias(\"categ_7\")\n",
    "                    , col(\"tmp\").getItem(21).alias(\"categ_8\")\n",
    "                    , col(\"tmp\").getItem(22).alias(\"categ_9\")\n",
    "                    , col(\"tmp\").getItem(23).alias(\"categ_10\")\n",
    "                    , col(\"tmp\").getItem(24).alias(\"categ_11\")\n",
    "                    , col(\"tmp\").getItem(25).alias(\"categ_12\")\n",
    "                    , col(\"tmp\").getItem(26).alias(\"categ_13\")\n",
    "                    , col(\"tmp\").getItem(27).alias(\"categ_14\")\n",
    "                    , col(\"tmp\").getItem(28).alias(\"categ_15\")\n",
    "                    , col(\"tmp\").getItem(29).alias(\"categ_16\")\n",
    "                    , col(\"tmp\").getItem(30).alias(\"categ_17\")\n",
    "                    , col(\"tmp\").getItem(31).alias(\"categ_18\")\n",
    "                    , col(\"tmp\").getItem(32).alias(\"categ_19\")\n",
    "                    , col(\"tmp\").getItem(33).alias(\"categ_20\")\n",
    "                    , col(\"tmp\").getItem(34).alias(\"categ_21\")\n",
    "                    , col(\"tmp\").getItem(35).alias(\"categ_22\")\n",
    "                    , col(\"tmp\").getItem(36).alias(\"categ_23\")\n",
    "                    , col(\"tmp\").getItem(37).alias(\"categ_24\")\n",
    "                    , col(\"tmp\").getItem(38).alias(\"categ_25\")\n",
    "                    , col(\"tmp\").getItem(39).alias(\"categ_26\")\n",
    "                    ).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2) 13 Numerical Columns, 26 Categorical Columns\n",
    "\n",
    "After parsing our data and separating the columns, we can see that there are 13 numerical columns and 26 categorical columns.  The numerical columns appear to be all integer values, while the categorical columns appear to be hash values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, int_1=1.0, int_2=1.0, int_3=5.0, int_4=0.0, int_5=1382.0, int_6=4.0, int_7=15.0, int_8=2.0, int_9=181.0, int_10=1.0, int_11=2.0, int_12=None, int_13=2.0, categ_1='68fd1e64', categ_2='80e26c9b', categ_3='fb936136', categ_4='7b4723c4', categ_5='25c83c98', categ_6='7e0ccccf', categ_7='de7995b8', categ_8='1f89b562', categ_9='a73ee510', categ_10='a8cd5504', categ_11='b2cb9c98', categ_12='37c9c164', categ_13='2824a5f6', categ_14='1adce6ef', categ_15='8ba8b39a', categ_16='891b62e7', categ_17='e5ba7672', categ_18='f54016b9', categ_19='21ddcdc9', categ_20='b1252a9d', categ_21='07b5194c', categ_22='', categ_23='3a171ecb', categ_24='c5c50484', categ_25='e8b83407', categ_26='9727dd16')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullWithColsDF.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3) Methods for Calculating Statistics\n",
    "\n",
    "Below are several methods that we use to calculate summary statistics, and perform any necessary transformations.  They include:\n",
    "\n",
    "1) f_calc_stats, which calculates mean, minimum value, maximum value, standard deviation, variance, skewness of a column in a dataframe.\n",
    "\n",
    "2) f_check_null, which calculates count of null or NaN or empty for a column.\n",
    "\n",
    "3) f_display_stats_categ, which calculates count of unique values and empty strings for a column.\n",
    "\n",
    "4) f_display_stats_int, which calls other functions to get mean, minimum value, maximum value, standard deviation, variance, skewness, and number of nulls/NaN/empty values of a column in a dataframe.\n",
    "\n",
    "5) f_display_corr, which calculates the correlation and covariance of a variable against the label.\n",
    "\n",
    "6) f_covert_to_df, which converts an RDD to dataframe.\n",
    "\n",
    "7) f_cast_str_to_int, which converts integer columns formatted as strings to integers.\n",
    "\n",
    "8) f_remove_empty_string, which removes rows where at least one column has empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_calc_stats(data, column):\n",
    "    \"\"\"\n",
    "    Calculates mean, minimum value, maximum value, standard deviation, variance, skewness of a column in a dataframe.\n",
    "    Returns a list containing mean, minimum value, maximum value, standard deviation, variance, skewness\n",
    "    Arguments:\n",
    "        data         - dataframe on which we are calculating statistics.\n",
    "        column       - column for which statistics have to be calculated\n",
    "    Returns:\n",
    "        A list containing the mean, minimum value, maximum value, standard deviation, variance, skewness of the column.\n",
    "    \"\"\"\n",
    "    return data.agg(F.avg(data[column]), F.min(data[column]), F.max(data[column]),\n",
    "                    F.stddev_pop(data[column]),F.var_pop(data[column]),F.skewness(data[column])\n",
    "                   ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_check_null(data, column):\n",
    "    \"\"\"\n",
    "    Calculates count of null or NaN or empty for a column.\n",
    "    Returns an integer for the count  of null or NaN or empty for a column.\n",
    "    Arguments:\n",
    "        data         - dataframe on which we are calculating the metric.\n",
    "        column       - column for which the metric has to be calculated.\n",
    "    Returns:\n",
    "        An integer for the count where the column is null or NaN or empty.\n",
    "    \"\"\"\n",
    "    return data.filter( (data[column] ==\"\") |F.isnull(data[column])|F.isnan(data[column])\n",
    "                      ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking cardinality\n",
    "def f_display_stats_categ(df, inColList):\n",
    "    \"\"\"\n",
    "    Calculates count of unique values and empty strings for a column.\n",
    "    Displays the output as a HTML table.\n",
    "    Arguments:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        inColList  - list of column names for which we are calculating the metrics.\n",
    "    Returns:\n",
    "        Displays the output as a HTML table.\n",
    "    \"\"\"\n",
    "    dict1={}\n",
    "    for col in inColList:\n",
    "        cardinal_cnt = df.select([col]).distinct().count()\n",
    "        dict1[col]={\"Count_Unique_Vals\":cardinal_cnt}\n",
    "        dict1[col]['Count_Empty_String'] = str(df.filter(df[col] == \"\").count())\n",
    "\n",
    "    display(HTML(pd.DataFrame(dict1).T.to_html( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_display_stats_int(data):\n",
    "    \"\"\"\n",
    "    Calls other functions to get mean, minimum value, maximum value, standard deviation, variance, skewness, number of nulls/NaN/empty values of a column in a dataframe..\n",
    "    Displays the output as a HTML table.\n",
    "    Arguments:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        inColList  - list of column names for which we are calculating the metrics.\n",
    "    Returns:\n",
    "        Displays the output as a HTML table.\n",
    "    \"\"\"\n",
    "    dict1={}\n",
    "    countTotal = data.count()\n",
    "    for colname in [item[0] for item in data.dtypes if item[1].startswith('double')]:\n",
    "        list1=f_calc_stats(data,colname)\n",
    "        mean_val, min_val,max_val,stddev,var, skewness =list1[0]\n",
    "        count_nulls = f_check_null(data,colname)\n",
    "        dict1[colname]={}\n",
    "        dict1[colname]['mean'] = str(round(mean_val,2))\n",
    "        dict1[colname]['min'] = str(min_val)\n",
    "        dict1[colname]['max'] = str(max_val)\n",
    "        dict1[colname]['stddev'] = str(round(stddev,2))\n",
    "        dict1[colname]['var'] = str(round(var,2))\n",
    "        dict1[colname]['skewness'] = str(round(skewness,2))\n",
    "        dict1[colname]['nulls_nans'] = str(count_nulls)\n",
    "        dict1[colname]['pct_nulls_nans'] = str(round(float(count_nulls/countTotal*100),2))\n",
    "        dict1[colname]['count_empty_string'] = str(data.filter(data[colname] == \"\").count())\n",
    "        dict1[colname]['count_unique_values'] = str(data.select([colname]).distinct().count())\n",
    "   #Transposing dataframe to keep column names as rows\n",
    "    display(HTML(pd.DataFrame(dict1).T.to_html( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_display_corr(df, int_col_list):\n",
    "    \"\"\"\n",
    "    Calculates the correlation and covariance of a variable against the label\n",
    "    Arguments:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        inColList  - list of numeric column names for which we are calculating covariance and correlation.\n",
    "    Returns:\n",
    "        Displays the correlation and covariance as a HTML table.\n",
    "    \"\"\"\n",
    "    sampleDF=df.sample(seed=1, fraction=0.5, withReplacement=False)\n",
    "    dict1={}\n",
    "    for col in int_col_list:\n",
    "        corr = df.stat.corr('label',col)\n",
    "        cov = df.stat.cov('label',col)\n",
    "        dict1[col]={}\n",
    "        dict1[col][\"Corr\"]=corr\n",
    "        dict1[col][\"Cov\"]=cov\n",
    "    display(HTML(pd.DataFrame(dict1).T.to_html( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dataframe from RDD\n",
    "def f_covert_to_df(rdd, col_list):\n",
    "    \"\"\"\n",
    "    Converts a RDD to dataframe\n",
    "    Arguments:\n",
    "        rdd         - RDD to convert to dataframe.\n",
    "        col_list    - list of columns representing the schema.\n",
    "    Returns:\n",
    "        A dataframe.\n",
    "    \"\"\"\n",
    "    return rdd.map(lambda x: x.split('\\t')).toDF(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert integer columns to IntegerType from String\n",
    "def f_cast_str_to_int(df, integer_col_list):\n",
    "    \"\"\"\n",
    "    Convers integer columns formatted as strings to integers.\n",
    "    Arguments:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        integer_col_list    - list of columns representing the integer columns in the schema.\n",
    "    Returns:\n",
    "        A dataframe.\n",
    "    \"\"\"\n",
    "    for col in integer_col_list:\n",
    "        df = df.withColumn(col, df[col].cast(types.IntegerType()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removes rows where at least one column has empty string\n",
    "def f_remove_empty_string(df, categ_col_list):\n",
    "    \"\"\"\n",
    "    Removes rows where at least one column has empty string\n",
    "    Arguments:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        col_list    - list of columns representing the schema.\n",
    "    Returns:\n",
    "        A dataframe.\n",
    "    \"\"\"\n",
    "    for categ_col in categ_col_list:\n",
    "        df = df.filter(df[categ_col] != \"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4) Summary Statistics\n",
    "\n",
    "Below we generate summary statistics for our full dataset, which again is rather large at 45,840,617 rows / records.\n",
    "\n",
    "#### Numerical Columns\n",
    "\n",
    "For our 13 numerical columns, we can observe that for many of the columns there are a substantial number of null / not-a-number (nan) values.  There are many columns for which this is around 20%, though the number reaches as high  as 76.5% for the column \"int_12\".  It should be noted that for the \"int_1\" column there are no null / nan values.\n",
    "\n",
    "The values in the numerical columns vary greatly in size and often in range.  For example, column int_11 has a mean value of 0.62, while column int_5 has a mean value of 18538.99, and ranges in value from 0 to 23,159,456.0.   This wide range for column int_5 suggests that it may have a number of outliers, which we will explore further graphically.\n",
    "\n",
    "Additionally, our target variable (denoted here as \"label\") shows that on average there is a 26% click-through rate in the Criteo data, which can be seen as the mean of the column given that the column can only take on binary values (0 or 1).  Once again, the fact that the target variable is binary allows the dataset to meet a condition necessary to use logistic regression.\n",
    "\n",
    "Furthermore, some columns, in particular \"int_5\", exhibit very high skewness and variance.  We will explore this further graphically.\n",
    "\n",
    "#### Categorical Columns\n",
    "\n",
    "For our 26 categorical columns, about half of them have no empty string / null values, while the other half contain a large amount.  This reaches as high as 34,955,073 empty string / null values for \"categ_22\".  Interesting is that many of the columns with higher number of unique values also have high numbers of empty string / null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45840617\n"
     ]
    }
   ],
   "source": [
    "print(rawDF_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelColList=[\"label\"]\n",
    "intColList=[\"int_1\", \"int_2\", \"int_3\", \"int_4\", \"int_5\", \"int_6\", \"int_7\"\\\n",
    "            , \"int_8\", \"int_9\", \"int_10\", \"int_11\", \"int_12\", \"int_13\"]\n",
    "categColList=[\"categ_1\", \"categ_2\", \"categ_3\", \"categ_4\", \"categ_5\", \"categ_6\"\\\n",
    "              , \"categ_7\", \"categ_8\", \"categ_9\", \"categ_10\", \"categ_11\", \"categ_12\"\\\n",
    "              , \"categ_13\", \"categ_14\", \"categ_15\", \"categ_16\", \"categ_17\", \"categ_18\"\\\n",
    "              , \"categ_19\", \"categ_20\", \"categ_21\", \"categ_22\", \"categ_23\", \"categ_24\", \"categ_25\", \"categ_26\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for numerical and categorical columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_empty_string</th>\n",
       "      <th>count_unique_values</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>nulls_nans</th>\n",
       "      <th>pct_nulls_nans</th>\n",
       "      <th>skewness</th>\n",
       "      <th>stddev</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_1</th>\n",
       "      <td>0</td>\n",
       "      <td>649</td>\n",
       "      <td>5775.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20793556</td>\n",
       "      <td>45.36</td>\n",
       "      <td>27.88</td>\n",
       "      <td>9.43</td>\n",
       "      <td>88.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_2</th>\n",
       "      <td>0</td>\n",
       "      <td>9364</td>\n",
       "      <td>257675.0</td>\n",
       "      <td>105.85</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>391.46</td>\n",
       "      <td>153239.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_3</th>\n",
       "      <td>0</td>\n",
       "      <td>14746</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>26.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9839447</td>\n",
       "      <td>21.46</td>\n",
       "      <td>81.49</td>\n",
       "      <td>397.97</td>\n",
       "      <td>158382.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_4</th>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>969.0</td>\n",
       "      <td>7.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9937369</td>\n",
       "      <td>21.68</td>\n",
       "      <td>4.09</td>\n",
       "      <td>8.79</td>\n",
       "      <td>77.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_5</th>\n",
       "      <td>0</td>\n",
       "      <td>476707</td>\n",
       "      <td>23159456.0</td>\n",
       "      <td>18538.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1183117</td>\n",
       "      <td>2.58</td>\n",
       "      <td>10.1</td>\n",
       "      <td>69394.6</td>\n",
       "      <td>4815610657.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_6</th>\n",
       "      <td>0</td>\n",
       "      <td>11618</td>\n",
       "      <td>431037.0</td>\n",
       "      <td>116.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10252328</td>\n",
       "      <td>22.37</td>\n",
       "      <td>184.98</td>\n",
       "      <td>382.57</td>\n",
       "      <td>146357.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_7</th>\n",
       "      <td>0</td>\n",
       "      <td>4142</td>\n",
       "      <td>56311.0</td>\n",
       "      <td>16.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982866</td>\n",
       "      <td>4.33</td>\n",
       "      <td>46.39</td>\n",
       "      <td>66.05</td>\n",
       "      <td>4362.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_8</th>\n",
       "      <td>0</td>\n",
       "      <td>1373</td>\n",
       "      <td>6047.0</td>\n",
       "      <td>12.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22773</td>\n",
       "      <td>0.05</td>\n",
       "      <td>66.16</td>\n",
       "      <td>16.69</td>\n",
       "      <td>278.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_9</th>\n",
       "      <td>0</td>\n",
       "      <td>7275</td>\n",
       "      <td>29019.0</td>\n",
       "      <td>106.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982866</td>\n",
       "      <td>4.33</td>\n",
       "      <td>8.52</td>\n",
       "      <td>220.28</td>\n",
       "      <td>48524.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_10</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20793556</td>\n",
       "      <td>45.36</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_11</th>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>231.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982866</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6.04</td>\n",
       "      <td>5.2</td>\n",
       "      <td>27.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_12</th>\n",
       "      <td>0</td>\n",
       "      <td>407</td>\n",
       "      <td>4008.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35071652</td>\n",
       "      <td>76.51</td>\n",
       "      <td>95.26</td>\n",
       "      <td>5.6</td>\n",
       "      <td>31.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_13</th>\n",
       "      <td>0</td>\n",
       "      <td>1376</td>\n",
       "      <td>7393.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9937369</td>\n",
       "      <td>21.68</td>\n",
       "      <td>105.35</td>\n",
       "      <td>16.21</td>\n",
       "      <td>262.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_Empty_String</th>\n",
       "      <th>Count_Unique_Vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categ_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_2</th>\n",
       "      <td>0</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_3</th>\n",
       "      <td>1559473</td>\n",
       "      <td>10131227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_4</th>\n",
       "      <td>1559473</td>\n",
       "      <td>2202608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_5</th>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_6</th>\n",
       "      <td>5540625</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_7</th>\n",
       "      <td>0</td>\n",
       "      <td>12517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_8</th>\n",
       "      <td>0</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_9</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_10</th>\n",
       "      <td>0</td>\n",
       "      <td>93145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_11</th>\n",
       "      <td>0</td>\n",
       "      <td>5683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_12</th>\n",
       "      <td>1559473</td>\n",
       "      <td>8351593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_13</th>\n",
       "      <td>0</td>\n",
       "      <td>3194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_14</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_15</th>\n",
       "      <td>0</td>\n",
       "      <td>14992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_16</th>\n",
       "      <td>1559473</td>\n",
       "      <td>5461306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_17</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_18</th>\n",
       "      <td>0</td>\n",
       "      <td>5652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_19</th>\n",
       "      <td>20172858</td>\n",
       "      <td>2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_20</th>\n",
       "      <td>20172858</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_21</th>\n",
       "      <td>1559473</td>\n",
       "      <td>7046547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_22</th>\n",
       "      <td>34955073</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_23</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_24</th>\n",
       "      <td>1559473</td>\n",
       "      <td>286181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_25</th>\n",
       "      <td>20172858</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_26</th>\n",
       "      <td>20172858</td>\n",
       "      <td>142572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Summary statistics for numerical and categorical columns\")\n",
    "f_display_stats_int(fullWithColsDF)\n",
    "f_display_stats_categ(fullWithColsDF, categColList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5) Lack of Correlation and Lack of Multicollinearity\n",
    "\n",
    "As we can see below, there is at best weak correlation of the numerical columns with the target variable.  Column int_10 has the highest correlation at 0.19, which is still fairly weak.  In terms of negative correlation, the lowest correlation is 0.08 for columns int_5 and int_13, which is also very weak.\n",
    "\n",
    "Furthermore, in the correlation matrix below we can see that there is a lack of notable multicollineraity of the columns with each other.  The majority of the values in the correlation matrix are between 0.20 and 0.30.  There are many values close to 0, though there are a handful of values as high as 0.61 (between int_04 and int_13), and 0.69 (between int_07 and int_11).  While these two columns have the highest risk of multicollinearity, which would potentially bias the data, this correlation is not strong.  We have also presented a correlation matrix heatmap to more easily visualize the covariances.\n",
    "\n",
    "Overall, our dataset can be said to not have multicollinearity, and thus meets this condition for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and Covariance w.r.t target field\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corr</th>\n",
       "      <th>Cov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>int_1</th>\n",
       "      <td>0.104088</td>\n",
       "      <td>0.326463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_2</th>\n",
       "      <td>0.044435</td>\n",
       "      <td>7.593410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_3</th>\n",
       "      <td>0.009770</td>\n",
       "      <td>1.505005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_4</th>\n",
       "      <td>-0.055718</td>\n",
       "      <td>-0.203014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_5</th>\n",
       "      <td>-0.076539</td>\n",
       "      <td>-2290.654047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_6</th>\n",
       "      <td>-0.055812</td>\n",
       "      <td>-8.296949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_7</th>\n",
       "      <td>0.085156</td>\n",
       "      <td>2.404850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_8</th>\n",
       "      <td>-0.027436</td>\n",
       "      <td>-0.199864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_9</th>\n",
       "      <td>0.024072</td>\n",
       "      <td>2.275556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_10</th>\n",
       "      <td>0.191717</td>\n",
       "      <td>0.049527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_11</th>\n",
       "      <td>0.158357</td>\n",
       "      <td>0.353649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_12</th>\n",
       "      <td>0.049629</td>\n",
       "      <td>0.059482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_13</th>\n",
       "      <td>-0.075477</td>\n",
       "      <td>-0.485725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Correlation and Covariance w.r.t target field\")\n",
    "f_display_corr(fullWithColsDF, intColList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select only numerical columns\n",
    "fullWithColsDF_int = fullWithColsDF.select(intColList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlation_df = fullWithColsDF_int.na.fill(0)\n",
    "\n",
    "# Convert to vector column first\n",
    "vector_col = \"corr_features\"\n",
    "assembler = VectorAssembler(inputCols=correlation_df.columns, outputCol=vector_col)\n",
    "df_vector = assembler.transform(correlation_df).select(vector_col)\n",
    "\n",
    "# Get correlation matrix\n",
    "matrix = Correlation.corr(df_vector, vector_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int_01</th>\n",
       "      <th>int_02</th>\n",
       "      <th>int_03</th>\n",
       "      <th>int_04</th>\n",
       "      <th>int_05</th>\n",
       "      <th>int_06</th>\n",
       "      <th>int_07</th>\n",
       "      <th>int_08</th>\n",
       "      <th>int_09</th>\n",
       "      <th>int_10</th>\n",
       "      <th>int_11</th>\n",
       "      <th>int_12</th>\n",
       "      <th>int_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>int_01</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>0.038390</td>\n",
       "      <td>0.081069</td>\n",
       "      <td>-0.068993</td>\n",
       "      <td>-0.058315</td>\n",
       "      <td>0.477780</td>\n",
       "      <td>0.097048</td>\n",
       "      <td>0.068316</td>\n",
       "      <td>0.465176</td>\n",
       "      <td>0.304534</td>\n",
       "      <td>0.092164</td>\n",
       "      <td>0.005279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_02</th>\n",
       "      <td>0.034108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>-0.081530</td>\n",
       "      <td>-0.006260</td>\n",
       "      <td>-0.013320</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>-0.028035</td>\n",
       "      <td>-0.004732</td>\n",
       "      <td>0.035712</td>\n",
       "      <td>0.032760</td>\n",
       "      <td>-0.001294</td>\n",
       "      <td>-0.034543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_03</th>\n",
       "      <td>0.038390</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042022</td>\n",
       "      <td>-0.003412</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.045087</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>0.030109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_04</th>\n",
       "      <td>0.081069</td>\n",
       "      <td>-0.081530</td>\n",
       "      <td>0.042022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.094468</td>\n",
       "      <td>0.015560</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>0.504384</td>\n",
       "      <td>0.194364</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.063999</td>\n",
       "      <td>0.021092</td>\n",
       "      <td>0.612960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_05</th>\n",
       "      <td>-0.068993</td>\n",
       "      <td>-0.006260</td>\n",
       "      <td>-0.003412</td>\n",
       "      <td>-0.094468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>-0.056270</td>\n",
       "      <td>-0.109468</td>\n",
       "      <td>-0.068310</td>\n",
       "      <td>-0.148043</td>\n",
       "      <td>-0.115582</td>\n",
       "      <td>-0.020923</td>\n",
       "      <td>-0.054280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_06</th>\n",
       "      <td>-0.058315</td>\n",
       "      <td>-0.013320</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.015560</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027060</td>\n",
       "      <td>0.022175</td>\n",
       "      <td>0.186576</td>\n",
       "      <td>-0.124605</td>\n",
       "      <td>-0.039072</td>\n",
       "      <td>-0.012915</td>\n",
       "      <td>0.045574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_07</th>\n",
       "      <td>0.477780</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>-0.056270</td>\n",
       "      <td>-0.027060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077122</td>\n",
       "      <td>0.233840</td>\n",
       "      <td>0.251448</td>\n",
       "      <td>0.685523</td>\n",
       "      <td>0.093341</td>\n",
       "      <td>0.003478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_08</th>\n",
       "      <td>0.097048</td>\n",
       "      <td>-0.028035</td>\n",
       "      <td>0.045087</td>\n",
       "      <td>0.504384</td>\n",
       "      <td>-0.109468</td>\n",
       "      <td>0.022175</td>\n",
       "      <td>0.077122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206472</td>\n",
       "      <td>0.156661</td>\n",
       "      <td>0.139375</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>0.631302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_09</th>\n",
       "      <td>0.068316</td>\n",
       "      <td>-0.004732</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>0.194364</td>\n",
       "      <td>-0.068310</td>\n",
       "      <td>0.186576</td>\n",
       "      <td>0.233840</td>\n",
       "      <td>0.206472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075001</td>\n",
       "      <td>0.403943</td>\n",
       "      <td>0.045726</td>\n",
       "      <td>0.192788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_10</th>\n",
       "      <td>0.465176</td>\n",
       "      <td>0.035712</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>-0.148043</td>\n",
       "      <td>-0.124605</td>\n",
       "      <td>0.251448</td>\n",
       "      <td>0.156661</td>\n",
       "      <td>0.075001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.386369</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.023659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_11</th>\n",
       "      <td>0.304534</td>\n",
       "      <td>0.032760</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>0.063999</td>\n",
       "      <td>-0.115582</td>\n",
       "      <td>-0.039072</td>\n",
       "      <td>0.685523</td>\n",
       "      <td>0.139375</td>\n",
       "      <td>0.403943</td>\n",
       "      <td>0.386369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098713</td>\n",
       "      <td>0.010549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_12</th>\n",
       "      <td>0.092164</td>\n",
       "      <td>-0.001294</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>0.021092</td>\n",
       "      <td>-0.020923</td>\n",
       "      <td>-0.012915</td>\n",
       "      <td>0.093341</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>0.045726</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.098713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_13</th>\n",
       "      <td>0.005279</td>\n",
       "      <td>-0.034543</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>0.612960</td>\n",
       "      <td>-0.054280</td>\n",
       "      <td>0.045574</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>0.631302</td>\n",
       "      <td>0.192788</td>\n",
       "      <td>0.023659</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>-0.003453</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          int_01    int_02    int_03    int_04    int_05    int_06    int_07  \\\n",
       "int_01  1.000000  0.034108  0.038390  0.081069 -0.068993 -0.058315  0.477780   \n",
       "int_02  0.034108  1.000000 -0.008308 -0.081530 -0.006260 -0.013320  0.025422   \n",
       "int_03  0.038390 -0.008308  1.000000  0.042022 -0.003412  0.005079  0.000373   \n",
       "int_04  0.081069 -0.081530  0.042022  1.000000 -0.094468  0.015560  0.038521   \n",
       "int_05 -0.068993 -0.006260 -0.003412 -0.094468  1.000000  0.002158 -0.056270   \n",
       "int_06 -0.058315 -0.013320  0.005079  0.015560  0.002158  1.000000 -0.027060   \n",
       "int_07  0.477780  0.025422  0.000373  0.038521 -0.056270 -0.027060  1.000000   \n",
       "int_08  0.097048 -0.028035  0.045087  0.504384 -0.109468  0.022175  0.077122   \n",
       "int_09  0.068316 -0.004732 -0.000465  0.194364 -0.068310  0.186576  0.233840   \n",
       "int_10  0.465176  0.035712 -0.003791  0.157900 -0.148043 -0.124605  0.251448   \n",
       "int_11  0.304534  0.032760 -0.005823  0.063999 -0.115582 -0.039072  0.685523   \n",
       "int_12  0.092164 -0.001294 -0.001431  0.021092 -0.020923 -0.012915  0.093341   \n",
       "int_13  0.005279 -0.034543  0.030109  0.612960 -0.054280  0.045574  0.003478   \n",
       "\n",
       "          int_08    int_09    int_10    int_11    int_12    int_13  \n",
       "int_01  0.097048  0.068316  0.465176  0.304534  0.092164  0.005279  \n",
       "int_02 -0.028035 -0.004732  0.035712  0.032760 -0.001294 -0.034543  \n",
       "int_03  0.045087 -0.000465 -0.003791 -0.005823 -0.001431  0.030109  \n",
       "int_04  0.504384  0.194364  0.157900  0.063999  0.021092  0.612960  \n",
       "int_05 -0.109468 -0.068310 -0.148043 -0.115582 -0.020923 -0.054280  \n",
       "int_06  0.022175  0.186576 -0.124605 -0.039072 -0.012915  0.045574  \n",
       "int_07  0.077122  0.233840  0.251448  0.685523  0.093341  0.003478  \n",
       "int_08  1.000000  0.206472  0.156661  0.139375  0.028334  0.631302  \n",
       "int_09  0.206472  1.000000  0.075001  0.403943  0.045726  0.192788  \n",
       "int_10  0.156661  0.075001  1.000000  0.386369  0.084908  0.023659  \n",
       "int_11  0.139375  0.403943  0.386369  1.000000  0.098713  0.010549  \n",
       "int_12  0.028334  0.045726  0.084908  0.098713  1.000000 -0.003453  \n",
       "int_13  0.631302  0.192788  0.023659  0.010549 -0.003453  1.000000  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intColList_ex = intColList=[\"int_01\", \"int_02\", \"int_03\", \"int_04\", \"int_05\", \"int_06\", \"int_07\", \"int_08\", \"int_09\", \"int_10\", \"int_11\", \"int_12\", \"int_13\"]\n",
    "\n",
    "correlation_matrix = pd.DataFrame(matrix.collect()[0][\"pearson({})\".format(vector_col)].values)\n",
    "correlation_matrix = correlation_matrix.values.reshape(13, 13)\n",
    "correlation_matrix = pd.DataFrame(correlation_matrix, columns = intColList_ex, index = intColList_ex)\n",
    "print(\"Correlation Matrix\")\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Heatmap for correlations matrix\n",
    "fig, ax = plt.subplots(figsize=(11, 9))\n",
    "mask = np.zeros_like(correlation_matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "cmap = sns.diverging_palette(240, 10, as_cmap=True)\n",
    "sns.heatmap(correlation_matrix, mask=mask, cmap=cmap, center=0, linewidths=.5)\n",
    "plt.title(\"Correlation Matrix.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6) Histograms on Data Subset\n",
    "\n",
    "Below we show several histograms of the numerical columns to better observe their distributions.  Due to the inefficiency with which Spark plots graphs, we are using a 0.01% subset of the data for our graphs, which represents 4,635 rows.\n",
    "\n",
    "Virtually all of the columns have a large number of values of 0.  This raises the concern that the data in the numerical columns may not be as useful as we would like, as if many of the values in the columns are identical (at 0) they may lack predictive power.  All of the columns are also heavily right-skewed, likely due to the large numer of 0 values.  However, the presence of a large number of 0 values makes the dataset ideal for sparse representation, which we will discuss further in our \"Algorithm Explanation\" section.\n",
    "\n",
    "Additionally, as seen earlier when numerically observing the range of values, many columns appear to have outliers.  This occurs most notably with columns int_5 and int_3.  These outliers run the risk of inordinately influencing our alogrithm, thus lowering its predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, int_1: double, int_2: double, int_3: double, int_4: double, int_5: double, int_6: double, int_7: double, int_8: double, int_9: double, int_10: double, int_11: double, int_12: double, int_13: double, categ_1: string, categ_2: string, categ_3: string, categ_4: string, categ_5: string, categ_6: string, categ_7: string, categ_8: string, categ_9: string, categ_10: string, categ_11: string, categ_12: string, categ_13: string, categ_14: string, categ_15: string, categ_16: string, categ_17: string, categ_18: string, categ_19: string, categ_20: string, categ_21: string, categ_22: string, categ_23: string, categ_24: string, categ_25: string, categ_26: string]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = fullWithColsDF.sample(False, fraction=0.0001, seed = 1)\n",
    "sample_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4635"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert to Pandas DataFrame\n",
    "pd_sample_df = sample_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01e2c320>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01fa9b38>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01cea470>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01c829e8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01caaf60>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01c5b518>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01c03a90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01c2dfd0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01bb7080>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01b86b00>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01b370b8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01b5d630>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01b04ba8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01ab7160>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01add6d8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d01a88c50>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd_sample_df.hist(figsize = (15, 15), bins = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.7) Graphs of Log-Odds - Final Logistic Regression Assumption Met\n",
    "\n",
    "We have one more assumption of logistic regression to test - that there is a linear relationship between the logit of the outcome and each predictor variable.  Again, the logit function is $logit(p) = log(p/(1-p))$ where p is the probability of the outcome.\n",
    "\n",
    "To save space, below we only plot the relationship between the logit of the outcome and the predictor variable \"int_1\".  However, this and the other numerical variables all show that this relationshp is linear.  For \"int_1\", this can be seen by the characteristic \"S\" shaped of the curve that has been generated by the sigmoid function.\n",
    "\n",
    "Thus, our final assumption needed for logstic regression has been met, and we can move on to implementation of the algrorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_plot_1 = sns.regplot(x = 'int_1', y = 'label', data= pd_sample_df, logistic= True).\\\n",
    "                set_title(\"Logit of Outcome vs. Predictor Variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Algorithm Explanation - With Toy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have shown that we have met all the assumptions for logistic regression, we will proceed to use it for our Click Through Rate prediction task.\n",
    "\n",
    "Before we perform the prediction on the Criteo dataset, we will begin by explaining the methodology behind how to apply linear regression to a toy (small and artifical) dataset that has a binary target variable and a mix of numerical and categorical columns.  Our methodolgy will include the use of one-hot encoding (OHE), sparse vectors, and gradient descent.  We will also explore some of the math behind logistic regression, including the use of a sigmoid function.\n",
    "\n",
    "For our toy example, we decided to measure the dropout rate for undergraduate students at Berkeley.  Please note that our data is completely randomly generated.  We created 1,000 records to obtain a large enough dataset for use with linear regression.  In addition to our target variable for drop_out (1 if a student drops out, 0 if they do not), our columns in order are terms taken, average partcipation rating (an average score from 0 to 10 assigned by professors), GPA, an indicator variable for whether the student is an in-state student or not, the major, and the minor.  The major and minor are categorical variables.  Below you can see some sample rows of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(text='1,4,6.37,2.85,0,Astrophysics,French'),\n",
       " Row(text='1,5,7.84,3.91,1,Sports Management,Data Science'),\n",
       " Row(text='1,2,5.5,2.82,1,Statistics,Computer Science'),\n",
       " Row(text='1,3,8.43,1.92,1,English,Religious Studies'),\n",
       " Row(text='0,4,6.29,3.43,1,Fine Arts,Data Science')]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_rawDF = sqlContext.read.text('gs://w261_final_project_ajh_bucket/data/Toy_Example_Data.csv').withColumnRenamed(\"value\", \"text\")\n",
    "toy_rawDF.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Parsing\n",
    "\n",
    "We begin by parsing our data into a usable format with the parse_point_toy function, before converting it to a DataFrame with the parse_toy_raw_df function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_point_toy(point):\n",
    "    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    values = point.split(',')[1:]\n",
    "    #values = filter(None, values)\n",
    "    indices = range(len(values))\n",
    "    return zip(indices,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, split\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, LongType, StringType, FloatType, DoubleType\n",
    "\n",
    "parse_point_toy_udf = udf(parse_point_toy, ArrayType(StructType([StructField('_1', LongType()),StructField('_2', StringType())])))\n",
    "\n",
    "def parse_toy_raw_df(raw_df):\n",
    "    \"\"\"Convert a DataFrame consisting of rows of comma separated text into labels and feature.\n",
    "    Args:\n",
    "        raw_df: DataFrame containing the raw comma separated data.\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with 'label' and 'feature' columns.   \n",
    "    \"\"\"\n",
    "    return (raw_df.select(split(raw_df.text,',').getItem(0).cast(\"double\").alias('label'),\n",
    "                         parse_point_toy_udf(raw_df.text).alias('features'))\n",
    "                        .cache())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) One-Hot Encoding with Sparse Representation\n",
    "\n",
    "To account for the categorical columns in our toy dataset (major and minor), we will use one-hot encoding (OHE).  One-hot encoding is used to represent categorical variables (which are often non-numeric) as binary vectors / values.  One-hot encoding is necessary as machine learning algorithms, including linear regression, cannot directly work with categorical data.  When implementing one-hot encoding in lists or dataframes, every label that is observed for a category is used to create additional columns.  Any time one of these labels is observed for a record, a “1” will be entered into the corresponding column.  If a label is not observed for a record, a “0” will be entered into the corresponding column.  For example, the major \"Data Science\" becomes a new column that supports binary values, as does the minor \"French\".\n",
    "\n",
    "To perform one-hot encoding on our data, we use the functions toy_create_one_hot_dict (creates a one-hot-encoder dictionary based on the input data), toy_ohe_udf_generator (generates a user-defined function that is set-up to one-hot-encode rows with the given dictionary), and toy_one_hot_encoding (produces a one-hot-encoding from a list of features and an OHE dictionary).  \n",
    "\n",
    "Important to note is that the toy_one_hot_encoding function creates a sparse matrix representation, which is important for scalability and memory utilization concerns.  Sparse matrices and vectors are most useful when a large number of values in a dataset are 0.  As shown in our EDA, the Criteo dataset contains a large proporion of values of 0, thus making it ideal for sparse representation.  Sparse representation of matrices and vectors acts as a form of compression, where much of the space that would have been used to store values of 0 in a dense representation is saved.  Sparse representation often runs much faster than dense representation, which is important for large datasets such as the Criteo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toy_create_one_hot_dict(input_df):\n",
    "    \"\"\"Creates a one-hot-encoder dictionary based on the input data.\n",
    "    Args:\n",
    "        input_df (DataFrame with 'features' column): A DataFrame where each row contains a list of\n",
    "            (featureID, value) tuples.\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are\n",
    "            unique integers.\n",
    "    \"\"\"\n",
    "    input_distinct_feats_df = input_df.select(explode(input_df.features)).distinct()\n",
    "    input_ohe_dict = (input_distinct_feats_df\n",
    "                     .rdd\n",
    "                     .map(lambda r: tuple(r[0]))\n",
    "                     .zipWithIndex().collectAsMap())\n",
    "    return input_ohe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.mllib.linalg import VectorUDT\n",
    "\n",
    "def toy_ohe_udf_generator(ohe_dict_broadcast):\n",
    "    \"\"\"Generate a UDF that is set-up to one-hot-encode rows with the given dictionary.\n",
    "    Note:\n",
    "        We'll reuse this function to generate a UDF that can one-hot-encode rows based on a\n",
    "        one-hot-encoding dictionary built from the training data.  Also, you should calculate\n",
    "        the number of features before calling the toy_one_hot_encoding function.\n",
    "    Args:\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "    Returns:\n",
    "        UserDefinedFunction: A UDF can be used in `DataFrame` `select` statement to call a\n",
    "            function on each row in a given column.  This UDF should call the toy_one_hot_encoding\n",
    "            function with the appropriate parameters.\n",
    "    \"\"\"\n",
    "    length = len(ohe_dict_broadcast.value)\n",
    "    return udf(lambda x: toy_one_hot_encoding(x, ohe_dict_broadcast, length), VectorUDT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseVector\n",
    "def toy_one_hot_encoding(raw_feats, ohe_dict_broadcast, num_ohe_feats):\n",
    "    \"\"\"Produces a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "    Note:\n",
    "        You should ensure that the indices used to create a SparseVector are sorted.\n",
    "    Args:\n",
    "        raw_feats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sample_one)\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "        num_ohe_feats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length num_ohe_feats with indices equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats])\n",
    "    values = np.ones(len(raw_feats))\n",
    "    return SparseVector(num_ohe_feats,indices,values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Logistic Regression with Gradient Descent\n",
    "\n",
    "After performing the one-hot encoding, we split our dataset into train, test, and dev sets that comprise 80%, 10%, and 10% of the rows, respectively.\n",
    "\n",
    "#### Logistic Regression\n",
    "\n",
    "At this point, we're ready to begin implementing our binary logistic regression algorithm.  Logistic regression relies on transforming a dataset using a sigmoid function.  This transformation gives the data in logistic regression an \"S\" shaped curve, and forces values to be between 0 and 1.  The equation for the sigmoid is:\n",
    "\n",
    "$$ f (x) =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^-(x) }  $$ \n",
    "\n",
    "#### Log-Loss\n",
    "\n",
    "Log-loss (related to cross-entropy) measures the performance of a classification model where the prediction input is a probability value between 0 and 1.  It represents a common cost, or loss function, used with logistic regression. A primary goal of the algorithm we are implementing is to minimize the log-loss value. A perfect model would have a log loss of 0. Log loss increases as the predicted probability diverges from the actual label.  The equation for log-loss is:\n",
    "\n",
    "For a single sample with true label $y_t$ in {0,1} and estimated probability $y_p$ that $y_t$ = 1, the log loss is\n",
    "\n",
    "$-log(P(y_t|y_p)) = -(y_t log(y_p) + (1 - y_t) log(1 - y_p))$\n",
    "\n",
    "#### Gradient Descent in Logistic Regression\n",
    "\n",
    "In order to implement our logistric regression algorithm in a scalable and computationally efficient manner, we chose to use gradient descent in our approach.  Gradient Descent is a process that works iteratively to find the optimal parameters for a model when fed a particular training data set. It does this by using the vector of partial derivatives of a loss function to strategically update parameters in a way that will reduce the loss.  As mentioned before, in the case of our logistic regression algorithm, the loss function being optimized is the log-loss function.  The hypothesis function for the method of gradient descent used in logistic regression is as follows:\n",
    "\n",
    "$$\\theta_j  = \\frac{1}{m} \\sum_{i=1}^m Cost(h_{\\theta} (\\pmb{x}^{(i)}), y^{(i)})$$\n",
    "\n",
    "Where $Cost(h_{\\theta}(x),y) ={−log(h_{\\theta}(x))}$ if y = 1 and\n",
    "\n",
    "$Cost(h_{\\theta}(x),y) ={−log(h_{\\theta}(1 - x))}$ if y = 0\n",
    "\n",
    "and where $h_{\\theta}$ is a hypothesis of the optimal value.\n",
    "\n",
    "#### Logistic Regression in the Toy Example\n",
    "\n",
    "To implement logistic regression in our toy example, we used the functions sigmoid (to generate a sigmoid transformation), GradientDescent (to implement Gradient Descent), LogLoss (to calculate log-loss), GDUpdate(to perform one step/update on the logistic regression).  Worth noting is that after performing One-Hot Encoding, we generated 682 features for inclusion in our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, dev, test, and total row counts\n",
      "806 94 100 1000\n"
     ]
    }
   ],
   "source": [
    "weights = [0.8, 0.1, 0.1]\n",
    "seed = 42\n",
    "# Use randomSplit with weights and seed\n",
    "raw_toy_train_df, raw_toy_validation_df, raw_toy_test_df = toy_rawDF.randomSplit(weights, seed)\n",
    "\n",
    "# Cache and count the DataFrames\n",
    "n_toy_train = raw_toy_train_df.cache().count()\n",
    "n_toy_val = raw_toy_validation_df.cache().count()\n",
    "n_toy_test = raw_toy_test_df.cache().count()\n",
    "print(\"Train, dev, test, and total row counts\")\n",
    "print(n_toy_train, n_toy_val, n_toy_test, str(n_toy_train + n_toy_val + n_toy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(label=0.0, features=[Row(_1=0, _2='2'), Row(_1=1, _2='5.01'), Row(_1=2, _2='2.41'), Row(_1=3, _2='1'), Row(_1=4, _2='Math'), Row(_1=5, _2='German')])\n"
     ]
    }
   ],
   "source": [
    "parsed_toy_train_df = parse_toy_raw_df(raw_toy_train_df)\n",
    "print(parsed_toy_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (explode, col)\n",
    "num_toy_categories = (parsed_toy_train_df\n",
    "                    .select(explode('features').alias('features'))\n",
    "                    .distinct()\n",
    "                    .select(col('features').getField('_1').alias('featureNumber'))\n",
    "                    .groupBy('featureNumber')\n",
    "                    .sum()\n",
    "                    .orderBy('featureNumber')\n",
    "                    .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(featureNumber=0, sum(featureNumber)=0), Row(featureNumber=1, sum(featureNumber)=402), Row(featureNumber=2, sum(featureNumber)=480), Row(featureNumber=3, sum(featureNumber)=6), Row(featureNumber=4, sum(featureNumber)=68), Row(featureNumber=5, sum(featureNumber)=85)]\n"
     ]
    }
   ],
   "source": [
    "print(num_toy_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OHE Features Generated\n",
      "682\n"
     ]
    }
   ],
   "source": [
    "toy_ohe_dict = toy_create_one_hot_dict(parsed_toy_train_df)\n",
    "num_toy_ohe_feats = len(toy_ohe_dict)\n",
    "print(\"Number of OHE Features Generated\")\n",
    "print(num_toy_ohe_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toy_ohe_dict_broadcast = sc.broadcast(toy_ohe_dict)\n",
    "toy_ohe_dict_udf =  toy_ohe_udf_generator(toy_ohe_dict_broadcast)\n",
    "toy_ohe_train_df =  parsed_toy_train_df.select(toy_ohe_dict_udf(parsed_toy_train_df.features).alias('features'),parsed_toy_train_df.label,)\n",
    "\n",
    "# print(toy_ohe_train_df.count())\n",
    "# print(toy_ohe_train_df.show())\n",
    "# print(toy_ohe_train_df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toy_ohe_train_rdd = toy_ohe_train_df \\\n",
    "                     .rdd \\\n",
    "                     .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PercentDropOut: 0.6625310173697271\n",
      "Mean: 0.6625310173697274\n",
      "Variance: 0.2235836683927612\n"
     ]
    }
   ],
   "source": [
    "meanDropOut = toy_ohe_train_rdd.map(lambda x: x[1]).mean()\n",
    "varDropOut = toy_ohe_train_rdd.map(lambda x: x[1]).variance()\n",
    "numDropOut = toy_ohe_train_rdd.map(lambda x: x[1]).sum()/toy_ohe_train_df.count()\n",
    "print(f\"PercentDropOut: {numDropOut}\")\n",
    "print(f\"Mean: {meanDropOut}\")\n",
    "print(f\"Variance: {varDropOut}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASELINE = np.append(meanDropOut, np.zeros(num_toy_ohe_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GradientDescent(trainRDD, testRDD, wInit, nSteps = 20, \n",
    "                    learningRate = 0.01, verbose = False):\n",
    "    \"\"\"\n",
    "    Perform nSteps iterations of gradient descent and \n",
    "    track loss on a test and train set. Return lists of\n",
    "    test/train loss and the models themselves.\n",
    "    \"\"\"\n",
    "    # initialize lists to track model performance\n",
    "    train_history, test_history, model_history = [], [], []\n",
    "    \n",
    "    # perform n updates & compute test and train loss after each\n",
    "    model = wInit\n",
    "    for idx in range(nSteps):  \n",
    "        model = GDUpdate(trainRDD, model, learningRate)\n",
    "        training_loss = LogLoss(trainRDD, model) \n",
    "        test_loss = LogLoss(testRDD, model)\n",
    "        \n",
    "        # keep track of test/train loss for plotting\n",
    "        train_history.append(training_loss)\n",
    "        test_history.append(test_loss)\n",
    "        model_history.append(model)\n",
    "        \n",
    "        # console output if desired\n",
    "        if verbose:\n",
    "            print(\"----------\")\n",
    "            print(f\"STEP: {idx+1}\")\n",
    "            print(f\"training loss: {training_loss}\")\n",
    "            print(f\"test loss: {test_loss}\")\n",
    "            print(f\"Model: {[round(w,3) for w in model]}\")\n",
    "    return train_history, test_history, model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LogLoss(dataRDD, W):\n",
    "    \"\"\"\n",
    "    Compute log loss.\n",
    "    Args:\n",
    "        dataRDD - each record is a tuple of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    \"\"\"\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1])).cache()\n",
    "    loss = augmentedData.map(lambda x: (-x[1] * np.log(sigmoid(W.dot(x[0]))) \\\n",
    "                                     - (1 - x[1]) * np.log(1 - sigmoid(W.dot(x[0])))) ).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GDUpdate(dataRDD, W, learningRate = 0.1):\n",
    "    \"\"\"\n",
    "    Perform one step/update on the Logistic regression.\n",
    "    Args:\n",
    "        dataRDD - records are tuples of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    Returns:\n",
    "        new_model - (array) updated coefficients, bias at index 0\n",
    "    \"\"\"\n",
    "    # add a bias 'feature' of 1 at index 0\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1])).cache()\n",
    "    grad = augmentedData.map(lambda x: np.dot(sigmoid(W.dot(x[0]) - x[1]),x[0])).mean()\n",
    "    new_model = W - learningRate * grad\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) Algorithm Performance for Toy Example\n",
    "\n",
    "After implementing several functions to transform our data and run our algorithm, we obtain a log-loss score of 0.6625 on our toy training dataset, and a very similar log-loss score of 0.6618 on our toy test dataset.  Ideally, we will be able to beat this when we run our logistic regression implementation on the Criteo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE:  Loss = 0.6393586657271466\n",
      "----------\n",
      "STEP: 1\n",
      "Loss: 0.6405834992567013\n",
      "----------\n",
      "STEP: 2\n",
      "Loss: 0.643721487215732\n",
      "----------\n",
      "STEP: 3\n",
      "Loss: 0.6485545689963543\n",
      "----------\n",
      "STEP: 4\n",
      "Loss: 0.6548778151932536\n",
      "----------\n",
      "STEP: 5\n",
      "Loss: 0.6625012704436208\n"
     ]
    }
   ],
   "source": [
    "nSteps = 5\n",
    "model = BASELINE\n",
    "print(f\"BASELINE:  Loss = {LogLoss(toy_ohe_train_rdd,model)}\")\n",
    "for idx in range(nSteps):\n",
    "    print(\"----------\")\n",
    "    print(f\"STEP: {idx+1}\")\n",
    "    model = GDUpdate(toy_ohe_train_rdd, model)\n",
    "    loss = LogLoss(toy_ohe_train_rdd, model)\n",
    "    print(f\"Loss: {loss}\")\n",
    "  #  print(f\"Model: {[round(w,3) for w in model]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... trained 50 iterations in 622.8087210655212 seconds\n"
     ]
    }
   ],
   "source": [
    "# run 50 iterations (RUN THIS CELL AS IS)\n",
    "wInit = BASELINE\n",
    "trainRDD, testRDD = toy_ohe_train_rdd.randomSplit([0.8,0.2], seed = 2018)\n",
    "start = time.time()\n",
    "train, test, models = GradientDescent(trainRDD, testRDD, wInit, nSteps = 50)\n",
    "print(f\"\\n... trained {len(models)} iterations in {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Additional functions used for transforming the test split\n",
    "def toy_one_hot_encoding_v2(raw_feats, ohe_dict_broadcast, num_ohe_feats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "    Args:\n",
    "        raw_feats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sample_one)\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "        num_ohe_feats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length num_ohe_feats with indices equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats if feat in ohe_dict_broadcast.value])\n",
    "    values = np.ones(len([feat for feat in raw_feats if feat in ohe_dict_broadcast.value] ))\n",
    "    return SparseVector(num_ohe_feats,indices,values)\n",
    "\n",
    "def toy_ohe_udf_generator_v2(ohe_dict_broadcast):\n",
    "    \"\"\"Generate a UDF that is setup to one-hot-encode rows with the given dictionary.\n",
    "    Note:\n",
    "        We'll reuse this function to generate a UDF that can one-hot-encode rows based on a\n",
    "        one-hot-encoding dictionary built from the training data.  Also, you should calculate\n",
    "        the number of features before calling the one_hot_encoding function.\n",
    "    Args:\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "    Returns:\n",
    "        UserDefinedFunction: A UDF can be used in `DataFrame` `select` statement to call a\n",
    "            function on each row in a given column.  This UDF should call the one_hot_encoding\n",
    "            function with the appropriate parameters.\n",
    "    \"\"\"\n",
    "    length = len(ohe_dict_broadcast.value)\n",
    "    return udf(lambda x: toy_one_hot_encoding_v2(x, ohe_dict_broadcast, length), VectorUDT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "toy_ohe_dict_missing_udf = toy_ohe_udf_generator_v2(toy_ohe_dict_broadcast)\n",
    "\n",
    "toy_ohe_test_df = parsed_toy_train_df.select(toy_ohe_dict_missing_udf(parsed_toy_train_df.features).alias('features'), parsed_toy_train_df.label,).cache()\n",
    "# print(toy_ohe_test_df.count())\n",
    "# print(toy_ohe_test_df.show())\n",
    "# print(toy_ohe_test_df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toy_ohe_test_rdd = toy_ohe_test_df \\\n",
    "                     .rdd \\\n",
    "                     .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6617741806149889"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSE = LogLoss(ohe_test_rdd, models)\n",
    "toy_train_model = np.asarray(models[-1])\n",
    "LogLoss(toy_ohe_test_rdd, toy_train_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Algorithm Implementation\n",
    "\n",
    "After demonstrating our methodolgy for implementing binary logistic regression on our toy dataset, we are ready to implement it on the Criteo dataset.\n",
    "\n",
    "We begin by creating a train, dev, and test split of the Criteo day.  We additionally ensure the column transformations used in the EDA are applied to the data to properly cast the numerical columns as numbers (\"doubles\") and separate the categorical columns.  Please note that for performance purposes we chose to run the majority of our model on 25% of the train set.  This still provide a wealth of data, with 9,167,896 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = [0.8, 0.1, 0.1]\n",
    "seed = 1\n",
    "\n",
    "# Use randomSplit with weights and seed\n",
    "rawTrainDF, rawValidationDF, rawTestDF = rawDF.randomSplit(weights, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#25% sampling due to memory errors\n",
    "rawTrainNewDF = rawTrainDF.sample(withReplacement=False, fraction=0.25, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawTrainNewDF.cache()\n",
    "rawValidationDF.cache()\n",
    "rawTestDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9167896"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawTrainNewDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainWithColsDF = rawTrainNewDF.withColumn('tmp', split('text', '\\t')).\\\n",
    "                    select( col(\"tmp\").getItem(0).cast(\"double\").alias(\"label\")\n",
    "                    , col(\"tmp\").getItem(1).cast(\"double\").alias(\"int_1\")\n",
    "                    , col(\"tmp\").getItem(2).cast(\"double\").alias(\"int_2\")\n",
    "                    , col(\"tmp\").getItem(3).cast(\"double\").alias(\"int_3\")\n",
    "                    , col(\"tmp\").getItem(4).cast(\"double\").alias(\"int_4\")\n",
    "                    , col(\"tmp\").getItem(5).cast(\"double\").alias(\"int_5\")\n",
    "                    , col(\"tmp\").getItem(6).cast(\"double\").alias(\"int_6\")\n",
    "                    , col(\"tmp\").getItem(7).cast(\"double\").alias(\"int_7\")\n",
    "                    , col(\"tmp\").getItem(8).cast(\"double\").alias(\"int_8\")\n",
    "                    , col(\"tmp\").getItem(9).cast(\"double\").alias(\"int_9\")\n",
    "                    , col(\"tmp\").getItem(10).cast(\"double\").alias(\"int_10\")\n",
    "                    , col(\"tmp\").getItem(11).cast(\"double\").alias(\"int_11\")\n",
    "                    , col(\"tmp\").getItem(12).cast(\"double\").alias(\"int_12\")\n",
    "                    , col(\"tmp\").getItem(13).cast(\"double\").alias(\"int_13\")\n",
    "                    , col(\"tmp\").getItem(14).alias(\"categ_1\")\n",
    "                    , col(\"tmp\").getItem(15).alias(\"categ_2\")\n",
    "                    , col(\"tmp\").getItem(16).alias(\"categ_3\")\n",
    "                    , col(\"tmp\").getItem(17).alias(\"categ_4\")\n",
    "                    , col(\"tmp\").getItem(18).alias(\"categ_5\")\n",
    "                    , col(\"tmp\").getItem(19).alias(\"categ_6\")\n",
    "                    , col(\"tmp\").getItem(20).alias(\"categ_7\")\n",
    "                    , col(\"tmp\").getItem(21).alias(\"categ_8\")\n",
    "                    , col(\"tmp\").getItem(22).alias(\"categ_9\")\n",
    "                    , col(\"tmp\").getItem(23).alias(\"categ_10\")\n",
    "                    , col(\"tmp\").getItem(24).alias(\"categ_11\")\n",
    "                    , col(\"tmp\").getItem(25).alias(\"categ_12\")\n",
    "                    , col(\"tmp\").getItem(26).alias(\"categ_13\")\n",
    "                    , col(\"tmp\").getItem(27).alias(\"categ_14\")\n",
    "                    , col(\"tmp\").getItem(28).alias(\"categ_15\")\n",
    "                    , col(\"tmp\").getItem(29).alias(\"categ_16\")\n",
    "                    , col(\"tmp\").getItem(30).alias(\"categ_17\")\n",
    "                    , col(\"tmp\").getItem(31).alias(\"categ_18\")\n",
    "                    , col(\"tmp\").getItem(32).alias(\"categ_19\")\n",
    "                    , col(\"tmp\").getItem(33).alias(\"categ_20\")\n",
    "                    , col(\"tmp\").getItem(34).alias(\"categ_21\")\n",
    "                    , col(\"tmp\").getItem(35).alias(\"categ_22\")\n",
    "                    , col(\"tmp\").getItem(36).alias(\"categ_23\")\n",
    "                    , col(\"tmp\").getItem(37).alias(\"categ_24\")\n",
    "                    , col(\"tmp\").getItem(38).alias(\"categ_25\")\n",
    "                    , col(\"tmp\").getItem(39).alias(\"categ_26\")\n",
    "                    ).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) Function Application\n",
    "\n",
    "For the application of our binary logistic regression algorithm to the Criteo dataset, we will utilize functions similar to those used for the toy example.  They include one_hot_encoding (produces a one-hot encoding from a list of features and an OHE dictionary), ohe_udf_generator (generates a user defined function that is set-up to one-hot encode rows with the given dictionary), create_one_hot_dict (creates a one-hot encoder dictionary based on the input data), parse_point(for parsing CSV data), and parse_raw_df(to transform a DataFrame into labels and features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(raw_feats, ohe_dict_broadcast, num_ohe_feats):\n",
    "    \"\"\"Produces a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "    Note:\n",
    "        You should ensure that the indices used to create a SparseVector are sorted, and that the\n",
    "        function handles missing features.\n",
    "    Args:\n",
    "        raw_feats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sample_one)\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "        num_ohe_feats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length num_ohe_feats with indices equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    #indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats if feat in ohe_dict_broadcast.value])\n",
    "    indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats])\n",
    "    values = np.ones(len(raw_feats))\n",
    "    return SparseVector(num_ohe_feats,indices,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ohe_udf_generator(ohe_dict_broadcast):\n",
    "    \"\"\"Generates a UDF that is set-up to one-hot encode rows with the given dictionary.\n",
    "    Note:\n",
    "        We'll reuse this function to generate a UDF that can one-hot-encode rows based on a\n",
    "        one-hot-encoding dictionary built from the training data.  Also, you should calculate\n",
    "        the number of features before calling the one_hot_encoding function.\n",
    "    Args:\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "    Returns:\n",
    "        UserDefinedFunction: A UDF can be used in `DataFrame` `select` statement to call a\n",
    "            function on each row in a given column.  This UDF should call the one_hot_encoding\n",
    "            function with the appropriate parameters.\n",
    "    \"\"\"\n",
    "    length = len(ohe_dict_broadcast.value)\n",
    "    return udf(lambda x: one_hot_encoding(x, ohe_dict_broadcast, length), VectorUDT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_one_hot_dict(input_df):\n",
    "    \"\"\"Creates a one-hot-encoder dictionary based on the input data.\n",
    "    Args:\n",
    "        input_df (DataFrame with 'features' column): A DataFrame where each row contains a list of\n",
    "            (featureID, value) tuples.\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are\n",
    "            unique integers.\n",
    "    \"\"\"\n",
    "    input_distinct_feats_df = input_df.select(explode(input_df.features)).distinct()\n",
    "    input_ohe_dict = (input_distinct_feats_df\n",
    "                     .rdd\n",
    "                     .map(lambda r: tuple(r[0]))\n",
    "                     .zipWithIndex().collectAsMap())\n",
    "    return input_ohe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_point(point):\n",
    "    \"\"\" Converts a tab separated string into a list of (featureID, value) tuples.\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "    Arguments:\n",
    "        point (str): A tab separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    values = point.split('\\t')[1:]\n",
    "    indices = range(len(values))\n",
    "    return zip(indices,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parse_point_udf = udf(parse_point, ArrayType(StructType([StructField('_1', LongType()),StructField('_2', StringType())])))\n",
    "\n",
    "def parse_raw_df(raw_df):\n",
    "    \"\"\" Will transform a DataFrame with tab separated text into labels and features.\n",
    "    Arguments:\n",
    "        raw_df (DataFrame with a 'text' column): DataFrame containing the raw tab separated data.\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with 'label' and 'feature' columns.   \n",
    "    \"\"\"\n",
    "    return (raw_df.select(split(raw_df.text,'\\t').getItem(0).cast(\"double\").alias('label'),\n",
    "                         parse_point_udf(raw_df.text).alias('features'))\n",
    "                        .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed_train_df = parse_raw_df(rawTrainNewDF)\n",
    "parsed_validation_df = parse_raw_df(rawValidationDF)\n",
    "parsed_test_df = parse_raw_df(rawTestDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: array<struct<_1:bigint,_2:string>>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_train_df.cache()\n",
    "parsed_validation_df.cache()\n",
    "parsed_test_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_categories = (parsed_train_df\n",
    "                    .select(explode('features').alias('features'))\n",
    "                    .distinct()\n",
    "                    .select(col('features').getField('_1').alias('featureNumber'))\n",
    "                    .groupBy('featureNumber')\n",
    "                    .sum()\n",
    "                    .orderBy('featureNumber')\n",
    "                    .collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2) One-Hot Encoding Application\n",
    "\n",
    "In the next few cells you can observe how we create our one-hot encoding dictionary using the create_one_hot_dict function.  It ends up producing a large number of features: 9,444,472!\n",
    "\n",
    "Next, to handle features seen in the test split but not the training split, we employ the functions one_hot_encoding_v2 and ohe_udf_generator_v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctr_ohe_dict = create_one_hot_dict(parsed_train_df)\n",
    "num_ctr_ohe_feats = len(ctr_ohe_dict)\n",
    "print(\"Number of one-hot encoding features\")\n",
    "print(num_ctr_ohe_feats)\n",
    "# print(ctr_ohe_dict[(0, '')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of one-hot encoding features\n",
    "\n",
    "9444472"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe_dict_broadcast = sc.broadcast(ctr_ohe_dict)\n",
    "ohe_dict_udf =  ohe_udf_generator(ohe_dict_broadcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_train_df =  parsed_train_df.select(parsed_train_df.label, ohe_dict_udf(parsed_train_df.features).alias('features'))\n",
    "ohe_train_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To Handle Unseen Features\n",
    "\n",
    "def one_hot_encoding_v2(raw_feats, ohe_dict_broadcast, num_ohe_feats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "    The indices used to create a SparseVector are sorted. We consider previously seen features only.\n",
    "    Args:\n",
    "        raw_feats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sample_one)\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "        num_ohe_feats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length num_ohe_feats with indices equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats if feat in ohe_dict_broadcast.value])\n",
    "    values = np.ones(len([feat for feat in raw_feats if feat in ohe_dict_broadcast.value] ))\n",
    "    return SparseVector(num_ohe_feats,indices,values)\n",
    "\n",
    "def ohe_udf_generator_v2(ohe_dict_broadcast):\n",
    "    \"\"\"Generate a UDF that is setup to one-hot-encode rows with the given dictionary.\n",
    "    Args:\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "    Returns:\n",
    "        UserDefinedFunction: A UDF can be used in `DataFrame` `select` statement to call a\n",
    "            function on each row in a given column.  This UDF should call the one_hot_encoding\n",
    "            function with the appropriate parameters.\n",
    "    \"\"\"\n",
    "    length = len(ohe_dict_broadcast.value)\n",
    "    return udf(lambda x: one_hot_encoding_v2(x, ohe_dict_broadcast, length), VectorUDT())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe_dict_missing_udf = ohe_udf_generator_v2(ohe_dict_broadcast)\n",
    "\n",
    "ohe_test_df = parsed_test_df.select(parsed_test_df.label,  ohe_dict_missing_udf(parsed_test_df.features).alias('features')).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3) Click Through Rate (CTR) Prediction and Log-Loss Evaluation\n",
    "\n",
    "The next few cells perform the actual logistic regression on the now one-hot encoded Criteo dataset.  Using our add_log_loss function for scoring, we are able to obtain a baseline training log-loss of 0.569."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1) Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: -1.0743401568315318\n",
      "length of coefficients: 9444472\n",
      "[-2.3933778261858674, -2.3640446886325717, -2.3606764183110305, -2.356334312584443, -2.345188385115328]\n"
     ]
    }
   ],
   "source": [
    "standardization = True\n",
    "elastic_net_param = 0.0\n",
    "reg_param = .01\n",
    "max_iter = 5\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", predictionCol=\"prediction\", maxIter=max_iter, regParam=reg_param, elasticNetParam=elastic_net_param, fitIntercept=True,  standardization=standardization)\n",
    "lr_model_basic = lr.fit(ohe_train_df)\n",
    "\n",
    "print('intercept: {0}'.format(lr_model_basic.intercept))\n",
    "print('length of coefficients: {0}'.format(len(lr_model_basic.coefficients)))\n",
    "sorted_coefficients = sorted(lr_model_basic.coefficients)[:5]\n",
    "print(sorted_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2) Log-Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, log, col\n",
    "epsilon = 1e-16\n",
    "\n",
    "def add_log_loss(df):\n",
    "    \"\"\"Computes and adds a 'log_loss' column to a DataFrame using 'p' and 'label' columns.\n",
    "    Note:\n",
    "        log(0) is undefined, so when p is 0 we add a small value (epsilon) to it and when\n",
    "        p is 1 we subtract a small value (epsilon) from it.\n",
    "    Args:\n",
    "        df (DataFrame with 'p' and 'label' columns): A DataFrame with a probability column\n",
    "            'p' and a 'label' column that corresponds to y in the log loss formula.\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with an additional column called 'log_loss' where 'log_loss' column contains the loss value as explained above.\n",
    "        if y == 1:\n",
    "          return -log(epsilon + p) if p == 0 else -log(p)\n",
    "        elif y == 0:\n",
    "          return -log(1 - p + epsilon) if p == 1 else -log(1 - p)         \n",
    "    \"\"\"\n",
    "    return (df.select(df['p'],df['label'],\n",
    "                when(df['label']==1.0,\n",
    "                     (when(df['p']!=0,-log(df['p'])))\n",
    "                     .otherwise(-log(epsilon + df['p'])))\n",
    "               .when(df['label']==0.0,\n",
    "                     (when(df['p']!=1.0,-log(1.0-df['p'])))\n",
    "                     .otherwise(-log(1.0 - df['p'] + epsilon)))\n",
    "               .alias(\"log_loss\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3) Baseline Log-Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class one fraction = 0.256\n",
      "Baseline Train Logloss = 0.569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "class_one_frac_train = ohe_train_df.select(F.sum('label')).collect()[0][0] / ohe_train_df.count()\n",
    "\n",
    "ohe_train_df = (ohe_train_df.withColumn(\"p\", lit(class_one_frac_train)))\n",
    "print('Training class one fraction = {0:.3f}'.format(class_one_frac_train))\n",
    "\n",
    "log_loss_tr_base = (add_log_loss(ohe_train_df).select(F.sum('log_loss')).collect()[0][0] / ohe_train_df.count())\n",
    "print('Baseline Train Logloss = {0:.3f}\\n'.format(log_loss_tr_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4) Predicting Probability\n",
    "\n",
    "For better insight into the workings of our model, we created the functions add_probability and get_p to create a column called \"p\" to be integrated into our stored training predictions.  \"p\" represents the probability a specific observation is made when simply given a list of features.  Interestingly, for the first 5 observations we examined, this probability fairly low, being between 0.038 and 0.096."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from math import exp #  exp(-t) = e^-t\n",
    "\n",
    "def add_probability(df, model):\n",
    "    \"\"\"Adds a probability column ('p') to a DataFrame given a model\n",
    "    Args:\n",
    "        df for which probability has to be calculated.\n",
    "        model with which probability has to be calculated\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with an additional column called p where p column contains the probability for an observation given a list of features.\n",
    "    \"\"\"\n",
    "    coefficients_broadcast = sc.broadcast(model.coefficients)\n",
    "    intercept = model.intercept\n",
    "\n",
    "    def get_p(features):\n",
    "        \"\"\"Calculate the probability for an observation given a list of features.\n",
    "        Note:\n",
    "            We'll bound our raw prediction between 20 and -20 for numerical purposes.\n",
    "        Args:\n",
    "            features: the features\n",
    "        Returns:\n",
    "            float: A probability between 0 and 1.\n",
    "        \"\"\"\n",
    "        # Compute the raw value\n",
    "        raw_prediction = features.dot(coefficients_broadcast.value)+intercept\n",
    "        # Bound the raw value between 20 and -20\n",
    "        raw_prediction = min(raw_prediction, 20)\n",
    "        raw_prediction = max(raw_prediction, -20)\n",
    "        return 1.0 / (1.0 + exp(-raw_prediction))\n",
    "\n",
    "    get_p_udf = udf(get_p, DoubleType())\n",
    "    return df.withColumn('p', get_p_udf('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "add_probability_model_basic = lambda df: add_probability(df, lr_model_basic)\n",
    "training_predictions = add_probability_model_basic(ohe_train_df).cache()\n",
    "# training_predictions.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            features|                   p|\n",
      "+-----+--------------------+--------------------+\n",
      "|  0.0|(9444472,[282595,...| 0.03797345839906773|\n",
      "|  0.0|(9444472,[282595,...| 0.04075749313455165|\n",
      "|  0.0|(9444472,[282595,...|  0.0602396726700737|\n",
      "|  0.0|(9444472,[235571,...|0.058502976931045676|\n",
      "|  0.0|(9444472,[282595,...| 0.09565946274868178|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5) Evaluating the Model\n",
    "\n",
    "As we finished the implementation of our logistic regression algorithm, we evaluated the results of our model on the test set.  In the end, we achieved a great log-loss score of 0.495.  This compared very favorably to the baseline training log-loss of 0.569 that we saw previously.\n",
    "\n",
    "We also noticed that for the test set that the probability a specific observation is made when simply given a list of features (\"p\") appeared to increase, now seeing several sample values above 0.10.\n",
    "\n",
    "The favorable performance of our test set over our train set was unexpected, and likely due to random chance.  We would have expected the train set to have a better (lower) log-loss score vs. the test set due to the potential for overfitting to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_results(df, model, baseline=None):\n",
    "    \"\"\"Calculates the log loss for the data given the model.\n",
    "    Note:\n",
    "        If baseline has a value the probability should be set to baseline before\n",
    "        the log loss is calculated.  Otherwise, use add_probability to add the\n",
    "        appropriate probabilities to the DataFrame.\n",
    "    Args:\n",
    "        df (DataFrame with 'label' and 'features' columns): A DataFrame containing\n",
    "            labels and features.\n",
    "        model (LogisticRegressionModel): A trained logistic regression model. This\n",
    "            can be None if baseline is set.\n",
    "        baseline (float): A baseline probability to use for the log loss calculation.\n",
    "    Returns:\n",
    "        float: Log loss for the data.\n",
    "    \"\"\"\n",
    "    with_probability_df = add_probability(df, model)\n",
    "    with_log_loss_df = add_log_loss(with_probability_df)\n",
    "    log_loss = (with_log_loss_df.select(F.sum('log_loss')).collect()[0][0] / with_log_loss_df.count())\n",
    "    return log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE Features Train Logloss:\n",
      "\tBaseline = 0.569\n",
      "\tLogReg = 0.335\n"
     ]
    }
   ],
   "source": [
    "log_loss_train_model_basic = evaluate_results(ohe_train_df, lr_model_basic)\n",
    "print ('OHE Features Train Logloss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(log_loss_tr_base, log_loss_train_model_basic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1) Test Dataset Log-Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss_val = evaluate_results(ohe_test_df, lr_model_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4948208635641279"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------------+\n",
      "|label|            features|                  p|\n",
      "+-----+--------------------+-------------------+\n",
      "|  0.0|(9444472,[282595,...| 0.0758689589710484|\n",
      "|  0.0|(9444472,[235572,...| 0.0400414644520275|\n",
      "|  0.0|(9444472,[47175,1...|0.10946047756433618|\n",
      "|  0.0|(9444472,[95297,4...|0.03827244701048019|\n",
      "|  0.0|(9444472,[424288,...|0.13123500785370285|\n",
      "+-----+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = add_probability_model_basic(ohe_test_df).cache()\n",
    "test_predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Conclusion and Course Concepts Used\n",
    "\n",
    "In this project on Click Through Rate prediction, we set out to predict a target variable of whether or not a display ad served resulted in a click.  Overall, we are pleased with our log-loss score on our test split of the Criteo data of 0.495.  It beat the log-loss score of 0.50 that we targeted at the beginning of our analysis, and indicates that we have a useful model.  Were the Critereo Kaggle competition still open, we would submit this score, and work further to iterate and improve upon it.\n",
    "\n",
    "In our analysis and implementation of binary logistic regression, we showed that logistic regression was an appropriate algorithm to use on the dataset.  Our EDA helped showed many of the idiosyncracies of the data numerically and graphically, including the presence of categorical columns, the large proportion of numerical values of 0, and the great range in numerical data values.\n",
    "\n",
    "Through completing a toy example on a custom-made undergraduate drop-out rate dataset, we implemented one-hot encoding on the values in our categorical columns, and used a sparse matrix representation to more efficiently store our data.   Utilizing gradient descent, we implemented a binary logistic regression algorithm.  This included the utilization of a sigmoid function to transform our data.  We measured our performance via the log-loss metric, which was the primary metric used to judge the Kaggle competition for which the Criteo data was originally made available.\n",
    "\n",
    "After using our toy example to demonstrate the theory behind and ways of implementing binary logistic regression, we moved on to tackle the implementation of logistic regression on the Criteo dataset at large.  With our test split log-loss score of 0.495, we again show that our model was useful.\n",
    "\n",
    "Important to note again is that if we had not used one-hot encoding in our approach, we would not have been able to use the categorical columns in the dataset.  As they represented 26 out of 39 columns in the original, untransformed dataset, our model would have had dramatically less data to work with had they not been present.  This in turn would have lowered the predictive power of our model, and likely increased (worsened) our log-loss score.\n",
    "\n",
    "In the future, it would be interesting to apply our logistic regression algorithm to other datasets that include a binary target variable and mix of numeric and categorical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 5.1) References:\n",
    "\n",
    "One-Hot encoding\n",
    "https://towardsdatascience.com/machine-learning-with-pyspark-and-mllib-solving-a-binary-classification-problem-96396065d2aa\n",
    "https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "\n",
    "LR from scratch\n",
    "https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac\n",
    "https://www.programcreek.com/python/example/106727/pyspark.ml.feature.StringIndexer\n",
    "\n",
    "pyspark.mllib vs pyspark.ml\n",
    "https://stackoverflow.com/questions/41074182/cannot-convert-type-class-pyspark-ml-linalg-sparsevector-into-vector\n",
    "\n",
    "Click-Through Rate\n",
    "https://www.wordstream.com/click-through-rate\n",
    "http://people.csail.mit.edu/romer/papers/TISTRespPredAds.pdf\n",
    "http://lncohn.com/spark/ctr.html\n",
    "\n",
    "Logistic Regression\n",
    "http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/#logistic-regression-assumptions\n",
    "https://statistics.laerd.com/spss-tutorials/binomial-logistic-regression-using-spss-statistics.php\n",
    "https://pythonfordatascience.org/logistic-regression-python/\n",
    "https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python\n",
    "http://cs229.stanford.edu/notes/cs229-notes1.pdf\n",
    "http://wiki.fast.ai/index.php/Log_Loss\n",
    "https://www.internalpointers.com/post/cost-function-logistic-regression\n",
    "\n",
    "RandomForest\n",
    "https://github.com/apache/spark/blob/v2.2.0/mllib/src/main/scala/org/apache/spark/ml/classification/RandomForestClassifier.scala#L120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
