{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final project we seek to perform Click Through Rate (CTR) prediction on a large public dataset of Criteo advertising data.  This data was made available as part of a Kaggle competition several years ago.  CTR is an important and commonly used metric in Internet marketing.  It measures the number of clicks advertisers receive on their ads per number of impressions ((Total Clicks on Ad) / (Total Impressions) = Click Through Rate).  In simple terms, a  high CTR means that a high percentage of people who see an ad click on it.  Thus, ads with a high CTR can be thought of as high performing, and the companies serving these ads can charge more for them.\n",
    "\n",
    "The winner of the Criteo Kaggle competition achieved a log-loss score of 0.445.  With 718 competition entries, all entries performing above the 90th percentile achieved a log-loss score of 0.46 or less.  While reaching a score this low would be ideal, our model could still be practically useful (especially if it was applied to other datasets) with a slightly higher log-loss score, such as around 0.50.\n",
    "\n",
    "In pursuit of our ultimate goal of performing CTR prediction on a public dataset of Criteo advertising data, we will perform an exploratory data analysis (EDA), and from this EDA determine if logistic regression is an appropriate algorithm to use for CTR prediction.  This will include thoroughly testing its assumption.  If we determine it is appropriate, we will then apply logistic regression to a toy example (an artificial example) to test our general algorithm implementation.  Our target variable will be the ###CTR for a specific display ad### before applying the same algorithm to a full test and train split.  We will seek to optimize our implementation of the algorithm to achieve a log-loss score of 0.50 or lower.\n",
    "\n",
    "Some of the limitations of the dataset include the fact that many of the columns in it are categorical in nature.  To be able to use them with logistic regression, which only accepts numeri\n",
    "\n",
    "###maybe describe algorithm (logistic regression in this section more) as opposed to starting discussion in EDA).###\n",
    "\n",
    "### Discuss more the limitations of the data and/or algorithm ###\n",
    "\n",
    "LImitations: We have a bunch of categorical columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installation of necessary packages\n",
    "\n",
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade pandas\n",
    "# !pip install --upgrade google-api-python-client\n",
    "# !pip install --upgrade seaborn\n",
    "# !pip install --upgrade networkx\n",
    "# !pip install --upgrade matplotlib\n",
    "# !pip install --upgrade pyspark\n",
    "# !pip install --upgrade pyspark_dist_explore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Imports\n",
    "\n",
    "from IPython.display import display, HTML, display_html #usefull to display wide tables\n",
    "from pyspark_dist_explore import Histogram, hist, distplot, pandas_histogram\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "#from pyspark.mllib.linalg import VectorUDT\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.sql import functions as F, types\n",
    "from pyspark.sql.functions import (explode, col)\n",
    "from pyspark.sql.functions import col, row_number, concat, lit\n",
    "from pyspark.sql.functions import trim\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, LongType, StringType\n",
    "from pyspark.sql.types import Row\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "import ast\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import seaborn as sns\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To better display plot from matplotlib\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://w266finalprojectajh6-m.c.w266-203601.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3d50db6e10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Spark Session - ensure that kernel is PySpark and not Python 2 or Python 3\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Spark Context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA & Discussion of Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin modeling an alogrithm for Click Through rate prediction, we should first examine the Criteo dataset that we will be using.  To do this, we will examine the initial format and structure of the dataset, the size of the dataset, examine it for missing values and outliers, and capture several summary statistics that will inform us of the distribution of the dataset.  To aid in our analysis, we will plot several graphs that will augment our understanding of the distribution of the dataset.\n",
    "\n",
    "Furthermore, as mentioned in our question formulation, we would like to use logistic regression as the main algorithm in our Click Through Rate prediction.  However, logistic regression models have several assumptions that must be met before they can be used.\n",
    "\n",
    "The assumptions for logistic regression include:\n",
    "\n",
    "1)  The outcome is a binary or dichotomous variable (e.g. “yes” or “no”, “positive” or “negative”, 1 or 0).\n",
    "\n",
    "2)  There is a linear relationship between the logit of the outcome and each predictor variables.  The logit function is $$logit(p) = log(p/(1-p))$$ where p is the probability of the outcome.\n",
    "\n",
    "3) Independence of observations.\n",
    "\n",
    "4) There is no multicollinearity among the independent variables.\n",
    "\n",
    "5) ??? There are a large number of observations.\n",
    "\n",
    "In the EDA that follows, we will show how the Criteo dataset meets the assumptions necessary for logistic regression, thus allowing us to comfortably use it as our prediction algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset is Large and Needs to be Parsed\n",
    "\n",
    "After loading the data and performing a row count, we can observe that the Criteo dataset is quite large.  It contains 45,840,617 rows (records). ??? reiterate what these are???\n",
    "\n",
    "Additionally, we can observe that each row in the dataset is initally a single, long string with tab-delimited columns.  These will need to be parsed before any further analysis can be performed.  We wrote code that performs this task, and separates all of these columns into numerical values or strings as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45840617\n"
     ]
    }
   ],
   "source": [
    "rawDF = sqlContext.read.text('gs://w261_final_project_ajh_bucket/data/train.txt').withColumnRenamed(\"value\", \"text\")\n",
    "rawDF.cache()\n",
    "rawDF_count = rawDF.count()\n",
    "print(rawDF_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(text='0\\t1\\t1\\t5\\t0\\t1382\\t4\\t15\\t2\\t181\\t1\\t2\\t\\t2\\t68fd1e64\\t80e26c9b\\tfb936136\\t7b4723c4\\t25c83c98\\t7e0ccccf\\tde7995b8\\t1f89b562\\ta73ee510\\ta8cd5504\\tb2cb9c98\\t37c9c164\\t2824a5f6\\t1adce6ef\\t8ba8b39a\\t891b62e7\\te5ba7672\\tf54016b9\\t21ddcdc9\\tb1252a9d\\t07b5194c\\t\\t3a171ecb\\tc5c50484\\te8b83407\\t9727dd16')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDF.printSchema()\n",
    "rawDF.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text: string]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullWithColsDF = rawDF.withColumn('tmp', split('text', '\\t')).\\\n",
    "                    select( col(\"tmp\").getItem(0).cast(\"double\").alias(\"label\")\n",
    "                    , col(\"tmp\").getItem(1).cast(\"double\").alias(\"int_1\")\n",
    "                    , col(\"tmp\").getItem(2).cast(\"double\").alias(\"int_2\")\n",
    "                    , col(\"tmp\").getItem(3).cast(\"double\").alias(\"int_3\")\n",
    "                    , col(\"tmp\").getItem(4).cast(\"double\").alias(\"int_4\")\n",
    "                    , col(\"tmp\").getItem(5).cast(\"double\").alias(\"int_5\")\n",
    "                    , col(\"tmp\").getItem(6).cast(\"double\").alias(\"int_6\")\n",
    "                    , col(\"tmp\").getItem(7).cast(\"double\").alias(\"int_7\")\n",
    "                    , col(\"tmp\").getItem(8).cast(\"double\").alias(\"int_8\")\n",
    "                    , col(\"tmp\").getItem(9).cast(\"double\").alias(\"int_9\")\n",
    "                    , col(\"tmp\").getItem(10).cast(\"double\").alias(\"int_10\")\n",
    "                    , col(\"tmp\").getItem(11).cast(\"double\").alias(\"int_11\")\n",
    "                    , col(\"tmp\").getItem(12).cast(\"double\").alias(\"int_12\")\n",
    "                    , col(\"tmp\").getItem(13).cast(\"double\").alias(\"int_13\")\n",
    "                    , col(\"tmp\").getItem(14).alias(\"categ_1\")\n",
    "                    , col(\"tmp\").getItem(15).alias(\"categ_2\")\n",
    "                    , col(\"tmp\").getItem(16).alias(\"categ_3\")\n",
    "                    , col(\"tmp\").getItem(17).alias(\"categ_4\")\n",
    "                    , col(\"tmp\").getItem(18).alias(\"categ_5\")\n",
    "                    , col(\"tmp\").getItem(19).alias(\"categ_6\")\n",
    "                    , col(\"tmp\").getItem(20).alias(\"categ_7\")\n",
    "                    , col(\"tmp\").getItem(21).alias(\"categ_8\")\n",
    "                    , col(\"tmp\").getItem(22).alias(\"categ_9\")\n",
    "                    , col(\"tmp\").getItem(23).alias(\"categ_10\")\n",
    "                    , col(\"tmp\").getItem(24).alias(\"categ_11\")\n",
    "                    , col(\"tmp\").getItem(25).alias(\"categ_12\")\n",
    "                    , col(\"tmp\").getItem(26).alias(\"categ_13\")\n",
    "                    , col(\"tmp\").getItem(27).alias(\"categ_14\")\n",
    "                    , col(\"tmp\").getItem(28).alias(\"categ_15\")\n",
    "                    , col(\"tmp\").getItem(29).alias(\"categ_16\")\n",
    "                    , col(\"tmp\").getItem(30).alias(\"categ_17\")\n",
    "                    , col(\"tmp\").getItem(31).alias(\"categ_18\")\n",
    "                    , col(\"tmp\").getItem(32).alias(\"categ_19\")\n",
    "                    , col(\"tmp\").getItem(33).alias(\"categ_20\")\n",
    "                    , col(\"tmp\").getItem(34).alias(\"categ_21\")\n",
    "                    , col(\"tmp\").getItem(35).alias(\"categ_22\")\n",
    "                    , col(\"tmp\").getItem(36).alias(\"categ_23\")\n",
    "                    , col(\"tmp\").getItem(37).alias(\"categ_24\")\n",
    "                    , col(\"tmp\").getItem(38).alias(\"categ_25\")\n",
    "                    , col(\"tmp\").getItem(39).alias(\"categ_26\")\n",
    "                    ).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 Numerical Columns, 26 Categorical Columns\n",
    "\n",
    "After parsing our data and separating the columns, we can see that there are 13 numerical columns and 26 categorical columns.  The numerical columns appear to be all integer values, while the categorical columns appear to be hash values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, int_1=1.0, int_2=1.0, int_3=5.0, int_4=0.0, int_5=1382.0, int_6=4.0, int_7=15.0, int_8=2.0, int_9=181.0, int_10=1.0, int_11=2.0, int_12=None, int_13=2.0, categ_1='68fd1e64', categ_2='80e26c9b', categ_3='fb936136', categ_4='7b4723c4', categ_5='25c83c98', categ_6='7e0ccccf', categ_7='de7995b8', categ_8='1f89b562', categ_9='a73ee510', categ_10='a8cd5504', categ_11='b2cb9c98', categ_12='37c9c164', categ_13='2824a5f6', categ_14='1adce6ef', categ_15='8ba8b39a', categ_16='891b62e7', categ_17='e5ba7672', categ_18='f54016b9', categ_19='21ddcdc9', categ_20='b1252a9d', categ_21='07b5194c', categ_22='', categ_23='3a171ecb', categ_24='c5c50484', categ_25='e8b83407', categ_26='9727dd16')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullWithColsDF.first()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for Calculating Statistics\n",
    "\n",
    "Below are several methods that we use to calculate summary statistics, and perform any necessary transformations.  They include:\n",
    "\n",
    "1) f_calc_stats, which calculates mean, minimum value, maximum value, standard deviation, variance, skewness of a column in a dataframe.\n",
    "2) f_check_null, which calculates count of null or NaN or empty for a column.\n",
    "3) f_display_stats_categ, which calculates count of unique values and empty strings for a column.\n",
    "4) f_display_stats_int, which calls other functions to get mean, minimum value, maximum value, standard deviation, variance, skewness, and number of nulls/NaN/empty values of a column in a dataframe.\n",
    "5) f_display_corr, which calculates the correlation and covariance of a variable against the label.\n",
    "6) f_covert_to_df, which converts an RDD to dataframe.\n",
    "7) f_cast_str_to_int, which converts integer columns formatted as strings to integers.\n",
    "8) f_remove_empty_string, which removes rows where at least one column has empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_calc_stats(data, column):\n",
    "    \"\"\"\n",
    "    Calculates mean, minimum value, maximum value, standard deviation, variance, skewness of a column in a dataframe.\n",
    "    Returns a list containing mean, minimum value, maximum value, standard deviation, variance, skewness\n",
    "    Arguments:\n",
    "        data         - dataframe on which we are calculating statistics.\n",
    "        column       - column for which statistics have to be calculated\n",
    "    Returns:\n",
    "        A list containing the mean, minimum value, maximum value, standard deviation, variance, skewness of the column.\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.agg(F.avg(data[column]), F.min(data[column]), F.max(data[column]),\n",
    "                    F.stddev_pop(data[column]),F.var_pop(data[column]),F.skewness(data[column])\n",
    "                   ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_check_null(data, column):\n",
    "    \"\"\"\n",
    "    Calculates count of null or NaN or empty for a column.\n",
    "    Returns an integer for the count  of null or NaN or empty for a column.\n",
    "    Arguments:\n",
    "        data         - dataframe on which we are calculating the metric.\n",
    "        column       - column for which the metric has to be calculated.\n",
    "    Returns:\n",
    "        An integer for the count where the column is null or NaN or empty.\n",
    "    \"\"\"\n",
    "    return data.filter( (data[column] ==\"\") |F.isnull(data[column])|F.isnan(data[column])\n",
    "                      ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking cardinality\n",
    "def f_display_stats_categ(df, inColList):\n",
    "    \"\"\"\n",
    "    Calculates count of unique values and empty strings for a column.\n",
    "    Displays the output as a HTML table.\n",
    "    Arguments:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        inColList  - list of column names for which we are calculating the metrics.\n",
    "    Returns:\n",
    "        Displays the output as a HTML table.\n",
    "    \"\"\"\n",
    "    dict1={}\n",
    "    for col in inColList:\n",
    "        cardinal_cnt = df.select([col]).distinct().count()\n",
    "        dict1[col]={\"Count_Unique_Vals\":cardinal_cnt}\n",
    "        dict1[col]['Count_Empty_String'] = str(df.filter(df[col] == \"\").count())\n",
    "\n",
    "    display(HTML(pd.DataFrame(dict1).T.to_html( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_display_stats_int(data):\n",
    "    \"\"\"\n",
    "    Calls other functions to get mean, minimum value, maximum value, standard deviation, variance, skewness, number of nulls/NaN/empty values of a column in a dataframe..\n",
    "    Displays the output as a HTML table.\n",
    "    Arguments:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        inColList  - list of column names for which we are calculating the metrics.\n",
    "    Returns:\n",
    "        Displays the output as a HTML table.\n",
    "    \"\"\"\n",
    "    dict1={}\n",
    "    countTotal = data.count()\n",
    "    for colname in [item[0] for item in data.dtypes if item[1].startswith('double')]:\n",
    "        list1=f_calc_stats(data,colname)\n",
    "        mean_val, min_val,max_val,stddev,var, skewness =list1[0]\n",
    "        count_nulls = f_check_null(data,colname)\n",
    "        dict1[colname]={}\n",
    "        dict1[colname]['mean'] = str(round(mean_val,2))\n",
    "        dict1[colname]['min'] = str(min_val)\n",
    "        dict1[colname]['max'] = str(max_val)\n",
    "        dict1[colname]['stddev'] = str(round(stddev,2))\n",
    "        dict1[colname]['var'] = str(round(var,2))\n",
    "        dict1[colname]['skewness'] = str(round(skewness,2))\n",
    "        dict1[colname]['nulls_nans'] = str(count_nulls)\n",
    "        dict1[colname]['pct_nulls_nans'] = str(round(float(count_nulls/countTotal*100),2))\n",
    "        dict1[colname]['count_empty_string'] = str(data.filter(data[colname] == \"\").count())\n",
    "        dict1[colname]['count_unique_values'] = str(data.select([colname]).distinct().count())\n",
    "   #Transposing dataframe to keep column names as rows\n",
    "    display(HTML(pd.DataFrame(dict1).T.to_html( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_display_corr(df, int_col_list):\n",
    "    \"\"\"\n",
    "    Calculates the correlation and covariance of a variable against the label\n",
    "    Arguments:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        inColList  - list of numeric column names for which we are calculating covariance and correlation.\n",
    "    Returns:\n",
    "        Displays the correlation and covariance as a HTML table.\n",
    "    \"\"\"\n",
    "    sampleDF=df.sample(seed=1, fraction=0.5, withReplacement=False)\n",
    "    dict1={}\n",
    "    for col in int_col_list:\n",
    "        corr = df.stat.corr('label',col)\n",
    "        cov = df.stat.cov('label',col)\n",
    "        dict1[col]={}\n",
    "        dict1[col][\"Corr\"]=corr\n",
    "        dict1[col][\"Cov\"]=cov\n",
    "    display(HTML(pd.DataFrame(dict1).T.to_html( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from RDD\n",
    "def f_covert_to_df(rdd, col_list):\n",
    "    \"\"\"\n",
    "    Converts a RDD to dataframe\n",
    "    Arguments:\n",
    "        rdd         - RDD to convert to dataframe.\n",
    "        col_list    - list of columns representing the schema.\n",
    "    Returns:\n",
    "        A dataframe.\n",
    "    \"\"\"\n",
    "    return rdd.map(lambda x: x.split('\\t')).toDF(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert integer columns to IntegerType from String\n",
    "def f_cast_str_to_int(df, integer_col_list):\n",
    "    \"\"\"\n",
    "    Convers integer columns formatted as strings to integers.\n",
    "    Arguments:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        integer_col_list    - list of columns representing the integer columns in the schema.\n",
    "    Returns:\n",
    "        A dataframe.\n",
    "    \"\"\"\n",
    "    for col in integer_col_list:\n",
    "        df = df.withColumn(col, df[col].cast(types.IntegerType()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes rows where at least one column has empty string\n",
    "def f_remove_empty_string(df, categ_col_list):\n",
    "    \"\"\"\n",
    "    Removes rows where at least one column has empty string\n",
    "    Arguments:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        col_list    - list of columns representing the schema.\n",
    "    Returns:\n",
    "        A dataframe.\n",
    "    \"\"\"\n",
    "    for categ_col in categ_col_list:\n",
    "        df = df.filter(df[categ_col] != \"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Below we generate summary statistics for our full dataset, which again is rather large at 45,840,617 rows / records.\n",
    "\n",
    "### Numerical Columns\n",
    "\n",
    "For our 13 numerical columns, we can observe that for many of the columns there are a substantial number of null / not-a-number (nan) values.  There are many columns for which this is around 20%, though the number reaches as high  as 76.5% for the column \"int_12\".  It should be noted that for the \"int_1\" column there a no null / nan values.\n",
    "\n",
    "The values in the numerical columns vary greatly in size and often in range.  For example, column int_11 has a mean value of 0.62, while column int_5 has a mean value of 18538.99, and ranges in value from 0 to 23,159,456.0.   This wide range for column int_5 suggests that it may have a number of outliers, which we will explore further graphically.\n",
    "\n",
    "Additionally, our target variable (denoted here as \"label\") shows that on average there is a 26% click-through rate in the Criteo data, which can be seen as the mean of the column given that the column can only take on binary values (0 or 1).\n",
    "\n",
    "Furthermore, some columns, in particular \"int_5\", exhibit very high skewness and variance.  We will explore this further graphically.\n",
    "\n",
    "### Categorical Columns\n",
    "\n",
    "For our 26 categorical columns, about half of them have no empty string / null values, while the other half contain a large amount.  This reaches as high as 34,955,073 empty string / null values for \"categ_22\".  Interesting is that many of the columns with higher number of unique values also have high numbers of empty string / null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45840617\n"
     ]
    }
   ],
   "source": [
    "print(rawDF_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelColList=[\"label\"]\n",
    "intColList=[\"int_1\", \"int_2\", \"int_3\", \"int_4\", \"int_5\", \"int_6\", \"int_7\"\\\n",
    "            , \"int_8\", \"int_9\", \"int_10\", \"int_11\", \"int_12\", \"int_13\"]\n",
    "categColList=[\"categ_1\", \"categ_2\", \"categ_3\", \"categ_4\", \"categ_5\", \"categ_6\"\\\n",
    "              , \"categ_7\", \"categ_8\", \"categ_9\", \"categ_10\", \"categ_11\", \"categ_12\"\\\n",
    "              , \"categ_13\", \"categ_14\", \"categ_15\", \"categ_16\", \"categ_17\", \"categ_18\"\\\n",
    "              , \"categ_19\", \"categ_20\", \"categ_21\", \"categ_22\", \"categ_23\", \"categ_24\", \"categ_25\", \"categ_26\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for numerical and categorical columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_empty_string</th>\n",
       "      <th>count_unique_values</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>nulls_nans</th>\n",
       "      <th>pct_nulls_nans</th>\n",
       "      <th>skewness</th>\n",
       "      <th>stddev</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_1</th>\n",
       "      <td>0</td>\n",
       "      <td>649</td>\n",
       "      <td>5775.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20793556</td>\n",
       "      <td>45.36</td>\n",
       "      <td>27.88</td>\n",
       "      <td>9.43</td>\n",
       "      <td>88.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_2</th>\n",
       "      <td>0</td>\n",
       "      <td>9364</td>\n",
       "      <td>257675.0</td>\n",
       "      <td>105.85</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>391.46</td>\n",
       "      <td>153239.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_3</th>\n",
       "      <td>0</td>\n",
       "      <td>14746</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>26.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9839447</td>\n",
       "      <td>21.46</td>\n",
       "      <td>81.49</td>\n",
       "      <td>397.97</td>\n",
       "      <td>158382.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_4</th>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>969.0</td>\n",
       "      <td>7.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9937369</td>\n",
       "      <td>21.68</td>\n",
       "      <td>4.09</td>\n",
       "      <td>8.79</td>\n",
       "      <td>77.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_5</th>\n",
       "      <td>0</td>\n",
       "      <td>476707</td>\n",
       "      <td>23159456.0</td>\n",
       "      <td>18538.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1183117</td>\n",
       "      <td>2.58</td>\n",
       "      <td>10.1</td>\n",
       "      <td>69394.6</td>\n",
       "      <td>4815610657.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_6</th>\n",
       "      <td>0</td>\n",
       "      <td>11618</td>\n",
       "      <td>431037.0</td>\n",
       "      <td>116.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10252328</td>\n",
       "      <td>22.37</td>\n",
       "      <td>184.98</td>\n",
       "      <td>382.57</td>\n",
       "      <td>146357.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_7</th>\n",
       "      <td>0</td>\n",
       "      <td>4142</td>\n",
       "      <td>56311.0</td>\n",
       "      <td>16.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982866</td>\n",
       "      <td>4.33</td>\n",
       "      <td>46.39</td>\n",
       "      <td>66.05</td>\n",
       "      <td>4362.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_8</th>\n",
       "      <td>0</td>\n",
       "      <td>1373</td>\n",
       "      <td>6047.0</td>\n",
       "      <td>12.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22773</td>\n",
       "      <td>0.05</td>\n",
       "      <td>66.16</td>\n",
       "      <td>16.69</td>\n",
       "      <td>278.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_9</th>\n",
       "      <td>0</td>\n",
       "      <td>7275</td>\n",
       "      <td>29019.0</td>\n",
       "      <td>106.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982866</td>\n",
       "      <td>4.33</td>\n",
       "      <td>8.52</td>\n",
       "      <td>220.28</td>\n",
       "      <td>48524.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_10</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20793556</td>\n",
       "      <td>45.36</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_11</th>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>231.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982866</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6.04</td>\n",
       "      <td>5.2</td>\n",
       "      <td>27.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_12</th>\n",
       "      <td>0</td>\n",
       "      <td>407</td>\n",
       "      <td>4008.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35071652</td>\n",
       "      <td>76.51</td>\n",
       "      <td>95.26</td>\n",
       "      <td>5.6</td>\n",
       "      <td>31.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_13</th>\n",
       "      <td>0</td>\n",
       "      <td>1376</td>\n",
       "      <td>7393.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9937369</td>\n",
       "      <td>21.68</td>\n",
       "      <td>105.35</td>\n",
       "      <td>16.21</td>\n",
       "      <td>262.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_Empty_String</th>\n",
       "      <th>Count_Unique_Vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categ_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_2</th>\n",
       "      <td>0</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_3</th>\n",
       "      <td>1559473</td>\n",
       "      <td>10131227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_4</th>\n",
       "      <td>1559473</td>\n",
       "      <td>2202608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_5</th>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_6</th>\n",
       "      <td>5540625</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_7</th>\n",
       "      <td>0</td>\n",
       "      <td>12517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_8</th>\n",
       "      <td>0</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_9</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_10</th>\n",
       "      <td>0</td>\n",
       "      <td>93145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_11</th>\n",
       "      <td>0</td>\n",
       "      <td>5683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_12</th>\n",
       "      <td>1559473</td>\n",
       "      <td>8351593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_13</th>\n",
       "      <td>0</td>\n",
       "      <td>3194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_14</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_15</th>\n",
       "      <td>0</td>\n",
       "      <td>14992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_16</th>\n",
       "      <td>1559473</td>\n",
       "      <td>5461306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_17</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_18</th>\n",
       "      <td>0</td>\n",
       "      <td>5652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_19</th>\n",
       "      <td>20172858</td>\n",
       "      <td>2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_20</th>\n",
       "      <td>20172858</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_21</th>\n",
       "      <td>1559473</td>\n",
       "      <td>7046547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_22</th>\n",
       "      <td>34955073</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_23</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_24</th>\n",
       "      <td>1559473</td>\n",
       "      <td>286181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_25</th>\n",
       "      <td>20172858</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_26</th>\n",
       "      <td>20172858</td>\n",
       "      <td>142572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Summary statistics for numerical and categorical columns\")\n",
    "f_display_stats_int(fullWithColsDF)\n",
    "f_display_stats_categ(fullWithColsDF, categColList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lack of Correlation or Multicollinearity\n",
    "\n",
    "As we can see below, there is at best weak correlation of the numerical columns with the target variable.  Column int_10 has the highest correlation at 0.19, which is still fairly weak.  In terms of negative correlation, the lowest correlation is 0.08 for columns int_5 and int_13, which is also very weak.\n",
    "\n",
    "Furthermore, in the covariance matrix below we can see that there is a lack of notable multicollineraity of the columns with each other.  The majority of the values in the covariance matrix are between 0.20 and 0.30.  There are many values close to 0, though there are a handful of values as high as 0.61 (between int_04 and int_13), and 0.69 (between int_07 and int_11).  While these two columns have the highest risk of multicollinearity, which would potentially bias the data, this covariance is not strong.\n",
    "\n",
    "Overall, our dataset can be said to not have multicollinearity, and thus meets this condition for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and Covariance w.r.t target field\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corr</th>\n",
       "      <th>Cov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>int_1</th>\n",
       "      <td>0.104088</td>\n",
       "      <td>0.326463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_2</th>\n",
       "      <td>0.044435</td>\n",
       "      <td>7.593410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_3</th>\n",
       "      <td>0.009770</td>\n",
       "      <td>1.505005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_4</th>\n",
       "      <td>-0.055718</td>\n",
       "      <td>-0.203014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_5</th>\n",
       "      <td>-0.076539</td>\n",
       "      <td>-2290.654047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_6</th>\n",
       "      <td>-0.055812</td>\n",
       "      <td>-8.296949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_7</th>\n",
       "      <td>0.085156</td>\n",
       "      <td>2.404850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_8</th>\n",
       "      <td>-0.027436</td>\n",
       "      <td>-0.199864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_9</th>\n",
       "      <td>0.024072</td>\n",
       "      <td>2.275556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_10</th>\n",
       "      <td>0.191717</td>\n",
       "      <td>0.049527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_11</th>\n",
       "      <td>0.158357</td>\n",
       "      <td>0.353649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_12</th>\n",
       "      <td>0.049629</td>\n",
       "      <td>0.059482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_13</th>\n",
       "      <td>-0.075477</td>\n",
       "      <td>-0.485725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Correlation and Covariance w.r.t target field\")\n",
    "f_display_corr(fullWithColsDF, intColList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numerical columns\n",
    "fullWithColsDF_int = fullWithColsDF.select(intColList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df = fullWithColsDF_int.na.fill(0)\n",
    "\n",
    "# Convert to vector column first\n",
    "vector_col = \"corr_features\"\n",
    "assembler = VectorAssembler(inputCols=correlation_df.columns, outputCol=vector_col)\n",
    "df_vector = assembler.transform(correlation_df).select(vector_col)\n",
    "\n",
    "# Get correlation matrix\n",
    "matrix = Correlation.corr(df_vector, vector_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int_01</th>\n",
       "      <th>int_02</th>\n",
       "      <th>int_03</th>\n",
       "      <th>int_04</th>\n",
       "      <th>int_05</th>\n",
       "      <th>int_06</th>\n",
       "      <th>int_07</th>\n",
       "      <th>int_08</th>\n",
       "      <th>int_09</th>\n",
       "      <th>int_10</th>\n",
       "      <th>int_11</th>\n",
       "      <th>int_12</th>\n",
       "      <th>int_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>int_01</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>0.038390</td>\n",
       "      <td>0.081069</td>\n",
       "      <td>-0.068993</td>\n",
       "      <td>-0.058315</td>\n",
       "      <td>0.477780</td>\n",
       "      <td>0.097048</td>\n",
       "      <td>0.068316</td>\n",
       "      <td>0.465176</td>\n",
       "      <td>0.304534</td>\n",
       "      <td>0.092164</td>\n",
       "      <td>0.005279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_02</th>\n",
       "      <td>0.034108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>-0.081530</td>\n",
       "      <td>-0.006260</td>\n",
       "      <td>-0.013320</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>-0.028035</td>\n",
       "      <td>-0.004732</td>\n",
       "      <td>0.035712</td>\n",
       "      <td>0.032760</td>\n",
       "      <td>-0.001294</td>\n",
       "      <td>-0.034543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_03</th>\n",
       "      <td>0.038390</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042022</td>\n",
       "      <td>-0.003412</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.045087</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>0.030109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_04</th>\n",
       "      <td>0.081069</td>\n",
       "      <td>-0.081530</td>\n",
       "      <td>0.042022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.094468</td>\n",
       "      <td>0.015560</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>0.504384</td>\n",
       "      <td>0.194364</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.063999</td>\n",
       "      <td>0.021092</td>\n",
       "      <td>0.612960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_05</th>\n",
       "      <td>-0.068993</td>\n",
       "      <td>-0.006260</td>\n",
       "      <td>-0.003412</td>\n",
       "      <td>-0.094468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>-0.056270</td>\n",
       "      <td>-0.109468</td>\n",
       "      <td>-0.068310</td>\n",
       "      <td>-0.148043</td>\n",
       "      <td>-0.115582</td>\n",
       "      <td>-0.020923</td>\n",
       "      <td>-0.054280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_06</th>\n",
       "      <td>-0.058315</td>\n",
       "      <td>-0.013320</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.015560</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027060</td>\n",
       "      <td>0.022175</td>\n",
       "      <td>0.186576</td>\n",
       "      <td>-0.124605</td>\n",
       "      <td>-0.039072</td>\n",
       "      <td>-0.012915</td>\n",
       "      <td>0.045574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_07</th>\n",
       "      <td>0.477780</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>-0.056270</td>\n",
       "      <td>-0.027060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077122</td>\n",
       "      <td>0.233840</td>\n",
       "      <td>0.251448</td>\n",
       "      <td>0.685523</td>\n",
       "      <td>0.093341</td>\n",
       "      <td>0.003478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_08</th>\n",
       "      <td>0.097048</td>\n",
       "      <td>-0.028035</td>\n",
       "      <td>0.045087</td>\n",
       "      <td>0.504384</td>\n",
       "      <td>-0.109468</td>\n",
       "      <td>0.022175</td>\n",
       "      <td>0.077122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206472</td>\n",
       "      <td>0.156661</td>\n",
       "      <td>0.139375</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>0.631302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_09</th>\n",
       "      <td>0.068316</td>\n",
       "      <td>-0.004732</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>0.194364</td>\n",
       "      <td>-0.068310</td>\n",
       "      <td>0.186576</td>\n",
       "      <td>0.233840</td>\n",
       "      <td>0.206472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075001</td>\n",
       "      <td>0.403943</td>\n",
       "      <td>0.045726</td>\n",
       "      <td>0.192788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_10</th>\n",
       "      <td>0.465176</td>\n",
       "      <td>0.035712</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>-0.148043</td>\n",
       "      <td>-0.124605</td>\n",
       "      <td>0.251448</td>\n",
       "      <td>0.156661</td>\n",
       "      <td>0.075001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.386369</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.023659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_11</th>\n",
       "      <td>0.304534</td>\n",
       "      <td>0.032760</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>0.063999</td>\n",
       "      <td>-0.115582</td>\n",
       "      <td>-0.039072</td>\n",
       "      <td>0.685523</td>\n",
       "      <td>0.139375</td>\n",
       "      <td>0.403943</td>\n",
       "      <td>0.386369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098713</td>\n",
       "      <td>0.010549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_12</th>\n",
       "      <td>0.092164</td>\n",
       "      <td>-0.001294</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>0.021092</td>\n",
       "      <td>-0.020923</td>\n",
       "      <td>-0.012915</td>\n",
       "      <td>0.093341</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>0.045726</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.098713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_13</th>\n",
       "      <td>0.005279</td>\n",
       "      <td>-0.034543</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>0.612960</td>\n",
       "      <td>-0.054280</td>\n",
       "      <td>0.045574</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>0.631302</td>\n",
       "      <td>0.192788</td>\n",
       "      <td>0.023659</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>-0.003453</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          int_01    int_02    int_03    int_04    int_05    int_06    int_07  \\\n",
       "int_01  1.000000  0.034108  0.038390  0.081069 -0.068993 -0.058315  0.477780   \n",
       "int_02  0.034108  1.000000 -0.008308 -0.081530 -0.006260 -0.013320  0.025422   \n",
       "int_03  0.038390 -0.008308  1.000000  0.042022 -0.003412  0.005079  0.000373   \n",
       "int_04  0.081069 -0.081530  0.042022  1.000000 -0.094468  0.015560  0.038521   \n",
       "int_05 -0.068993 -0.006260 -0.003412 -0.094468  1.000000  0.002158 -0.056270   \n",
       "int_06 -0.058315 -0.013320  0.005079  0.015560  0.002158  1.000000 -0.027060   \n",
       "int_07  0.477780  0.025422  0.000373  0.038521 -0.056270 -0.027060  1.000000   \n",
       "int_08  0.097048 -0.028035  0.045087  0.504384 -0.109468  0.022175  0.077122   \n",
       "int_09  0.068316 -0.004732 -0.000465  0.194364 -0.068310  0.186576  0.233840   \n",
       "int_10  0.465176  0.035712 -0.003791  0.157900 -0.148043 -0.124605  0.251448   \n",
       "int_11  0.304534  0.032760 -0.005823  0.063999 -0.115582 -0.039072  0.685523   \n",
       "int_12  0.092164 -0.001294 -0.001431  0.021092 -0.020923 -0.012915  0.093341   \n",
       "int_13  0.005279 -0.034543  0.030109  0.612960 -0.054280  0.045574  0.003478   \n",
       "\n",
       "          int_08    int_09    int_10    int_11    int_12    int_13  \n",
       "int_01  0.097048  0.068316  0.465176  0.304534  0.092164  0.005279  \n",
       "int_02 -0.028035 -0.004732  0.035712  0.032760 -0.001294 -0.034543  \n",
       "int_03  0.045087 -0.000465 -0.003791 -0.005823 -0.001431  0.030109  \n",
       "int_04  0.504384  0.194364  0.157900  0.063999  0.021092  0.612960  \n",
       "int_05 -0.109468 -0.068310 -0.148043 -0.115582 -0.020923 -0.054280  \n",
       "int_06  0.022175  0.186576 -0.124605 -0.039072 -0.012915  0.045574  \n",
       "int_07  0.077122  0.233840  0.251448  0.685523  0.093341  0.003478  \n",
       "int_08  1.000000  0.206472  0.156661  0.139375  0.028334  0.631302  \n",
       "int_09  0.206472  1.000000  0.075001  0.403943  0.045726  0.192788  \n",
       "int_10  0.156661  0.075001  1.000000  0.386369  0.084908  0.023659  \n",
       "int_11  0.139375  0.403943  0.386369  1.000000  0.098713  0.010549  \n",
       "int_12  0.028334  0.045726  0.084908  0.098713  1.000000 -0.003453  \n",
       "int_13  0.631302  0.192788  0.023659  0.010549 -0.003453  1.000000  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intColList_ex = intColList=[\"int_01\", \"int_02\", \"int_03\", \"int_04\", \"int_05\", \"int_06\", \"int_07\", \"int_08\", \"int_09\", \"int_10\", \"int_11\", \"int_12\", \"int_13\"]\n",
    "\n",
    "correlation_matrix = pd.DataFrame(matrix.collect()[0][\"pearson({})\".format(vector_col)].values)\n",
    "correlation_matrix = correlation_matrix.values.reshape(13, 13)\n",
    "correlation_matrix = pd.DataFrame(correlation_matrix, columns = intColList_ex, index = intColList_ex)\n",
    "print(\"Covariance Matrix\")\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs on Data Subset\n",
    "\n",
    "Below we show several histograms of the numerical columns to better observe their distributions.  Due to the inefficiency with which Spark plots graphs, we are using a 0.01% subset of the data for our graphs, which represents 4,635 rows.\n",
    "\n",
    "Virtually all of the columns have a large number of values of 0.  This raises the concern that the data in the numerical columns may not be as useful as we would like, as if many of the values in the columns are identical (at 0) they may lack predictive power.  All of the columns are also heavily right-skewed, likely due to the large numer of 0 values.  \n",
    "\n",
    "As seen earlier when numerically observing the range of values, many columns appear to have outliers, in particular column int_5 and int_3.  These outliers run the risk of inordinately influencing our alogrithm, thus lowering its predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, int_1: double, int_2: double, int_3: double, int_4: double, int_5: double, int_6: double, int_7: double, int_8: double, int_9: double, int_10: double, int_11: double, int_12: double, int_13: double, categ_1: string, categ_2: string, categ_3: string, categ_4: string, categ_5: string, categ_6: string, categ_7: string, categ_8: string, categ_9: string, categ_10: string, categ_11: string, categ_12: string, categ_13: string, categ_14: string, categ_15: string, categ_16: string, categ_17: string, categ_18: string, categ_19: string, categ_20: string, categ_21: string, categ_22: string, categ_23: string, categ_24: string, categ_25: string, categ_26: string]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = fullWithColsDF.sample(False, fraction=0.0001, seed = 1)\n",
    "sample_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4635"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to Pandas DataFrame\n",
    "pd_sample_df = sample_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0ee8ab38>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0d54eb00>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0d4460b8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0d39b630>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0d3e8ba8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0cf97128>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0d1626a0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0cdc4c50>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0cdc4c88>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0c80e748>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0cc80cc0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0cc10278>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0caf97f0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0ca6ed68>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0c939320>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f3d0c8a7898>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd_sample_df.hist(figsize = (15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Explanation - With Toy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have shown that we have met all the assumptions for logistic regression, we will proceed to use it for our Click Through Rate prediction task.\n",
    "\n",
    "Before we perform the prediction on the Criteo dataset, we will begin by explaining the methodology behind how to apply linear regression to a dataset with a mix of numerical and categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "??parse_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_rawDF = sqlContext.read.text('gs://w261_final_project_ajh_bucket/data/Toy_Example_Data.csv').withColumnRenamed(\"value\", \"text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_point_toy(point):\n",
    "    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n",
    "\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    values = point.split(',')[1:]\n",
    "    #values = filter(None, values)\n",
    "    indices = range(len(values))\n",
    "    return zip(indices,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, split\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, LongType, StringType, FloatType, DoubleType\n",
    "\n",
    "\n",
    "parse_point_toy_udf = udf(parse_point_toy, ArrayType(StructType([StructField('_1', LongType()),StructField('_2', StringType())])))\n",
    "\n",
    "def parse_toy_raw_df(raw_df):\n",
    "    \"\"\"Convert a DataFrame consisting of rows of comma separated text into labels and feature.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        raw_df: DataFrame containing the raw comma separated data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with 'label' and 'feature' columns.   \n",
    "  \n",
    "    \"\"\"\n",
    "    return (raw_df.select(split(raw_df.text,',').getItem(0).cast(\"double\").alias('label'),\n",
    "                         parse_point_toy_udf(raw_df.text).alias('features'))\n",
    "                        .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_create_one_hot_dict(input_df):\n",
    "    \"\"\"Creates a one-hot-encoder dictionary based on the input data.\n",
    "\n",
    "    Args:\n",
    "        input_df (DataFrame with 'features' column): A DataFrame where each row contains a list of\n",
    "            (featureID, value) tuples.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are\n",
    "            unique integers.\n",
    "    \"\"\"\n",
    "    input_distinct_feats_df = input_df.select(explode(input_df.features)).distinct()\n",
    "    input_ohe_dict = (input_distinct_feats_df\n",
    "                     .rdd\n",
    "                     .map(lambda r: tuple(r[0]))\n",
    "                     .zipWithIndex().collectAsMap())\n",
    "    return input_ohe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.mllib.linalg import VectorUDT\n",
    "\n",
    "def toy_ohe_udf_generator(ohe_dict_broadcast):\n",
    "    \"\"\"Generate a UDF that is setup to one-hot-encode rows with the given dictionary.\n",
    "\n",
    "    Note:\n",
    "        We'll reuse this function to generate a UDF that can one-hot-encode rows based on a\n",
    "        one-hot-encoding dictionary built from the training data.  Also, you should calculate\n",
    "        the number of features before calling the toy_one_hot_encoding function.\n",
    "\n",
    "    Args:\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "\n",
    "    Returns:\n",
    "        UserDefinedFunction: A UDF can be used in `DataFrame` `select` statement to call a\n",
    "            function on each row in a given column.  This UDF should call the toy_one_hot_encoding\n",
    "            function with the appropriate parameters.\n",
    "    \"\"\"\n",
    "    length = len(ohe_dict_broadcast.value)\n",
    "    return udf(lambda x: toy_one_hot_encoding(x, ohe_dict_broadcast, length), VectorUDT())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseVector\n",
    "def toy_one_hot_encoding(raw_feats, ohe_dict_broadcast, num_ohe_feats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "\n",
    "    Note:\n",
    "        You should ensure that the indices used to create a SparseVector are sorted.\n",
    "\n",
    "    Args:\n",
    "        raw_feats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sample_one)\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "        num_ohe_feats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length num_ohe_feats with indices equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats])\n",
    "    values = np.ones(len(raw_feats))\n",
    "    return SparseVector(num_ohe_feats,indices,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|1,4,6.37,2.85,0,A...|\n",
      "|1,5,7.84,3.91,1,S...|\n",
      "|1,2,5.5,2.82,1,St...|\n",
      "|1,3,8.43,1.92,1,E...|\n",
      "|0,4,6.29,3.43,1,F...|\n",
      "|1,4,8.36,1.91,1,J...|\n",
      "|1,4,6.56,3.61,1,B...|\n",
      "|0,2,7.98,1.96,0,F...|\n",
      "|1,4,5.52,2.85,0,C...|\n",
      "|1,3,9.15,3.34,0,F...|\n",
      "|1,4,6.14,1.82,1,M...|\n",
      "|0,4,6.87,1.75,1,J...|\n",
      "|1,3,6.9,3.84,1,Sp...|\n",
      "|1,2,6.53,1.57,0,A...|\n",
      "|1,4,9.98,3.66,1,S...|\n",
      "|0,2,9.78,2.81,1,M...|\n",
      "|0,2,5.1,3.32,1,St...|\n",
      "|1,3,5.32,3.62,1,A...|\n",
      "|1,2,7.16,3.72,1,C...|\n",
      "|0,3,6.07,2.29,0,R...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toy_rawDF.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806 94 100 1000\n"
     ]
    }
   ],
   "source": [
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "# Use randomSplit with weights and seed\n",
    "raw_toy_train_df, raw_toy_validation_df, raw_toy_test_df = toy_rawDF.randomSplit(weights, seed)\n",
    "\n",
    "# Cache and count the DataFrames\n",
    "n_toy_train = raw_toy_train_df.cache().count()\n",
    "n_toy_val = raw_toy_validation_df.cache().count()\n",
    "n_toy_test = raw_toy_test_df.cache().count()\n",
    "print(n_toy_train, n_toy_val, n_toy_test, str(n_toy_train + n_toy_val + n_toy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(label=0.0, features=[Row(_1=0, _2='2'), Row(_1=1, _2='5.01'), Row(_1=2, _2='2.41'), Row(_1=3, _2='1'), Row(_1=4, _2='Math'), Row(_1=5, _2='German')])\n"
     ]
    }
   ],
   "source": [
    "parsed_toy_train_df = parse_toy_raw_df(raw_toy_train_df)\n",
    "print(parsed_toy_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (explode, col)\n",
    "num_toy_categories = (parsed_toy_train_df\n",
    "                    .select(explode('features').alias('features'))\n",
    "                    .distinct()\n",
    "                    .select(col('features').getField('_1').alias('featureNumber'))\n",
    "                    .groupBy('featureNumber')\n",
    "                    .sum()\n",
    "                    .orderBy('featureNumber')\n",
    "                    .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(featureNumber=0, sum(featureNumber)=0), Row(featureNumber=1, sum(featureNumber)=402), Row(featureNumber=2, sum(featureNumber)=480), Row(featureNumber=3, sum(featureNumber)=6), Row(featureNumber=4, sum(featureNumber)=68), Row(featureNumber=5, sum(featureNumber)=85)]\n"
     ]
    }
   ],
   "source": [
    "print(num_toy_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682\n"
     ]
    }
   ],
   "source": [
    "toy_ohe_dict = toy_create_one_hot_dict(parsed_toy_train_df)\n",
    "num_toy_ohe_feats = len(toy_ohe_dict)\n",
    "print(num_toy_ohe_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(682,[82,113,117,...|  0.0|\n",
      "|(682,[23,82,185,3...|  0.0|\n",
      "|(682,[70,82,234,2...|  0.0|\n",
      "|(682,[82,355,418,...|  0.0|\n",
      "|(682,[82,462,576,...|  0.0|\n",
      "|(682,[176,378,418...|  0.0|\n",
      "|(682,[260,378,418...|  0.0|\n",
      "|(682,[378,414,447...|  0.0|\n",
      "|(682,[217,378,522...|  0.0|\n",
      "|(682,[235,378,536...|  0.0|\n",
      "|(682,[82,151,152,...|  0.0|\n",
      "|(682,[82,230,272,...|  0.0|\n",
      "|(682,[160,227,378...|  0.0|\n",
      "|(682,[82,153,160,...|  0.0|\n",
      "|(682,[131,182,348...|  0.0|\n",
      "|(682,[67,82,137,5...|  0.0|\n",
      "|(682,[32,137,250,...|  0.0|\n",
      "|(682,[82,137,154,...|  0.0|\n",
      "|(682,[117,267,330...|  0.0|\n",
      "|(682,[82,144,370,...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "[Row(features=SparseVector(682, {82: 1.0, 113: 1.0, 117: 1.0, 413: 1.0, 502: 1.0, 674: 1.0}), label=0.0)]\n"
     ]
    }
   ],
   "source": [
    "toy_ohe_dict_broadcast = sc.broadcast(toy_ohe_dict)\n",
    "toy_ohe_dict_udf =  toy_ohe_udf_generator(toy_ohe_dict_broadcast)\n",
    "toy_ohe_train_df =  parsed_toy_train_df.select(toy_ohe_dict_udf(parsed_toy_train_df.features).alias('features'),parsed_toy_train_df.label,)\n",
    "#ohe_train_df.show(1)                  \n",
    "\n",
    "print(toy_ohe_train_df.count())\n",
    "print(toy_ohe_train_df.show())\n",
    "print(toy_ohe_train_df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_ohe_train_rdd = toy_ohe_train_df \\\n",
    "                     .rdd \\\n",
    "                     .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PercentDropOut: 0.6625310173697271\n",
      "Mean: 0.6625310173697274\n",
      "Variance: 0.2235836683927612\n"
     ]
    }
   ],
   "source": [
    "meanDropOut = toy_ohe_train_rdd.map(lambda x: x[1]).mean()\n",
    "varDropOut = toy_ohe_train_rdd.map(lambda x: x[1]).variance()\n",
    "numDropOut = toy_ohe_train_rdd.map(lambda x: x[1]).sum()/toy_ohe_train_df.count()\n",
    "print(f\"PercentDropOut: {numDropOut}\")\n",
    "print(f\"Mean: {meanDropOut}\")\n",
    "print(f\"Variance: {varDropOut}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE = np.append(meanDropOut, np.zeros(num_toy_ohe_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientDescent(trainRDD, testRDD, wInit, nSteps = 20, \n",
    "                    learningRate = 0.01, verbose = False):\n",
    "    \"\"\"\n",
    "    Perform nSteps iterations of gradient descent and \n",
    "    track loss on a test and train set. Return lists of\n",
    "    test/train loss and the models themselves.\n",
    "    \"\"\"\n",
    "    # initialize lists to track model performance\n",
    "    train_history, test_history, model_history = [], [], []\n",
    "    \n",
    "    # perform n updates & compute test and train loss after each\n",
    "    model = wInit\n",
    "    for idx in range(nSteps):  \n",
    "        model = GDUpdate(trainRDD, model, learningRate)\n",
    "        training_loss = LogLoss(trainRDD, model) \n",
    "        test_loss = LogLoss(testRDD, model)\n",
    "        \n",
    "        # keep track of test/train loss for plotting\n",
    "        train_history.append(training_loss)\n",
    "        test_history.append(test_loss)\n",
    "        model_history.append(model)\n",
    "        \n",
    "        # console output if desired\n",
    "        if verbose:\n",
    "            print(\"----------\")\n",
    "            print(f\"STEP: {idx+1}\")\n",
    "            print(f\"training loss: {training_loss}\")\n",
    "            print(f\"test loss: {test_loss}\")\n",
    "            print(f\"Model: {[round(w,3) for w in model]}\")\n",
    "    return train_history, test_history, model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogLoss(dataRDD, W):\n",
    "    \"\"\"\n",
    "    Compute log loss.\n",
    "    Args:\n",
    "        dataRDD - each record is a tuple of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    \"\"\"\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1])).cache()\n",
    "    loss = augmentedData.map(lambda x: (-x[1] * np.log(sigmoid(W.dot(x[0]))) \\\n",
    "                                     - (1 - x[1]) * np.log(1 - sigmoid(W.dot(x[0])))) ).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GDUpdate(dataRDD, W, learningRate = 0.1):\n",
    "    \"\"\"\n",
    "    Perform one step/update on the Logistic regression.\n",
    "    Args:\n",
    "        dataRDD - records are tuples of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    Returns:\n",
    "        new_model - (array) updated coefficients, bias at index 0\n",
    "    \"\"\"\n",
    "    # add a bias 'feature' of 1 at index 0\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1])).cache()\n",
    "    grad = augmentedData.map(lambda x: np.dot(sigmoid(W.dot(x[0]) - x[1]),x[0])).mean()\n",
    "    new_model = W - learningRate * grad\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASELINE:  Loss = 0.6393586657271466\n",
      "----------\n",
      "STEP: 1\n",
      "Loss: 0.6405834992567013\n",
      "----------\n",
      "STEP: 2\n",
      "Loss: 0.643721487215732\n",
      "----------\n",
      "STEP: 3\n",
      "Loss: 0.6485545689963543\n",
      "----------\n",
      "STEP: 4\n",
      "Loss: 0.6548778151932536\n",
      "----------\n",
      "STEP: 5\n",
      "Loss: 0.6625012704436208\n"
     ]
    }
   ],
   "source": [
    "nSteps = 5\n",
    "model = BASELINE\n",
    "print(f\"BASELINE:  Loss = {LogLoss(toy_ohe_train_rdd,model)}\")\n",
    "for idx in range(nSteps):\n",
    "    print(\"----------\")\n",
    "    print(f\"STEP: {idx+1}\")\n",
    "    model = GDUpdate(toy_ohe_train_rdd, model)\n",
    "    loss = LogLoss(toy_ohe_train_rdd, model)\n",
    "    print(f\"Loss: {loss}\")\n",
    "  #  print(f\"Model: {[round(w,3) for w in model]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... trained 50 iterations in 622.8087210655212 seconds\n"
     ]
    }
   ],
   "source": [
    "# run 50 iterations (RUN THIS CELL AS IS)\n",
    "wInit = BASELINE\n",
    "trainRDD, testRDD = toy_ohe_train_rdd.randomSplit([0.8,0.2], seed = 2018)\n",
    "start = time.time()\n",
    "train, test, models = GradientDescent(trainRDD, testRDD, wInit, nSteps = 50)\n",
    "print(f\"\\n... trained {len(models)} iterations in {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_one_hot_encoding_v2(raw_feats, ohe_dict_broadcast, num_ohe_feats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "\n",
    "    Note:\n",
    "        You should ensure that the indices used to create a SparseVector are sorted, and that the\n",
    "        function handles missing features.\n",
    "\n",
    "    Args:\n",
    "        raw_feats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sample_one)\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "        num_ohe_feats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length num_ohe_feats with indices equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats if feat in ohe_dict_broadcast.value])\n",
    "    values = np.ones(len([feat for feat in raw_feats if feat in ohe_dict_broadcast.value] ))\n",
    "#     values = np.ones(len([raw_feats]))\n",
    "    return SparseVector(num_ohe_feats,indices,values)\n",
    "\n",
    "def toy_ohe_udf_generator_v2(ohe_dict_broadcast):\n",
    "    \"\"\"Generate a UDF that is setup to one-hot-encode rows with the given dictionary.\n",
    "\n",
    "    Note:\n",
    "        We'll reuse this function to generate a UDF that can one-hot-encode rows based on a\n",
    "        one-hot-encoding dictionary built from the training data.  Also, you should calculate\n",
    "        the number of features before calling the one_hot_encoding function.\n",
    "\n",
    "    Args:\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "\n",
    "    Returns:\n",
    "        UserDefinedFunction: A UDF can be used in `DataFrame` `select` statement to call a\n",
    "            function on each row in a given column.  This UDF should call the one_hot_encoding\n",
    "            function with the appropriate parameters.\n",
    "    \"\"\"\n",
    "    length = len(ohe_dict_broadcast.value)\n",
    "    return udf(lambda x: toy_one_hot_encoding_v2(x, ohe_dict_broadcast, length), VectorUDT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(682,[82,113,117,...|  0.0|\n",
      "|(682,[23,82,185,3...|  0.0|\n",
      "|(682,[70,82,234,2...|  0.0|\n",
      "|(682,[82,355,418,...|  0.0|\n",
      "|(682,[82,462,576,...|  0.0|\n",
      "|(682,[176,378,418...|  0.0|\n",
      "|(682,[260,378,418...|  0.0|\n",
      "|(682,[378,414,447...|  0.0|\n",
      "|(682,[217,378,522...|  0.0|\n",
      "|(682,[235,378,536...|  0.0|\n",
      "|(682,[82,151,152,...|  0.0|\n",
      "|(682,[82,230,272,...|  0.0|\n",
      "|(682,[160,227,378...|  0.0|\n",
      "|(682,[82,153,160,...|  0.0|\n",
      "|(682,[131,182,348...|  0.0|\n",
      "|(682,[67,82,137,5...|  0.0|\n",
      "|(682,[32,137,250,...|  0.0|\n",
      "|(682,[82,137,154,...|  0.0|\n",
      "|(682,[117,267,330...|  0.0|\n",
      "|(682,[82,144,370,...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "[Row(features=SparseVector(682, {82: 1.0, 113: 1.0, 117: 1.0, 413: 1.0, 502: 1.0, 674: 1.0}), label=0.0)]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "toy_ohe_dict_missing_udf = toy_ohe_udf_generator_v2(toy_ohe_dict_broadcast)\n",
    "\n",
    "toy_ohe_test_df = parsed_toy_train_df.select(toy_ohe_dict_missing_udf(parsed_toy_train_df.features).alias('features'), parsed_toy_train_df.label,).cache()\n",
    "print(toy_ohe_test_df.count())\n",
    "print(toy_ohe_test_df.show())\n",
    "print(toy_ohe_test_df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_ohe_test_rdd = toy_ohe_test_df \\\n",
    "                     .rdd \\\n",
    "                     .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6617741806149889"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSE = LogLoss(ohe_test_rdd, models)\n",
    "toy_train_model = np.asarray(models[-1])\n",
    "LogLoss(toy_ohe_test_rdd, toy_train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = [0.8, 0.1, 0.1]\n",
    "seed = 1\n",
    "\n",
    "# Use randomSplit with weights and seed\n",
    "rawTrainDF, rawValidationDF, rawTestDF = rawDF.randomSplit(weights, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#25% sampling due to memory errors\n",
    "rawTrainNewDF = rawTrainDF.sample(withReplacement=False, fraction=0.25, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawTrainNewDF.cache()\n",
    "rawValidationDF.cache()\n",
    "rawTestDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9167896"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawTrainNewDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainWithColsDF = rawTrainNewDF.withColumn('tmp', split('text', '\\t')).\\\n",
    "                    select( col(\"tmp\").getItem(0).cast(\"double\").alias(\"label\")\n",
    "                    , col(\"tmp\").getItem(1).cast(\"double\").alias(\"int_1\")\n",
    "                    , col(\"tmp\").getItem(2).cast(\"double\").alias(\"int_2\")\n",
    "                    , col(\"tmp\").getItem(3).cast(\"double\").alias(\"int_3\")\n",
    "                    , col(\"tmp\").getItem(4).cast(\"double\").alias(\"int_4\")\n",
    "                    , col(\"tmp\").getItem(5).cast(\"double\").alias(\"int_5\")\n",
    "                    , col(\"tmp\").getItem(6).cast(\"double\").alias(\"int_6\")\n",
    "                    , col(\"tmp\").getItem(7).cast(\"double\").alias(\"int_7\")\n",
    "                    , col(\"tmp\").getItem(8).cast(\"double\").alias(\"int_8\")\n",
    "                    , col(\"tmp\").getItem(9).cast(\"double\").alias(\"int_9\")\n",
    "                    , col(\"tmp\").getItem(10).cast(\"double\").alias(\"int_10\")\n",
    "                    , col(\"tmp\").getItem(11).cast(\"double\").alias(\"int_11\")\n",
    "                    , col(\"tmp\").getItem(12).cast(\"double\").alias(\"int_12\")\n",
    "                    , col(\"tmp\").getItem(13).cast(\"double\").alias(\"int_13\")\n",
    "                    , col(\"tmp\").getItem(14).alias(\"categ_1\")\n",
    "                    , col(\"tmp\").getItem(15).alias(\"categ_2\")\n",
    "                    , col(\"tmp\").getItem(16).alias(\"categ_3\")\n",
    "                    , col(\"tmp\").getItem(17).alias(\"categ_4\")\n",
    "                    , col(\"tmp\").getItem(18).alias(\"categ_5\")\n",
    "                    , col(\"tmp\").getItem(19).alias(\"categ_6\")\n",
    "                    , col(\"tmp\").getItem(20).alias(\"categ_7\")\n",
    "                    , col(\"tmp\").getItem(21).alias(\"categ_8\")\n",
    "                    , col(\"tmp\").getItem(22).alias(\"categ_9\")\n",
    "                    , col(\"tmp\").getItem(23).alias(\"categ_10\")\n",
    "                    , col(\"tmp\").getItem(24).alias(\"categ_11\")\n",
    "                    , col(\"tmp\").getItem(25).alias(\"categ_12\")\n",
    "                    , col(\"tmp\").getItem(26).alias(\"categ_13\")\n",
    "                    , col(\"tmp\").getItem(27).alias(\"categ_14\")\n",
    "                    , col(\"tmp\").getItem(28).alias(\"categ_15\")\n",
    "                    , col(\"tmp\").getItem(29).alias(\"categ_16\")\n",
    "                    , col(\"tmp\").getItem(30).alias(\"categ_17\")\n",
    "                    , col(\"tmp\").getItem(31).alias(\"categ_18\")\n",
    "                    , col(\"tmp\").getItem(32).alias(\"categ_19\")\n",
    "                    , col(\"tmp\").getItem(33).alias(\"categ_20\")\n",
    "                    , col(\"tmp\").getItem(34).alias(\"categ_21\")\n",
    "                    , col(\"tmp\").getItem(35).alias(\"categ_22\")\n",
    "                    , col(\"tmp\").getItem(36).alias(\"categ_23\")\n",
    "                    , col(\"tmp\").getItem(37).alias(\"categ_24\")\n",
    "                    , col(\"tmp\").getItem(38).alias(\"categ_25\")\n",
    "                    , col(\"tmp\").getItem(39).alias(\"categ_26\")\n",
    "                    ).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(raw_feats, ohe_dict_broadcast, num_ohe_feats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "\n",
    "    Note:\n",
    "        You should ensure that the indices used to create a SparseVector are sorted, and that the\n",
    "        function handles missing features.\n",
    "\n",
    "    Args:\n",
    "        raw_feats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sample_one)\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "        num_ohe_feats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length num_ohe_feats with indices equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    #indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats if feat in ohe_dict_broadcast.value])\n",
    "    indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats])\n",
    "    values = np.ones(len(raw_feats))\n",
    "    return SparseVector(num_ohe_feats,indices,values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ohe_udf_generator(ohe_dict_broadcast):\n",
    "    \"\"\"Generate a UDF that is setup to one-hot-encode rows with the given dictionary.\n",
    "\n",
    "    Note:\n",
    "        We'll reuse this function to generate a UDF that can one-hot-encode rows based on a\n",
    "        one-hot-encoding dictionary built from the training data.  Also, you should calculate\n",
    "        the number of features before calling the one_hot_encoding function.\n",
    "\n",
    "    Args:\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "\n",
    "    Returns:\n",
    "        UserDefinedFunction: A UDF can be used in `DataFrame` `select` statement to call a\n",
    "            function on each row in a given column.  This UDF should call the one_hot_encoding\n",
    "            function with the appropriate parameters.\n",
    "    \"\"\"\n",
    "    length = len(ohe_dict_broadcast.value)\n",
    "    return udf(lambda x: one_hot_encoding(x, ohe_dict_broadcast, length), VectorUDT())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_one_hot_dict(input_df):\n",
    "    \"\"\"Creates a one-hot-encoder dictionary based on the input data.\n",
    "\n",
    "    Args:\n",
    "        input_df (DataFrame with 'features' column): A DataFrame where each row contains a list of\n",
    "            (featureID, value) tuples.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are\n",
    "            unique integers.\n",
    "    \"\"\"\n",
    "    input_distinct_feats_df = input_df.select(explode(input_df.features)).distinct()\n",
    "    input_ohe_dict = (input_distinct_feats_df\n",
    "                     .rdd\n",
    "                     .map(lambda r: tuple(r[0]))\n",
    "                     .zipWithIndex().collectAsMap())\n",
    "    return input_ohe_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_point(point):\n",
    "    \"\"\" Converts a comma separated string into a list of (featureID, value) tuples.\n",
    "\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "\n",
    "    Arguments:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    values = point.split('\\t')[1:]\n",
    "    indices = range(len(values))\n",
    "    return zip(indices,values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_point_udf = udf(parse_point, ArrayType(StructType([StructField('_1', LongType()),StructField('_2', StringType())])))\n",
    "\n",
    "def parse_raw_df(raw_df):\n",
    "    \"\"\" Will transform a DataFrame with comma separated text into labels and feature.\n",
    "\n",
    "    Arguments:\n",
    "        raw_df (DataFrame with a 'text' column): DataFrame containing the raw comma separated data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with 'label' and 'feature' columns.   \n",
    "    \"\"\"\n",
    "    return (raw_df.select(split(raw_df.text,'\\t').getItem(0).cast(\"double\").alias('label'),\n",
    "                         parse_point_udf(raw_df.text).alias('features'))\n",
    "                        .cache())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed_train_df = parse_raw_df(rawTrainNewDF)\n",
    "parsed_validation_df = parse_raw_df(rawValidationDF)\n",
    "parsed_test_df = parse_raw_df(rawTestDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: array<struct<_1:bigint,_2:string>>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_train_df.cache()\n",
    "parsed_validation_df.cache()\n",
    "parsed_test_df.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9167896"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, features=[Row(_1=0, _2=''), Row(_1=1, _2='-1'), Row(_1=2, _2=''), Row(_1=3, _2=''), Row(_1=4, _2=''), Row(_1=5, _2=''), Row(_1=6, _2=''), Row(_1=7, _2=''), Row(_1=8, _2=''), Row(_1=9, _2=''), Row(_1=10, _2=''), Row(_1=11, _2=''), Row(_1=12, _2=''), Row(_1=13, _2='05db9164'), Row(_1=14, _2='38a947a1'), Row(_1=15, _2=''), Row(_1=16, _2=''), Row(_1=17, _2='25c83c98'), Row(_1=18, _2=''), Row(_1=19, _2='1d7560d9'), Row(_1=20, _2='64523cfa'), Row(_1=21, _2='7cc72ec2'), Row(_1=22, _2='3b08e48b'), Row(_1=23, _2='8951ed6a'), Row(_1=24, _2=''), Row(_1=25, _2='27dc8af3'), Row(_1=26, _2='b28479f6'), Row(_1=27, _2='4df46b2c'), Row(_1=28, _2=''), Row(_1=29, _2='2005abd1'), Row(_1=30, _2='40685634'), Row(_1=31, _2=''), Row(_1=32, _2=''), Row(_1=33, _2=''), Row(_1=34, _2=''), Row(_1=35, _2='32c7478e'), Row(_1=36, _2=''), Row(_1=37, _2=''), Row(_1=38, _2='')])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_categories = (parsed_train_df\n",
    "                    .select(explode('features').alias('features'))\n",
    "                    .distinct()\n",
    "                    .select(col('features').getField('_1').alias('featureNumber'))\n",
    "                    .groupBy('featureNumber')\n",
    "                    .sum()\n",
    "                    .orderBy('featureNumber')\n",
    "                    .collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(featureNumber=0, sum(featureNumber)=0),\n",
       " Row(featureNumber=1, sum(featureNumber)=6850),\n",
       " Row(featureNumber=2, sum(featureNumber)=11562),\n",
       " Row(featureNumber=3, sum(featureNumber)=876),\n",
       " Row(featureNumber=4, sum(featureNumber)=1024108),\n",
       " Row(featureNumber=5, sum(featureNumber)=36790),\n",
       " Row(featureNumber=6, sum(featureNumber)=16362),\n",
       " Row(featureNumber=7, sum(featureNumber)=5229),\n",
       " Row(featureNumber=8, sum(featureNumber)=41136),\n",
       " Row(featureNumber=9, sum(featureNumber)=99),\n",
       " Row(featureNumber=10, sum(featureNumber)=1470),\n",
       " Row(featureNumber=11, sum(featureNumber)=2915),\n",
       " Row(featureNumber=12, sum(featureNumber)=8088),\n",
       " Row(featureNumber=13, sum(featureNumber)=18954),\n",
       " Row(featureNumber=14, sum(featureNumber)=7868),\n",
       " Row(featureNumber=15, sum(featureNumber)=38094315),\n",
       " Row(featureNumber=16, sum(featureNumber)=11218608),\n",
       " Row(featureNumber=17, sum(featureNumber)=5185),\n",
       " Row(featureNumber=18, sum(featureNumber)=414),\n",
       " Row(featureNumber=19, sum(featureNumber)=232522),\n",
       " Row(featureNumber=20, sum(featureNumber)=12660),\n",
       " Row(featureNumber=21, sum(featureNumber)=63),\n",
       " Row(featureNumber=22, sum(featureNumber)=1409958),\n",
       " Row(featureNumber=23, sum(featureNumber)=124131),\n",
       " Row(featureNumber=24, sum(featureNumber)=52219896),\n",
       " Row(featureNumber=25, sum(featureNumber)=79600),\n",
       " Row(featureNumber=26, sum(featureNumber)=702),\n",
       " Row(featureNumber=27, sum(featureNumber)=350271),\n",
       " Row(featureNumber=28, sum(featureNumber)=42570808),\n",
       " Row(featureNumber=29, sum(featureNumber)=290),\n",
       " Row(featureNumber=30, sum(featureNumber)=151830),\n",
       " Row(featureNumber=31, sum(featureNumber)=65317),\n",
       " Row(featureNumber=32, sum(featureNumber)=128),\n",
       " Row(featureNumber=33, sum(featureNumber)=62487876),\n",
       " Row(featureNumber=34, sum(featureNumber)=612),\n",
       " Row(featureNumber=35, sum(featureNumber)=525),\n",
       " Row(featureNumber=36, sum(featureNumber)=4895424),\n",
       " Row(featureNumber=37, sum(featureNumber)=3552),\n",
       " Row(featureNumber=38, sum(featureNumber)=3163006)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an OHE dictionary from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9444472\n",
      "8499753\n"
     ]
    }
   ],
   "source": [
    "ctr_ohe_dict = create_one_hot_dict(parsed_train_df)\n",
    "num_ctr_ohe_feats = len(ctr_ohe_dict)\n",
    "print(num_ctr_ohe_feats)\n",
    "print(ctr_ohe_dict[(0, '')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply OHE to the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe_dict_broadcast = sc.broadcast(ctr_ohe_dict)\n",
    "ohe_dict_udf =  ohe_udf_generator(ohe_dict_broadcast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_train_df =  parsed_train_df.select(parsed_train_df.label, ohe_dict_udf(parsed_train_df.features).alias('features'))\n",
    "ohe_train_df.cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3f) Handling unseen features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding_v2(raw_feats, ohe_dict_broadcast, num_ohe_feats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "    The indices used to create a SparseVector are sorted. We consider previously seen features only.\n",
    "\n",
    "    Args:\n",
    "        raw_feats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sample_one)\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "        num_ohe_feats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length num_ohe_feats with indices equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats if feat in ohe_dict_broadcast.value])\n",
    "    values = np.ones(len([feat for feat in raw_feats if feat in ohe_dict_broadcast.value] ))\n",
    "    return SparseVector(num_ohe_feats,indices,values)\n",
    "\n",
    "def ohe_udf_generator_v2(ohe_dict_broadcast):\n",
    "    \"\"\"Generate a UDF that is setup to one-hot-encode rows with the given dictionary.\n",
    "\n",
    "    Args:\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "\n",
    "    Returns:\n",
    "        UserDefinedFunction: A UDF can be used in `DataFrame` `select` statement to call a\n",
    "            function on each row in a given column.  This UDF should call the one_hot_encoding\n",
    "            function with the appropriate parameters.\n",
    "    \"\"\"\n",
    "    length = len(ohe_dict_broadcast.value)\n",
    "    return udf(lambda x: one_hot_encoding_v2(x, ohe_dict_broadcast, length), VectorUDT())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe_dict_missing_udf = ohe_udf_generator_v2(ohe_dict_broadcast)\n",
    "\n",
    "ohe_test_df = parsed_test_df.select(parsed_test_df.label,  ohe_dict_missing_udf(parsed_test_df.features).alias('features')).cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4585725\n",
      "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0.0  |(9444472,[282595,424288,659969,706928,1320318,1557022,1557024,1604080,2264580,2406696,2500884,2736370,3113587,3255788,4010909,4058045,4153235,4200705,4578630,4814588,4909212,5146054,5524541,5808565,5855851,6091432,6233661,6611261,6705776,7602305,7884943,8074256,8358485,8405758,8452489,8499753,9161299,9350284,9350285],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ohe_test_df.count())\n",
    "print(ohe_test_df.show(1, truncate=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, features=SparseVector(9444472, {282595: 1.0, 424288: 1.0, 659969: 1.0, 706928: 1.0, 989935: 1.0, 1320318: 1.0, 1557022: 1.0, 1557023: 1.0, 1557024: 1.0, 2123496: 1.0, 2264580: 1.0, 2406696: 1.0, 2736370: 1.0, 3113587: 1.0, 3255788: 1.0, 4010909: 1.0, 4153235: 1.0, 4200705: 1.0, 4200706: 1.0, 4296513: 1.0, 4814588: 1.0, 4909212: 1.0, 5146054: 1.0, 5524541: 1.0, 5808565: 1.0, 5903003: 1.0, 6233661: 1.0, 6611261: 1.0, 6705776: 1.0, 6895237: 1.0, 7602305: 1.0, 8074256: 1.0, 8358485: 1.0, 8405758: 1.0, 8452489: 1.0, 8499753: 1.0, 9161299: 1.0, 9350284: 1.0, 9350285: 1.0}))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_train_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, features=SparseVector(9444472, {282595: 1.0, 424288: 1.0, 659969: 1.0, 706928: 1.0, 1320318: 1.0, 1557022: 1.0, 1557024: 1.0, 1604080: 1.0, 2264580: 1.0, 2406696: 1.0, 2500884: 1.0, 2736370: 1.0, 3113587: 1.0, 3255788: 1.0, 4010909: 1.0, 4058045: 1.0, 4153235: 1.0, 4200705: 1.0, 4578630: 1.0, 4814588: 1.0, 4909212: 1.0, 5146054: 1.0, 5524541: 1.0, 5808565: 1.0, 5855851: 1.0, 6091432: 1.0, 6233661: 1.0, 6611261: 1.0, 6705776: 1.0, 7602305: 1.0, 7884943: 1.0, 8074256: 1.0, 8358485: 1.0, 8405758: 1.0, 8452489: 1.0, 8499753: 1.0, 9161299: 1.0, 9350284: 1.0, 9350285: 1.0}))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_test_df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: CTR prediction and logloss evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4a) Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: -1.0743401568315318\n",
      "length of coefficients: 9444472\n",
      "[-2.3933778261858674, -2.3640446886325717, -2.3606764183110305, -2.356334312584443, -2.345188385115328]\n"
     ]
    }
   ],
   "source": [
    "standardization = True\n",
    "elastic_net_param = 0.0\n",
    "reg_param = .01\n",
    "max_iter = 5\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", predictionCol=\"prediction\", maxIter=max_iter, regParam=reg_param, elasticNetParam=elastic_net_param, fitIntercept=True,  standardization=standardization)\n",
    "\n",
    "lr_model_basic = lr.fit(ohe_train_df)\n",
    "\n",
    "print('intercept: {0}'.format(lr_model_basic.intercept))\n",
    "print('length of coefficients: {0}'.format(len(lr_model_basic.coefficients)))\n",
    "sorted_coefficients = sorted(lr_model_basic.coefficients)[:5]\n",
    "print(sorted_coefficients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4b) Log loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, log, col\n",
    "epsilon = 1e-16\n",
    "\n",
    "def add_log_loss(df):\n",
    "    \"\"\"Computes and adds a 'log_loss' column to a DataFrame using 'p' and 'label' columns.\n",
    "\n",
    "    Note:\n",
    "        log(0) is undefined, so when p is 0 we add a small value (epsilon) to it and when\n",
    "        p is 1 we subtract a small value (epsilon) from it.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame with 'p' and 'label' columns): A DataFrame with a probability column\n",
    "            'p' and a 'label' column that corresponds to y in the log loss formula.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with an additional column called 'log_loss' where 'log_loss' column contains the loss value as explained above.\n",
    "        \n",
    "        if y == 1:\n",
    "          return -log(epsilon + p) if p == 0 else -log(p)\n",
    "        elif y == 0:\n",
    "          return -log(1 - p + epsilon) if p == 1 else -log(1 - p)         \n",
    "    \"\"\"\n",
    "    \n",
    "    return (df.select(df['p'],df['label'],\n",
    "                when(df['label']==1.0,\n",
    "                     (when(df['p']!=0,-log(df['p'])))\n",
    "                     .otherwise(-log(epsilon + df['p'])))\n",
    "               .when(df['label']==0.0,\n",
    "                     (when(df['p']!=1.0,-log(1.0-df['p'])))\n",
    "                     .otherwise(-log(1.0 - df['p'] + epsilon)))\n",
    "               .alias(\"log_loss\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4c) Baseline log loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class one fraction = 0.256\n",
      "Baseline Train Logloss = 0.569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "class_one_frac_train = ohe_train_df.select(F.sum('label')).collect()[0][0] / ohe_train_df.count()\n",
    "\n",
    "ohe_train_df = (ohe_train_df.withColumn(\"p\", lit(class_one_frac_train)))\n",
    "print('Training class one fraction = {0:.3f}'.format(class_one_frac_train))\n",
    "\n",
    "log_loss_tr_base = (add_log_loss(ohe_train_df).select(F.sum('log_loss')).collect()[0][0] / ohe_train_df.count())\n",
    "print('Baseline Train Logloss = {0:.3f}\\n'.format(log_loss_tr_base))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from math import exp #  exp(-t) = e^-t\n",
    "\n",
    "def add_probability(df, model):\n",
    "    \"\"\"Adds a probability column ('p') to a DataFrame given a model\n",
    "    Args:\n",
    "        df for which probability has to be calculated.\n",
    "        model with which probability has to be calculated\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with an additional column called p where p column contains the probability for an observation given a list of features.\n",
    "    \n",
    "    \"\"\"\n",
    "    coefficients_broadcast = sc.broadcast(model.coefficients)\n",
    "    intercept = model.intercept\n",
    "\n",
    "    def get_p(features):\n",
    "        \"\"\"Calculate the probability for an observation given a list of features.\n",
    "\n",
    "        Note:\n",
    "            We'll bound our raw prediction between 20 and -20 for numerical purposes.\n",
    "\n",
    "        Args:\n",
    "            features: the features\n",
    "\n",
    "        Returns:\n",
    "            float: A probability between 0 and 1.\n",
    "        \"\"\"\n",
    "        # Compute the raw value\n",
    "        raw_prediction = features.dot(coefficients_broadcast.value)+intercept\n",
    "        # Bound the raw value between 20 and -20\n",
    "        raw_prediction = min(raw_prediction, 20)\n",
    "        raw_prediction = max(raw_prediction, -20)\n",
    "        return 1.0 / (1.0 + exp(-raw_prediction))\n",
    "\n",
    "    get_p_udf = udf(get_p, DoubleType())\n",
    "    return df.withColumn('p', get_p_udf('features'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|label|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |p                   |\n",
      "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|0.0  |(9444472,[282595,424288,659969,706928,989935,1320318,1557022,1557023,1557024,2123496,2264580,2406696,2736370,3113587,3255788,4010909,4153235,4200705,4200706,4296513,4814588,4909212,5146054,5524541,5808565,5903003,6233661,6611261,6705776,6895237,7602305,8074256,8358485,8405758,8452489,8499753,9161299,9350284,9350285],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]) |0.03797345839906773 |\n",
      "|0.0  |(9444472,[282595,424288,659969,706928,1232762,1320318,1557022,2264580,2406696,2736370,3113587,3255788,3538394,4010909,4153235,4200705,4200706,4437058,4578630,4767540,4814588,4909212,5146054,5288211,5524541,5808565,6233661,6611261,6705776,7225116,7602305,8074256,8358485,8405758,8452489,8499753,9161299,9350284,9350285],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.04075749313455165 |\n",
      "|0.0  |(9444472,[282595,424288,706928,894905,1320318,1557022,1557024,1604080,2264580,2264581,2406696,2500884,2547651,2736370,3113587,3160920,3255788,3538395,3821451,4010909,4153235,4200705,4814588,4909212,5146054,5524541,5808565,6091432,6233661,6611261,6705776,7602305,8074256,8358485,8405758,8452489,8499753,9350284,9350285],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0602396726700737  |\n",
      "|0.0  |(9444472,[235571,282595,424288,612985,659969,706928,1133915,1320318,1557022,1557024,1651141,2264580,2406696,2547651,2736370,3113587,3255788,3585421,4010909,4153235,4200705,4814588,4909212,5146054,5524541,5808565,5808566,6233661,6233662,6611261,6705776,7602305,8074256,8358485,8405758,8452489,8499753,9350284,9350285],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |0.058502976931045676|\n",
      "|0.0  |(9444472,[282595,424288,471465,706928,1131695,1320318,1557022,1651142,2264580,2406696,2594745,2736370,3113587,3255788,3585421,4010909,4153235,4200705,4767541,4814588,4909212,5146054,5524541,5808565,5808567,6233661,6280595,6611261,6705776,7602305,8074256,8358485,8405758,8452489,8499753,8688750,9161300,9350284,9350285],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.09565946274868178 |\n",
      "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_probability_model_basic = lambda df: add_probability(df, lr_model_basic)\n",
    "training_predictions = add_probability_model_basic(ohe_train_df).cache()\n",
    "training_predictions.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            features|                   p|\n",
      "+-----+--------------------+--------------------+\n",
      "|  0.0|(9444472,[282595,...| 0.03797345839906773|\n",
      "|  0.0|(9444472,[282595,...| 0.04075749313455165|\n",
      "|  0.0|(9444472,[282595,...|  0.0602396726700737|\n",
      "|  0.0|(9444472,[235571,...|0.058502976931045676|\n",
      "|  0.0|(9444472,[282595,...| 0.09565946274868178|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_predictions.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_results(df, model, baseline=None):\n",
    "    \"\"\"Calculates the log loss for the data given the model.\n",
    "\n",
    "    Note:\n",
    "        If baseline has a value the probability should be set to baseline before\n",
    "        the log loss is calculated.  Otherwise, use add_probability to add the\n",
    "        appropriate probabilities to the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame with 'label' and 'features' columns): A DataFrame containing\n",
    "            labels and features.\n",
    "        model (LogisticRegressionModel): A trained logistic regression model. This\n",
    "            can be None if baseline is set.\n",
    "        baseline (float): A baseline probability to use for the log loss calculation.\n",
    "\n",
    "    Returns:\n",
    "        float: Log loss for the data.\n",
    "    \"\"\"\n",
    "    with_probability_df = add_probability(df, model)\n",
    "    with_log_loss_df = add_log_loss(with_probability_df)\n",
    "    log_loss = (with_log_loss_df.select(F.sum('log_loss')).collect()[0][0] / with_log_loss_df.count())\n",
    "    return log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE Features Train Logloss:\n",
      "\tBaseline = 0.569\n",
      "\tLogReg = 0.335\n"
     ]
    }
   ],
   "source": [
    "log_loss_train_model_basic = evaluate_results(ohe_train_df, lr_model_basic)\n",
    "print ('OHE Features Train Logloss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(log_loss_tr_base, log_loss_train_model_basic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4f) Test dataset log loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss_val = evaluate_results(ohe_test_df, lr_model_basic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4948208635641279"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------------+\n",
      "|label|            features|                  p|\n",
      "+-----+--------------------+-------------------+\n",
      "|  0.0|(9444472,[282595,...| 0.0758689589710484|\n",
      "|  0.0|(9444472,[235572,...| 0.0400414644520275|\n",
      "|  0.0|(9444472,[47175,1...|0.10946047756433618|\n",
      "|  0.0|(9444472,[95297,4...|0.03827244701048019|\n",
      "|  0.0|(9444472,[424288,...|0.13123500785370285|\n",
      "+-----+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = add_probability_model_basic(ohe_test_df).cache()\n",
    "test_predictions.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|Probability| count|\n",
      "+-----------+------+\n",
      "|       0.66| 14531|\n",
      "|       0.07|149394|\n",
      "|       0.84|  6620|\n",
      "|       0.87|  5837|\n",
      "|        0.0|  4639|\n",
      "|       0.16|110505|\n",
      "|       0.93|  5016|\n",
      "|       0.89|  5339|\n",
      "|       0.18|100581|\n",
      "|        0.2| 92191|\n",
      "|       0.05|149975|\n",
      "|       0.39| 39944|\n",
      "|       0.79|  8147|\n",
      "|       0.72| 11352|\n",
      "|        0.7| 12170|\n",
      "|       0.24| 76046|\n",
      "|       0.54| 22642|\n",
      "|       0.21| 87714|\n",
      "|        0.1|139554|\n",
      "|       0.45| 31639|\n",
      "+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions.withColumn(\"Probability\",F.round(col(\"p\"),2) ).groupBy(\"Probability\").agg(F.count(lit(1)).alias(\"count\")).show()\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference :\n",
    "#RandomForest\n",
    "#https://github.com/apache/spark/blob/v2.2.0/mllib/src/main/scala/org/apache/spark/ml/classification/RandomForestClassifier.scala#L120\n",
    "#One hot encoding\n",
    "#https://towardsdatascience.com/machine-learning-with-pyspark-and-mllib-solving-a-binary-classification-problem-96396065d2aa\n",
    "#LR from scratch\n",
    "#https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac\n",
    "#https://www.programcreek.com/python/example/106727/pyspark.ml.feature.StringIndexer\n",
    "\n",
    "#pyspark.mllib vs pyspark.ml\n",
    "#https://stackoverflow.com/questions/41074182/cannot-convert-type-class-pyspark-ml-linalg-sparsevector-into-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}