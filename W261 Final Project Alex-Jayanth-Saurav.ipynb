{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference :\n",
    "#RandomForest\n",
    "#https://github.com/apache/spark/blob/v2.2.0/mllib/src/main/scala/org/apache/spark/ml/classification/RandomForestClassifier.scala#L120\n",
    "#One hot encoding\n",
    "#https://towardsdatascience.com/machine-learning-with-pyspark-and-mllib-solving-a-binary-classification-problem-96396065d2aa\n",
    "#LR from scratch\n",
    "#https://medium.com/@martinpella/logistic-regression-from-scratch-in-python-124c5636b8ac\n",
    "#https://www.programcreek.com/python/example/106727/pyspark.ml.feature.StringIndexer\n",
    "\n",
    "#pyspark.mllib vs pyspark.ml\n",
    "#https://stackoverflow.com/questions/41074182/cannot-convert-type-class-pyspark-ml-linalg-sparsevector-into-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade pandas\n",
    "# !pip install --upgrade google-api-python-client\n",
    "# !pip install --upgrade seaborn\n",
    "# !pip install --upgrade networkx\n",
    "# !pip install --upgrade matplotlib\n",
    "# !pip install --upgrade pyspark\n",
    "# !pip install --upgrade pyspark_dist_explore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, display_html #usefull to display wide tables\n",
    "from pyspark_dist_explore import Histogram, hist, distplot, pandas_histogram\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "#from pyspark.mllib.linalg import VectorUDT\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "from pyspark.sql import functions as F, types\n",
    "from pyspark.sql.functions import (explode, col)\n",
    "from pyspark.sql.functions import col, row_number, concat, lit\n",
    "from pyspark.sql.functions import trim\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import udf, split\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, LongType, StringType\n",
    "from pyspark.sql.types import Row\n",
    "from pyspark.sql.window import Window\n",
    "import ast\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://cluster-w261-m.c.w266-203603.internal:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f55aca76f60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "??parse_raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toy_rawDF = sqlContext.read.text('gs://bucket-w261-final/data/Toy_Example_Data.csv').withColumnRenamed(\"value\", \"text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|1,4,6.37,2.85,0,A...|\n",
      "|1,5,7.84,3.91,1,S...|\n",
      "|1,2,5.5,2.82,1,St...|\n",
      "|1,3,8.43,1.92,1,E...|\n",
      "|0,4,6.29,3.43,1,F...|\n",
      "|1,4,8.36,1.91,1,J...|\n",
      "|1,4,6.56,3.61,1,B...|\n",
      "|0,2,7.98,1.96,0,F...|\n",
      "|1,4,5.52,2.85,0,C...|\n",
      "|1,3,9.15,3.34,0,F...|\n",
      "|1,4,6.14,1.82,1,M...|\n",
      "|0,4,6.87,1.75,1,J...|\n",
      "|1,3,6.9,3.84,1,Sp...|\n",
      "|1,2,6.53,1.57,0,A...|\n",
      "|1,4,9.98,3.66,1,S...|\n",
      "|0,2,9.78,2.81,1,M...|\n",
      "|0,2,5.1,3.32,1,St...|\n",
      "|1,3,5.32,3.62,1,A...|\n",
      "|1,2,7.16,3.72,1,C...|\n",
      "|0,3,6.07,2.29,0,R...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toy_rawDF.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "806 94 100 1000\n"
     ]
    }
   ],
   "source": [
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "# Use randomSplit with weights and seed\n",
    "raw_train_df, raw_validation_df, raw_test_df = toy_rawDF.randomSplit(weights, seed)\n",
    "\n",
    "# Cache and count the DataFrames\n",
    "n_train = raw_train_df.cache().count()\n",
    "n_val = raw_validation_df.cache().count()\n",
    "n_test = raw_test_df.cache().count()\n",
    "print(n_train, n_val, n_test, str(n_train + n_val + n_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(text='0,2,5.01,2.41,1,Math,German')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed_train_df = parse_raw_df(raw_train_df)\n",
    "print(parsed_train_df.head())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Row(label=0.0, features=[Row(_1=0, _2='2'), Row(_1=1, _2='5.01'), Row(_1=2, _2='2.41'), Row(_1=3, _2='1'), Row(_1=4, _2='Math'), Row(_1=5, _2='German')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (explode, col)\n",
    "num_categories = (parsed_train_df\n",
    "                    .select(explode('features').alias('features'))\n",
    "                    .distinct()\n",
    "                    .select(col('features').getField('_1').alias('featureNumber'))\n",
    "                    .groupBy('featureNumber')\n",
    "                    .sum()\n",
    "                    .orderBy('featureNumber')\n",
    "                    .collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(num_categories)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Row(featureNumber=0, sum(featureNumber)=0), Row(featureNumber=1, sum(featureNumber)=402), Row(featureNumber=2, sum(featureNumber)=480), Row(featureNumber=3, sum(featureNumber)=6), Row(featureNumber=4, sum(featureNumber)=68), Row(featureNumber=5, sum(featureNumber)=85)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctr_ohe_dict = create_one_hot_dict(parsed_train_df)\n",
    "num_ctr_ohe_feats = len(ctr_ohe_dict)\n",
    "print(num_ctr_ohe_feats)\n",
    "ctr_ohe_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe_dict_broadcast = sc.broadcast(ctr_ohe_dict)\n",
    "ohe_dict_udf =  ohe_udf_generator(ohe_dict_broadcast)\n",
    "ohe_train_df =  parsed_train_df.select(parsed_train_df.label, ohe_dict_udf(parsed_train_df.features).alias('features'))\n",
    "#ohe_train_df.show(1)                  \n",
    "\n",
    "print(ohe_train_df.count())\n",
    "print(ohe_train_df.show())\n",
    "print(ohe_train_df.take(1))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "806\n",
    "+--------------------+-----+\n",
    "|            features|label|\n",
    "+--------------------+-----+\n",
    "|(682,[82,113,117,...|  0.0|\n",
    "|(682,[23,82,185,3...|  0.0|\n",
    "|(682,[70,82,234,2...|  0.0|\n",
    "|(682,[82,355,418,...|  0.0|\n",
    "|(682,[82,462,576,...|  0.0|\n",
    "|(682,[176,378,418...|  0.0|\n",
    "|(682,[260,378,418...|  0.0|\n",
    "|(682,[378,414,447...|  0.0|\n",
    "|(682,[217,378,522...|  0.0|\n",
    "|(682,[235,378,536...|  0.0|\n",
    "|(682,[82,151,152,...|  0.0|\n",
    "|(682,[82,230,272,...|  0.0|\n",
    "|(682,[160,227,378...|  0.0|\n",
    "|(682,[82,153,160,...|  0.0|\n",
    "|(682,[131,182,348...|  0.0|\n",
    "|(682,[67,82,137,5...|  0.0|\n",
    "|(682,[32,137,250,...|  0.0|\n",
    "|(682,[82,137,154,...|  0.0|\n",
    "|(682,[117,267,330...|  0.0|\n",
    "|(682,[82,144,370,...|  0.0|\n",
    "+--------------------+-----+\n",
    "only showing top 20 rows\n",
    "\n",
    "None\n",
    "[Row(features=SparseVector(682, {82: 1.0, 113: 1.0, 117: 1.0, 413: 1.0, 502: 1.0, 674: 1.0}), label=0.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe_train_rdd = ohe_train_df \\\n",
    "                     .rdd \\\n",
    "                     .cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meanDropOut = ohe_train_rdd.map(lambda x: x[0]).mean()\n",
    "varDropOut = ohe_train_rdd.map(lambda x: x[0]).variance()\n",
    "print(f\"Mean: {meanDropOut}\")\n",
    "print(f\"Variance: {varDropOut}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mean: 0.6625310173697274\n",
    "Variance: 0.2235836683927612"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASELINE = np.append(meanDropOut, np.zeros(ohe_train_df.count()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GradientDescent(trainRDD, testRDD, wInit, nSteps = 20, \n",
    "                    learningRate = 0.1, verbose = False):\n",
    "    \"\"\"\n",
    "    Perform nSteps iterations of OLS gradient descent and \n",
    "    track loss on a test and train set. Return lists of\n",
    "    test/train loss and the models themselves.\n",
    "    \"\"\"\n",
    "    # initialize lists to track model performance\n",
    "    train_history, test_history, model_history = [], [], []\n",
    "    \n",
    "    # perform n updates & compute test and train loss after each\n",
    "    model = wInit\n",
    "    for idx in range(nSteps):  \n",
    "        model = GDUpdate(trainRDD, model, learningRate)\n",
    "        training_loss = LogLoss(trainRDD, model) \n",
    "        test_loss = LogLoss(testRDD, model)\n",
    "        \n",
    "        # keep track of test/train loss for plotting\n",
    "        train_history.append(training_loss)\n",
    "        test_history.append(test_loss)\n",
    "        model_history.append(model)\n",
    "        \n",
    "        # console output if desired\n",
    "        if verbose:\n",
    "            print(\"----------\")\n",
    "            print(f\"STEP: {idx+1}\")\n",
    "            print(f\"training loss: {training_loss}\")\n",
    "            print(f\"test loss: {test_loss}\")\n",
    "            print(f\"Model: {[round(w,3) for w in model]}\")\n",
    "    return train_history, test_history, model_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotErrorCurves(trainLoss, testLoss, title = None):\n",
    "    \"\"\"\n",
    "    Helper function for plotting.\n",
    "    Args: trainLoss (list of MSE) , testLoss (list of MSE)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1,figsize = (16,8))\n",
    "    x = list(range(len(trainLoss)))[1:]\n",
    "    ax.plot(x, trainLoss[1:], 'k--', label='Training Loss')\n",
    "    ax.plot(x, testLoss[1:], 'r--', label='Test Loss')\n",
    "    ax.legend(loc='upper right', fontsize='x-large')\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Log loss')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LogLoss(dataRDD, W):\n",
    "    \"\"\"\n",
    "    Compute log loss.\n",
    "    Args:\n",
    "        dataRDD - each record is a tuple of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    \"\"\"\n",
    "    augmentedData = dataRDD.map(lambda x: (x[0], np.append([1.0], x[1])))\n",
    "    ################## YOUR CODE HERE ##################\n",
    "    loss = augmentedData.map(lambda x: (-x[0] * np.log(sigmoid(W.dot(x[1]))) - (1 - x[0]) * np.log(1 - sigmoid(W.dot(x[1])))) ).mean()\n",
    "    ################## (END) YOUR CODE ##################\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GDUpdate(dataRDD, W, learningRate = 0.1):\n",
    "    \"\"\"\n",
    "    Perform one OLS gradient descent step/update.\n",
    "    Args:\n",
    "        dataRDD - records are tuples of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    Returns:\n",
    "        new_model - (array) updated coefficients, bias at index 0\n",
    "    \"\"\"\n",
    "    # add a bias 'feature' of 1 at index 0\n",
    "    #augmentedData = dataRDD.map(lambda x: ( x[0], np.append([1.0], x[1]))).cache()\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1])).cache()\n",
    "    ################## YOUR CODE HERE ################# \n",
    "    #grad = augmentedData.map(lambda x: (sigmoid(W.dot(x[1])) - x[0])*x[1]).mean()\n",
    "    grad = augmentedData.map(lambda x: np.dot(sigmoid(W.dot(x[0]) - x[1]),x[0])).mean()\n",
    "    new_model = W - learningRate * grad\n",
    "    ################## (END) YOUR CODE ################# \n",
    "    \n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GradientDescent(trainRDD, testRDD, wInit, nSteps = 20, \n",
    "                    learningRate = 0.01, verbose = False):\n",
    "    \"\"\"\n",
    "    Perform nSteps iterations of OLS gradient descent and \n",
    "    track loss on a test and train set. Return lists of\n",
    "    test/train loss and the models themselves.\n",
    "    \"\"\"\n",
    "    # initialize lists to track model performance\n",
    "    train_history, test_history, model_history = [], [], []\n",
    "    \n",
    "    # perform n updates & compute test and train loss after each\n",
    "    model = wInit\n",
    "    for idx in range(nSteps):  \n",
    "        ############## YOUR CODE HERE #############\n",
    "        model = GDUpdate(trainRDD, model, learningRate)\n",
    "        training_loss = LogLoss(trainRDD, model) \n",
    "        test_loss = LogLoss(testRDD, model)\n",
    "        ############## (END) YOUR CODE #############\n",
    "        \n",
    "        # keep track of test/train loss for plotting\n",
    "        train_history.append(training_loss)\n",
    "        test_history.append(test_loss)\n",
    "        model_history.append(model)\n",
    "        \n",
    "        # console output if desired\n",
    "        if verbose:\n",
    "            print(\"----------\")\n",
    "            print(f\"STEP: {idx+1}\")\n",
    "            print(f\"training loss: {training_loss}\")\n",
    "            print(f\"test loss: {test_loss}\")\n",
    "            print(f\"Model: {[round(w,3) for w in model]}\")\n",
    "    return train_history, test_history, model_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotErrorCurves(trainLoss, testLoss, title = None):\n",
    "    \"\"\"\n",
    "    Helper function for plotting.\n",
    "    Args: trainLoss (list of MSE) , testLoss (list of MSE)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1,figsize = (16,8))\n",
    "    x = list(range(len(trainLoss)))[1:]\n",
    "    ax.plot(x, trainLoss[1:], 'k--', label='Training Loss')\n",
    "    ax.plot(x, testLoss[1:], 'r--', label='Test Loss')\n",
    "    ax.legend(loc='upper right', fontsize='x-large')\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nSteps = 5\n",
    "model = BASELINE\n",
    "print(f\"BASELINE:  Loss = {LogLoss(ohe_train_rdd,model)}\")\n",
    "for idx in range(nSteps):\n",
    "    print(\"----------\")\n",
    "    print(f\"STEP: {idx+1}\")\n",
    "    model = GDUpdate(ohe_train_rdd, model)\n",
    "    loss = LogLoss(ohe_train_rdd, model)\n",
    "    print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BASELINE:  Loss = 0.6393586657271466\n",
    "----------\n",
    "STEP: 1\n",
    "Loss: 0.6405834992567013\n",
    "----------\n",
    "STEP: 2\n",
    "Loss: 0.643721487215732\n",
    "----------\n",
    "STEP: 3\n",
    "Loss: 0.6485545689963543\n",
    "----------\n",
    "STEP: 4\n",
    "Loss: 0.6548778151932536\n",
    "----------\n",
    "STEP: 5\n",
    "Loss: 0.6625012704436208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run 20 iterations (RUN THIS CELL AS IS)\n",
    "wInit = BASELINE\n",
    "trainRDD, testRDD = ohe_train_rdd.randomSplit([0.8,0.2], seed = 2018)\n",
    "start = time.time()\n",
    "train, test, models = GradientDescent(trainRDD, testRDD, wInit, nSteps = 20)\n",
    "print(f\"\\n... trained {len(models)} iterations in {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "... trained 20 iterations in 321.46514868736267 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take a look (RUN THIS CELL AS IS)\n",
    "plotErrorCurves(train, test, title = 'Logistic Regression' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Toy Logistic Regression](img/Toy_Example_Logistic_Regression.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA & Discussion of Challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_calc_stats(data, column):\n",
    "    \"\"\"\n",
    "    Calculates mean, minimum value, maximum value, standard deviation, variance, skewness of a column in a dataframe.\n",
    "    Returns a list containing mean, minimum value, maximum value, standard deviation, variance, skewness\n",
    "    Args:\n",
    "        data         - dataframe on which we are calculating statistics.\n",
    "        column       - column for which statistics have to be calculated\n",
    "    Returns:\n",
    "        A list containing the mean, minimum value, maximum value, standard deviation, variance, skewness of the column.\n",
    "    \"\"\"\n",
    "    \n",
    "    return data.agg(F.avg(data[column]), F.min(data[column]), F.max(data[column]),\n",
    "                    F.stddev_pop(data[column]),F.var_pop(data[column]),F.skewness(data[column])\n",
    "                   ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_check_null(data, column):\n",
    "    \"\"\"\n",
    "    Calculates count of null or NaN or empty for a column.\n",
    "    Returns an integer for the count  of null or NaN or empty for a column.\n",
    "    Args:\n",
    "        data         - dataframe on which we are calculating the metric.\n",
    "        column       - column for which the metric has to be calculated.\n",
    "    Returns:\n",
    "        An integer for the count where the column is null or NaN or empty.\n",
    "    \"\"\"\n",
    "    return data.filter( (data[column] ==\"\") |F.isnull(data[column])|F.isnan(data[column])\n",
    "                      ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checking cardinality\n",
    "def f_display_stats_categ(df, inColList):\n",
    "    \"\"\"\n",
    "    Calculates count of unique values and empty strings for a column.\n",
    "    Displays the output as a HTML table.\n",
    "    Args:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        inColList  - list of column names for which we are calculating the metrics.\n",
    "    Returns:\n",
    "        Displays the output as a HTML table.\n",
    "    \"\"\"\n",
    "    dict1={}\n",
    "    for col in inColList:\n",
    "        cardinal_cnt = df.select([col]).distinct().count()\n",
    "        dict1[col]={\"Count_Unique_Vals\":cardinal_cnt}\n",
    "        dict1[col]['Count_Empty_String'] = str(df.filter(df[col] == \"\").count())\n",
    "\n",
    "    display(HTML(pd.DataFrame(dict1).T.to_html( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_display_stats_int(data):\n",
    "    \"\"\"\n",
    "    Calls other functions to get mean, minimum value, maximum value, standard deviation, variance, skewness, number of nulls/NaN/empty values of a column in a dataframe..\n",
    "    Displays the output as a HTML table.\n",
    "    \n",
    "    Args:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        inColList  - list of column names for which we are calculating the metrics.\n",
    "        \n",
    "    Returns:\n",
    "        Displays the output as a HTML table.\n",
    "    \"\"\"\n",
    "    dict1={}\n",
    "    countTotal = data.count()\n",
    "    for colname in [item[0] for item in data.dtypes if item[1].startswith('double')]:\n",
    "        list1=f_calc_stats(data,colname)\n",
    "        mean_val, min_val,max_val,stddev,var, skewness =list1[0]\n",
    "        count_nulls = f_check_null(data,colname)\n",
    "        dict1[colname]={}\n",
    "        dict1[colname]['mean'] = str(round(mean_val,2))\n",
    "        dict1[colname]['min'] = str(min_val)\n",
    "        dict1[colname]['max'] = str(max_val)\n",
    "        dict1[colname]['stddev'] = str(round(stddev,2))\n",
    "        dict1[colname]['var'] = str(round(var,2))\n",
    "        dict1[colname]['skewness'] = str(round(skewness,2))\n",
    "        dict1[colname]['nulls_nans'] = str(count_nulls)\n",
    "        dict1[colname]['pct_nulls_nans'] = str(round(float(count_nulls/countTotal*100),2))\n",
    "        dict1[colname]['count_empty_string'] = str(data.filter(data[colname] == \"\").count())\n",
    "        dict1[colname]['count_unique_values'] = str(data.select([colname]).distinct().count())\n",
    "        dict1[colname]['count'] = 'N/A'\n",
    "    dict1['TOTAL']={}\n",
    "    dict1['TOTAL']['count'] = str(data.count())\n",
    "   #Transposing dataframe to keep column names as rows\n",
    "    display(HTML(pd.DataFrame(dict1).T.to_html( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_display_corr(df, int_col_list):\n",
    "    \"\"\"\n",
    "    Calculates the correlation and covariance of a variable against the label\n",
    "    \n",
    "    Args:\n",
    "        df         - dataframe on which we are calculating the metric.\n",
    "        inColList  - list of numeric column names for which we are calculating covariance and correlation.\n",
    "        \n",
    "    Returns:\n",
    "        Displays the correlation and covariance as a HTML table.\n",
    "    \"\"\"\n",
    "    sampleDF=df.sample(seed=1, fraction=0.5, withReplacement=False)\n",
    "    dict1={}\n",
    "    for col in int_col_list:\n",
    "        corr = trainWithColsDF.stat.corr('label',col)\n",
    "        cov = trainWithColsDF.stat.cov('label',col)\n",
    "        dict1[col]={}\n",
    "        dict1[col][\"Corr\"]=corr\n",
    "        dict1[col][\"Cov\"]=cov\n",
    "    display(HTML(pd.DataFrame(dict1).T.to_html( )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dataframe from RDD\n",
    "def f_covert_to_df(rdd, col_list):\n",
    "    \"\"\"\n",
    "    Converts a RDD to dataframe\n",
    "    \n",
    "    Args:\n",
    "        rdd         - RDD to convert to dataframe.\n",
    "        col_list    - list of columns representing the schema.\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe.\n",
    "    \"\"\"\n",
    "    return rdd.map(lambda x: x.split('\\t')).toDF(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert integer columns to IntegerType from String\n",
    "def f_cast_str_to_int(df, integer_col_list):\n",
    "    \"\"\"\n",
    "    Converts a RDD to dataframe\n",
    "    \n",
    "    Args:\n",
    "        rdd         - RDD to convert to dataframe.\n",
    "        col_list    - list of columns representing the schema.\n",
    "        \n",
    "    Returns:\n",
    "        A dataframe.\n",
    "    \"\"\"\n",
    "    for col in integer_col_list:\n",
    "        df = df.withColumn(col, df[col].cast(types.IntegerType()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removing rows where at least one column has empty string\n",
    "def f_remove_empty_string(df, categ_col_list):\n",
    "    for categ_col in categ_col_list:\n",
    "        df = df.filter(df[categ_col] != \"\")\n",
    "        #df = df.filter(col(categ_col) != \"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelColList=[\"clicked_0_1\"]\n",
    "intColList=[\"int_1\", \"int_2\", \"int_3\", \"int_4\", \"int_5\", \"int_6\", \"int_7\", \"int_8\", \"int_9\", \"int_10\", \"int_11\", \"int_12\", \"int_13\"]\n",
    "categColList=[\"categ_1\", \"categ_2\", \"categ_3\", \"categ_4\", \"categ_5\", \"categ_6\", \"categ_7\", \"categ_8\", \"categ_9\", \"categ_10\", \"categ_11\", \"categ_12\", \"categ_13\", \"categ_14\", \"categ_15\", \"categ_16\", \"categ_17\", \"categ_18\", \"categ_19\", \"categ_20\", \"categ_21\", \"categ_22\", \"categ_23\", \"categ_24\", \"categ_25\", \"categ_26\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_point(point):\n",
    "    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n",
    "\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    values = point.split('\\t')[1:]\n",
    "    indices = range(len(values))\n",
    "    return zip(indices,values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parse_point_udf = udf(parse_point, ArrayType(StructType([StructField('_1', LongType()),StructField('_2', StringType())])))\n",
    "\n",
    "def parse_raw_df(raw_df):\n",
    "    \"\"\"Convert a DataFrame consisting of rows of comma separated text into labels and feature.\n",
    "\n",
    "    Args:\n",
    "        raw_df (DataFrame with a 'text' column): DataFrame containing the raw comma separated data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with 'label' and 'feature' columns.   \n",
    "    \"\"\"\n",
    "    return (raw_df.select(split(raw_df.text,'\\t').getItem(0).cast(\"double\").alias('label'),\n",
    "                         parse_point_udf(raw_df.text).alias('features'))\n",
    "                        .cache())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawDF = sqlContext.read.text('gs://bucket-w261-final/data/train.txt').withColumnRenamed(\"value\", \"text\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA Stats on Full Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text: string]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDF.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45840617\n"
     ]
    }
   ],
   "source": [
    "rawDF_count = rawDF.count()\n",
    "print(rawDF_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDF.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullWithColsDF=rawDF.withColumn('tmp', split('text', '\\t')).select( col(\"tmp\").getItem(0).cast(\"double\").alias(\"label\")\n",
    "                                                                            ,col(\"tmp\").getItem(1).cast(\"double\").alias(\"int_1\")\n",
    "                                                                            ,col(\"tmp\").getItem(2).cast(\"double\").alias(\"int_2\")\n",
    "                                                                            ,col(\"tmp\").getItem(3).cast(\"double\").alias(\"int_3\")\n",
    "                                                                            ,col(\"tmp\").getItem(4).cast(\"double\").alias(\"int_4\")\n",
    "                                                                            ,col(\"tmp\").getItem(5).cast(\"double\").alias(\"int_5\")\n",
    "                                                                            ,col(\"tmp\").getItem(6).cast(\"double\").alias(\"int_6\")\n",
    "                                                                            ,col(\"tmp\").getItem(7).cast(\"double\").alias(\"int_7\")\n",
    "                                                                            ,col(\"tmp\").getItem(8).cast(\"double\").alias(\"int_8\")\n",
    "                                                                            ,col(\"tmp\").getItem(9).cast(\"double\").alias(\"int_9\")\n",
    "                                                                            ,col(\"tmp\").getItem(10).cast(\"double\").alias(\"int_10\")\n",
    "                                                                            ,col(\"tmp\").getItem(11).cast(\"double\").alias(\"int_11\")\n",
    "                                                                            ,col(\"tmp\").getItem(12).cast(\"double\").alias(\"int_12\")\n",
    "                                                                            ,col(\"tmp\").getItem(13).cast(\"double\").alias(\"int_13\")\n",
    "                                                                            ,col(\"tmp\").getItem(14).alias(\"categ_1\")\n",
    "                                                                            ,col(\"tmp\").getItem(15).alias(\"categ_2\")\n",
    "                                                                            ,col(\"tmp\").getItem(16).alias(\"categ_3\")\n",
    "                                                                            ,col(\"tmp\").getItem(17).alias(\"categ_4\")\n",
    "                                                                            ,col(\"tmp\").getItem(18).alias(\"categ_5\")\n",
    "                                                                            ,col(\"tmp\").getItem(19).alias(\"categ_6\")\n",
    "                                                                            ,col(\"tmp\").getItem(20).alias(\"categ_7\")\n",
    "                                                                            ,col(\"tmp\").getItem(21).alias(\"categ_8\")\n",
    "                                                                            ,col(\"tmp\").getItem(22).alias(\"categ_9\")\n",
    "                                                                            ,col(\"tmp\").getItem(23).alias(\"categ_10\")\n",
    "                                                                            ,col(\"tmp\").getItem(24).alias(\"categ_11\")\n",
    "                                                                            ,col(\"tmp\").getItem(25).alias(\"categ_12\")\n",
    "                                                                            ,col(\"tmp\").getItem(26).alias(\"categ_13\")\n",
    "                                                                            ,col(\"tmp\").getItem(27).alias(\"categ_14\")\n",
    "                                                                            ,col(\"tmp\").getItem(28).alias(\"categ_15\")\n",
    "                                                                            ,col(\"tmp\").getItem(29).alias(\"categ_16\")\n",
    "                                                                            ,col(\"tmp\").getItem(30).alias(\"categ_17\")\n",
    "                                                                            ,col(\"tmp\").getItem(31).alias(\"categ_18\")\n",
    "                                                                            ,col(\"tmp\").getItem(32).alias(\"categ_19\")\n",
    "                                                                            ,col(\"tmp\").getItem(33).alias(\"categ_20\")\n",
    "                                                                            ,col(\"tmp\").getItem(34).alias(\"categ_21\")\n",
    "                                                                            ,col(\"tmp\").getItem(35).alias(\"categ_22\")\n",
    "                                                                            ,col(\"tmp\").getItem(36).alias(\"categ_23\")\n",
    "                                                                            ,col(\"tmp\").getItem(37).alias(\"categ_24\")\n",
    "                                                                            ,col(\"tmp\").getItem(38).alias(\"categ_25\")\n",
    "                                                                            ,col(\"tmp\").getItem(39).alias(\"categ_26\")\n",
    "                                                            ).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(text='0\\t1\\t1\\t5\\t0\\t1382\\t4\\t15\\t2\\t181\\t1\\t2\\t\\t2\\t68fd1e64\\t80e26c9b\\tfb936136\\t7b4723c4\\t25c83c98\\t7e0ccccf\\tde7995b8\\t1f89b562\\ta73ee510\\ta8cd5504\\tb2cb9c98\\t37c9c164\\t2824a5f6\\t1adce6ef\\t8ba8b39a\\t891b62e7\\te5ba7672\\tf54016b9\\t21ddcdc9\\tb1252a9d\\t07b5194c\\t\\t3a171ecb\\tc5c50484\\te8b83407\\t9727dd16')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDF.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, int_1=1.0, int_2=1.0, int_3=5.0, int_4=0.0, int_5=1382.0, int_6=4.0, int_7=15.0, int_8=2.0, int_9=181.0, int_10=1.0, int_11=2.0, int_12=None, int_13=2.0, categ_1='68fd1e64', categ_2='80e26c9b', categ_3='fb936136', categ_4='7b4723c4', categ_5='25c83c98', categ_6='7e0ccccf', categ_7='de7995b8', categ_8='1f89b562', categ_9='a73ee510', categ_10='a8cd5504', categ_11='b2cb9c98', categ_12='37c9c164', categ_13='2824a5f6', categ_14='1adce6ef', categ_15='8ba8b39a', categ_16='891b62e7', categ_17='e5ba7672', categ_18='f54016b9', categ_19='21ddcdc9', categ_20='b1252a9d', categ_21='07b5194c', categ_22='', categ_23='3a171ecb', categ_24='c5c50484', categ_25='e8b83407', categ_26='9727dd16')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullWithColsDF.first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelColList=[\"label\"]\n",
    "intColList=[\"int_1\", \"int_2\", \"int_3\", \"int_4\", \"int_5\", \"int_6\", \"int_7\", \"int_8\", \"int_9\", \"int_10\", \"int_11\", \"int_12\", \"int_13\"]\n",
    "categColList=[\"categ_1\", \"categ_2\", \"categ_3\", \"categ_4\", \"categ_5\", \"categ_6\", \"categ_7\", \"categ_8\", \"categ_9\", \"categ_10\", \"categ_11\", \"categ_12\", \"categ_13\", \"categ_14\", \"categ_15\", \"categ_16\", \"categ_17\", \"categ_18\", \"categ_19\", \"categ_20\", \"categ_21\", \"categ_22\", \"categ_23\", \"categ_24\", \"categ_25\", \"categ_26\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count_empty_string</th>\n",
       "      <th>count_unique_values</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>nulls_nans</th>\n",
       "      <th>pct_nulls_nans</th>\n",
       "      <th>skewness</th>\n",
       "      <th>stddev</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_1</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>649</td>\n",
       "      <td>5775.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20793556</td>\n",
       "      <td>45.36</td>\n",
       "      <td>27.88</td>\n",
       "      <td>9.43</td>\n",
       "      <td>88.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_2</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>9364</td>\n",
       "      <td>257675.0</td>\n",
       "      <td>105.85</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>391.46</td>\n",
       "      <td>153239.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_3</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>14746</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>26.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9839447</td>\n",
       "      <td>21.46</td>\n",
       "      <td>81.49</td>\n",
       "      <td>397.97</td>\n",
       "      <td>158382.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_4</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>969.0</td>\n",
       "      <td>7.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9937369</td>\n",
       "      <td>21.68</td>\n",
       "      <td>4.09</td>\n",
       "      <td>8.79</td>\n",
       "      <td>77.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_5</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>476707</td>\n",
       "      <td>23159456.0</td>\n",
       "      <td>18538.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1183117</td>\n",
       "      <td>2.58</td>\n",
       "      <td>10.1</td>\n",
       "      <td>69394.6</td>\n",
       "      <td>4815610657.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_6</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>11618</td>\n",
       "      <td>431037.0</td>\n",
       "      <td>116.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10252328</td>\n",
       "      <td>22.37</td>\n",
       "      <td>184.98</td>\n",
       "      <td>382.57</td>\n",
       "      <td>146357.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_7</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>4142</td>\n",
       "      <td>56311.0</td>\n",
       "      <td>16.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982866</td>\n",
       "      <td>4.33</td>\n",
       "      <td>46.39</td>\n",
       "      <td>66.05</td>\n",
       "      <td>4362.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_8</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>1373</td>\n",
       "      <td>6047.0</td>\n",
       "      <td>12.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22773</td>\n",
       "      <td>0.05</td>\n",
       "      <td>66.16</td>\n",
       "      <td>16.69</td>\n",
       "      <td>278.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_9</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>7275</td>\n",
       "      <td>29019.0</td>\n",
       "      <td>106.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982866</td>\n",
       "      <td>4.33</td>\n",
       "      <td>8.52</td>\n",
       "      <td>220.28</td>\n",
       "      <td>48524.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_10</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20793556</td>\n",
       "      <td>45.36</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_11</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>231.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1982866</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6.04</td>\n",
       "      <td>5.2</td>\n",
       "      <td>27.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_12</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>407</td>\n",
       "      <td>4008.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35071652</td>\n",
       "      <td>76.51</td>\n",
       "      <td>95.26</td>\n",
       "      <td>5.6</td>\n",
       "      <td>31.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_13</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>1376</td>\n",
       "      <td>7393.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9937369</td>\n",
       "      <td>21.68</td>\n",
       "      <td>105.35</td>\n",
       "      <td>16.21</td>\n",
       "      <td>262.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>45840617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_Empty_String</th>\n",
       "      <th>Count_Unique_Vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categ_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_2</th>\n",
       "      <td>0</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_3</th>\n",
       "      <td>1559473</td>\n",
       "      <td>10131227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_4</th>\n",
       "      <td>1559473</td>\n",
       "      <td>2202608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_5</th>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_6</th>\n",
       "      <td>5540625</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_7</th>\n",
       "      <td>0</td>\n",
       "      <td>12517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_8</th>\n",
       "      <td>0</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_9</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_10</th>\n",
       "      <td>0</td>\n",
       "      <td>93145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_11</th>\n",
       "      <td>0</td>\n",
       "      <td>5683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_12</th>\n",
       "      <td>1559473</td>\n",
       "      <td>8351593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_13</th>\n",
       "      <td>0</td>\n",
       "      <td>3194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_14</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_15</th>\n",
       "      <td>0</td>\n",
       "      <td>14992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_16</th>\n",
       "      <td>1559473</td>\n",
       "      <td>5461306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_17</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_18</th>\n",
       "      <td>0</td>\n",
       "      <td>5652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_19</th>\n",
       "      <td>20172858</td>\n",
       "      <td>2173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_20</th>\n",
       "      <td>20172858</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_21</th>\n",
       "      <td>1559473</td>\n",
       "      <td>7046547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_22</th>\n",
       "      <td>34955073</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_23</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_24</th>\n",
       "      <td>1559473</td>\n",
       "      <td>286181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_25</th>\n",
       "      <td>20172858</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_26</th>\n",
       "      <td>20172858</td>\n",
       "      <td>142572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and Covariance w.r.t target field\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corr</th>\n",
       "      <th>Cov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>int_1</th>\n",
       "      <td>0.104506</td>\n",
       "      <td>0.326917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_2</th>\n",
       "      <td>0.044621</td>\n",
       "      <td>7.603534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_3</th>\n",
       "      <td>0.009372</td>\n",
       "      <td>1.422942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_4</th>\n",
       "      <td>-0.055757</td>\n",
       "      <td>-0.202735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_5</th>\n",
       "      <td>-0.076178</td>\n",
       "      <td>-2296.478111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_6</th>\n",
       "      <td>-0.051921</td>\n",
       "      <td>-8.296947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_7</th>\n",
       "      <td>0.083761</td>\n",
       "      <td>2.405540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_8</th>\n",
       "      <td>-0.027570</td>\n",
       "      <td>-0.200104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_9</th>\n",
       "      <td>0.024018</td>\n",
       "      <td>2.267424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_10</th>\n",
       "      <td>0.191403</td>\n",
       "      <td>0.049470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_11</th>\n",
       "      <td>0.158222</td>\n",
       "      <td>0.353766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_12</th>\n",
       "      <td>0.047553</td>\n",
       "      <td>0.059298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_13</th>\n",
       "      <td>-0.074932</td>\n",
       "      <td>-0.484548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_display_stats_int(fullWithColsDF)\n",
    "f_display_stats_categ(fullWithColsDF, categColList)\n",
    "print(\"Correlation and Covariance w.r.t target field\")\n",
    "f_display_corr(fullWithColsDF, intColList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select only numerical columns\n",
    "fullWithColsDF_int = fullWithColsDF.select(intColList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlation_df = fullWithColsDF_int.na.fill(0)\n",
    "\n",
    "# Convert to vector column first\n",
    "vector_col = \"corr_features\"\n",
    "assembler = VectorAssembler(inputCols=correlation_df.columns, outputCol=vector_col)\n",
    "df_vector = assembler.transform(correlation_df).select(vector_col)\n",
    "\n",
    "# Get correlation matrix\n",
    "matrix = Correlation.corr(df_vector, vector_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>int_01</th>\n",
       "      <th>int_02</th>\n",
       "      <th>int_03</th>\n",
       "      <th>int_04</th>\n",
       "      <th>int_05</th>\n",
       "      <th>int_06</th>\n",
       "      <th>int_07</th>\n",
       "      <th>int_08</th>\n",
       "      <th>int_09</th>\n",
       "      <th>int_10</th>\n",
       "      <th>int_11</th>\n",
       "      <th>int_12</th>\n",
       "      <th>int_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>int_01</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>0.038390</td>\n",
       "      <td>0.081069</td>\n",
       "      <td>-0.068993</td>\n",
       "      <td>-0.058315</td>\n",
       "      <td>0.477780</td>\n",
       "      <td>0.097048</td>\n",
       "      <td>0.068316</td>\n",
       "      <td>0.465176</td>\n",
       "      <td>0.304534</td>\n",
       "      <td>0.092164</td>\n",
       "      <td>0.005279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_02</th>\n",
       "      <td>0.034108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>-0.081530</td>\n",
       "      <td>-0.006260</td>\n",
       "      <td>-0.013320</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>-0.028035</td>\n",
       "      <td>-0.004732</td>\n",
       "      <td>0.035712</td>\n",
       "      <td>0.032760</td>\n",
       "      <td>-0.001294</td>\n",
       "      <td>-0.034543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_03</th>\n",
       "      <td>0.038390</td>\n",
       "      <td>-0.008308</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042022</td>\n",
       "      <td>-0.003412</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.045087</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>0.030109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_04</th>\n",
       "      <td>0.081069</td>\n",
       "      <td>-0.081530</td>\n",
       "      <td>0.042022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.094468</td>\n",
       "      <td>0.015560</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>0.504384</td>\n",
       "      <td>0.194364</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>0.063999</td>\n",
       "      <td>0.021092</td>\n",
       "      <td>0.612960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_05</th>\n",
       "      <td>-0.068993</td>\n",
       "      <td>-0.006260</td>\n",
       "      <td>-0.003412</td>\n",
       "      <td>-0.094468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>-0.056270</td>\n",
       "      <td>-0.109468</td>\n",
       "      <td>-0.068310</td>\n",
       "      <td>-0.148043</td>\n",
       "      <td>-0.115582</td>\n",
       "      <td>-0.020923</td>\n",
       "      <td>-0.054280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_06</th>\n",
       "      <td>-0.058315</td>\n",
       "      <td>-0.013320</td>\n",
       "      <td>0.005079</td>\n",
       "      <td>0.015560</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027060</td>\n",
       "      <td>0.022175</td>\n",
       "      <td>0.186576</td>\n",
       "      <td>-0.124605</td>\n",
       "      <td>-0.039072</td>\n",
       "      <td>-0.012915</td>\n",
       "      <td>0.045574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_07</th>\n",
       "      <td>0.477780</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>-0.056270</td>\n",
       "      <td>-0.027060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077122</td>\n",
       "      <td>0.233840</td>\n",
       "      <td>0.251448</td>\n",
       "      <td>0.685523</td>\n",
       "      <td>0.093341</td>\n",
       "      <td>0.003478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_08</th>\n",
       "      <td>0.097048</td>\n",
       "      <td>-0.028035</td>\n",
       "      <td>0.045087</td>\n",
       "      <td>0.504384</td>\n",
       "      <td>-0.109468</td>\n",
       "      <td>0.022175</td>\n",
       "      <td>0.077122</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206472</td>\n",
       "      <td>0.156661</td>\n",
       "      <td>0.139375</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>0.631302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_09</th>\n",
       "      <td>0.068316</td>\n",
       "      <td>-0.004732</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>0.194364</td>\n",
       "      <td>-0.068310</td>\n",
       "      <td>0.186576</td>\n",
       "      <td>0.233840</td>\n",
       "      <td>0.206472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075001</td>\n",
       "      <td>0.403943</td>\n",
       "      <td>0.045726</td>\n",
       "      <td>0.192788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_10</th>\n",
       "      <td>0.465176</td>\n",
       "      <td>0.035712</td>\n",
       "      <td>-0.003791</td>\n",
       "      <td>0.157900</td>\n",
       "      <td>-0.148043</td>\n",
       "      <td>-0.124605</td>\n",
       "      <td>0.251448</td>\n",
       "      <td>0.156661</td>\n",
       "      <td>0.075001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.386369</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.023659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_11</th>\n",
       "      <td>0.304534</td>\n",
       "      <td>0.032760</td>\n",
       "      <td>-0.005823</td>\n",
       "      <td>0.063999</td>\n",
       "      <td>-0.115582</td>\n",
       "      <td>-0.039072</td>\n",
       "      <td>0.685523</td>\n",
       "      <td>0.139375</td>\n",
       "      <td>0.403943</td>\n",
       "      <td>0.386369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098713</td>\n",
       "      <td>0.010549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_12</th>\n",
       "      <td>0.092164</td>\n",
       "      <td>-0.001294</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>0.021092</td>\n",
       "      <td>-0.020923</td>\n",
       "      <td>-0.012915</td>\n",
       "      <td>0.093341</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>0.045726</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.098713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_13</th>\n",
       "      <td>0.005279</td>\n",
       "      <td>-0.034543</td>\n",
       "      <td>0.030109</td>\n",
       "      <td>0.612960</td>\n",
       "      <td>-0.054280</td>\n",
       "      <td>0.045574</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>0.631302</td>\n",
       "      <td>0.192788</td>\n",
       "      <td>0.023659</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>-0.003453</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          int_01    int_02    int_03    int_04    int_05    int_06    int_07  \\\n",
       "int_01  1.000000  0.034108  0.038390  0.081069 -0.068993 -0.058315  0.477780   \n",
       "int_02  0.034108  1.000000 -0.008308 -0.081530 -0.006260 -0.013320  0.025422   \n",
       "int_03  0.038390 -0.008308  1.000000  0.042022 -0.003412  0.005079  0.000373   \n",
       "int_04  0.081069 -0.081530  0.042022  1.000000 -0.094468  0.015560  0.038521   \n",
       "int_05 -0.068993 -0.006260 -0.003412 -0.094468  1.000000  0.002158 -0.056270   \n",
       "int_06 -0.058315 -0.013320  0.005079  0.015560  0.002158  1.000000 -0.027060   \n",
       "int_07  0.477780  0.025422  0.000373  0.038521 -0.056270 -0.027060  1.000000   \n",
       "int_08  0.097048 -0.028035  0.045087  0.504384 -0.109468  0.022175  0.077122   \n",
       "int_09  0.068316 -0.004732 -0.000465  0.194364 -0.068310  0.186576  0.233840   \n",
       "int_10  0.465176  0.035712 -0.003791  0.157900 -0.148043 -0.124605  0.251448   \n",
       "int_11  0.304534  0.032760 -0.005823  0.063999 -0.115582 -0.039072  0.685523   \n",
       "int_12  0.092164 -0.001294 -0.001431  0.021092 -0.020923 -0.012915  0.093341   \n",
       "int_13  0.005279 -0.034543  0.030109  0.612960 -0.054280  0.045574  0.003478   \n",
       "\n",
       "          int_08    int_09    int_10    int_11    int_12    int_13  \n",
       "int_01  0.097048  0.068316  0.465176  0.304534  0.092164  0.005279  \n",
       "int_02 -0.028035 -0.004732  0.035712  0.032760 -0.001294 -0.034543  \n",
       "int_03  0.045087 -0.000465 -0.003791 -0.005823 -0.001431  0.030109  \n",
       "int_04  0.504384  0.194364  0.157900  0.063999  0.021092  0.612960  \n",
       "int_05 -0.109468 -0.068310 -0.148043 -0.115582 -0.020923 -0.054280  \n",
       "int_06  0.022175  0.186576 -0.124605 -0.039072 -0.012915  0.045574  \n",
       "int_07  0.077122  0.233840  0.251448  0.685523  0.093341  0.003478  \n",
       "int_08  1.000000  0.206472  0.156661  0.139375  0.028334  0.631302  \n",
       "int_09  0.206472  1.000000  0.075001  0.403943  0.045726  0.192788  \n",
       "int_10  0.156661  0.075001  1.000000  0.386369  0.084908  0.023659  \n",
       "int_11  0.139375  0.403943  0.386369  1.000000  0.098713  0.010549  \n",
       "int_12  0.028334  0.045726  0.084908  0.098713  1.000000 -0.003453  \n",
       "int_13  0.631302  0.192788  0.023659  0.010549 -0.003453  1.000000  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intColList_ex = intColList=[\"int_01\", \"int_02\", \"int_03\", \"int_04\", \"int_05\", \"int_06\", \"int_07\", \"int_08\", \"int_09\", \"int_10\", \"int_11\", \"int_12\", \"int_13\"]\n",
    "\n",
    "\n",
    "# matrix.show()\n",
    "correlation_matrix = pd.DataFrame(matrix.collect()[0][\"pearson({})\".format(vector_col)].values)\n",
    "correlation_matrix = correlation_matrix.values.reshape(13, 13)\n",
    "correlation_matrix = pd.DataFrame(correlation_matrix, columns = intColList_ex, index = intColList_ex)\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Data for Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, int_1: double, int_2: double, int_3: double, int_4: double, int_5: double, int_6: double, int_7: double, int_8: double, int_9: double, int_10: double, int_11: double, int_12: double, int_13: double, categ_1: string, categ_2: string, categ_3: string, categ_4: string, categ_5: string, categ_6: string, categ_7: string, categ_8: string, categ_9: string, categ_10: string, categ_11: string, categ_12: string, categ_13: string, categ_14: string, categ_15: string, categ_16: string, categ_17: string, categ_18: string, categ_19: string, categ_20: string, categ_21: string, categ_22: string, categ_23: string, categ_24: string, categ_25: string, categ_26: string]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = fullWithColsDF.sample(False, fraction=0.0001, seed = 1)\n",
    "sample_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert to Pandas DataFrame\n",
    "pd_sample_df = sample_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4635"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pd_sample_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>int_1</th>\n",
       "      <th>int_2</th>\n",
       "      <th>int_3</th>\n",
       "      <th>int_4</th>\n",
       "      <th>int_5</th>\n",
       "      <th>int_6</th>\n",
       "      <th>int_7</th>\n",
       "      <th>int_8</th>\n",
       "      <th>int_9</th>\n",
       "      <th>...</th>\n",
       "      <th>categ_17</th>\n",
       "      <th>categ_18</th>\n",
       "      <th>categ_19</th>\n",
       "      <th>categ_20</th>\n",
       "      <th>categ_21</th>\n",
       "      <th>categ_22</th>\n",
       "      <th>categ_23</th>\n",
       "      <th>categ_24</th>\n",
       "      <th>categ_25</th>\n",
       "      <th>categ_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3021.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>005c6740</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>8717ea07</td>\n",
       "      <td></td>\n",
       "      <td>423fab69</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>b9809574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>891589e7</td>\n",
       "      <td>4764bf77</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>0bf4a9b7</td>\n",
       "      <td></td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>3fdb382b</td>\n",
       "      <td>ea9a246c</td>\n",
       "      <td>49d68486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17313.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>963139a7</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>87cd3c7c</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>31129d1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>ffd53157</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>5f957280</td>\n",
       "      <td></td>\n",
       "      <td>bcdee96c</td>\n",
       "      <td>1793a828</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>414c6af0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5290.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>52e44668</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0014c32a</td>\n",
       "      <td>c9d4222a</td>\n",
       "      <td>423fab69</td>\n",
       "      <td>3b183c5c</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  int_1  int_2  int_3  int_4    int_5  int_6  int_7  int_8  int_9  \\\n",
       "0    0.0    0.0    1.0    NaN    0.0   3021.0    9.0    6.0    2.0   16.0   \n",
       "1    0.0    2.0   -1.0  150.0    2.0     89.0   24.0    5.0   38.0   42.0   \n",
       "2    0.0    0.0    2.0    5.0    4.0  17313.0  526.0    2.0    6.0   80.0   \n",
       "3    0.0    5.0   11.0   45.0    2.0     18.0    4.0    5.0    2.0    2.0   \n",
       "4    0.0    0.0  100.0    3.0    5.0   5290.0  172.0    4.0   24.0  169.0   \n",
       "\n",
       "     ...     categ_17  categ_18  categ_19  categ_20  categ_21  categ_22  \\\n",
       "0    ...     e5ba7672  005c6740  21ddcdc9  b1252a9d  8717ea07             \n",
       "1    ...     e5ba7672  891589e7  4764bf77  5840adea  0bf4a9b7             \n",
       "2    ...     e5ba7672  963139a7  21ddcdc9  b1252a9d  87cd3c7c  ad3062eb   \n",
       "3    ...     07c540c4  ffd53157  21ddcdc9  5840adea  5f957280             \n",
       "4    ...     e5ba7672  52e44668                      0014c32a  c9d4222a   \n",
       "\n",
       "   categ_23  categ_24  categ_25  categ_26  \n",
       "0  423fab69  1793a828  e8b83407  b9809574  \n",
       "1  bcdee96c  3fdb382b  ea9a246c  49d68486  \n",
       "2  3a171ecb  1793a828  e8b83407  31129d1d  \n",
       "3  bcdee96c  1793a828  e8b83407  414c6af0  \n",
       "4  423fab69  3b183c5c                      \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_sample_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>int_1</th>\n",
       "      <th>int_2</th>\n",
       "      <th>int_3</th>\n",
       "      <th>int_4</th>\n",
       "      <th>int_5</th>\n",
       "      <th>int_6</th>\n",
       "      <th>int_7</th>\n",
       "      <th>int_8</th>\n",
       "      <th>int_9</th>\n",
       "      <th>int_10</th>\n",
       "      <th>int_11</th>\n",
       "      <th>int_12</th>\n",
       "      <th>int_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4635.000000</td>\n",
       "      <td>2554.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>3628.000000</td>\n",
       "      <td>3604.000000</td>\n",
       "      <td>4508.000000</td>\n",
       "      <td>3568.000000</td>\n",
       "      <td>4428.000000</td>\n",
       "      <td>4633.000000</td>\n",
       "      <td>4428.000000</td>\n",
       "      <td>2554.000000</td>\n",
       "      <td>4428.000000</td>\n",
       "      <td>1067.000000</td>\n",
       "      <td>3604.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.251996</td>\n",
       "      <td>3.413469</td>\n",
       "      <td>104.611003</td>\n",
       "      <td>23.949559</td>\n",
       "      <td>7.414817</td>\n",
       "      <td>17403.103372</td>\n",
       "      <td>123.585202</td>\n",
       "      <td>16.395890</td>\n",
       "      <td>12.426506</td>\n",
       "      <td>103.229675</td>\n",
       "      <td>0.590838</td>\n",
       "      <td>2.662150</td>\n",
       "      <td>0.841612</td>\n",
       "      <td>8.324362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.434206</td>\n",
       "      <td>8.910210</td>\n",
       "      <td>377.792795</td>\n",
       "      <td>156.789196</td>\n",
       "      <td>8.737750</td>\n",
       "      <td>60225.827088</td>\n",
       "      <td>318.505254</td>\n",
       "      <td>60.082353</td>\n",
       "      <td>12.971814</td>\n",
       "      <td>218.406858</td>\n",
       "      <td>0.679688</td>\n",
       "      <td>5.021584</td>\n",
       "      <td>4.446918</td>\n",
       "      <td>12.224514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2892.500000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10311.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>4435.000000</td>\n",
       "      <td>8337.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>972280.000000</td>\n",
       "      <td>5027.000000</td>\n",
       "      <td>1682.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>5700.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label        int_1        int_2        int_3        int_4  \\\n",
       "count  4635.000000  2554.000000  4635.000000  3628.000000  3604.000000   \n",
       "mean      0.251996     3.413469   104.611003    23.949559     7.414817   \n",
       "std       0.434206     8.910210   377.792795   156.789196     8.737750   \n",
       "min       0.000000     0.000000    -2.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     2.000000     2.000000   \n",
       "50%       0.000000     1.000000     3.000000     6.000000     4.000000   \n",
       "75%       1.000000     3.000000    36.000000    17.000000    10.000000   \n",
       "max       1.000000   177.000000  4435.000000  8337.000000    96.000000   \n",
       "\n",
       "               int_5        int_6        int_7        int_8        int_9  \\\n",
       "count    4508.000000  3568.000000  4428.000000  4633.000000  4428.000000   \n",
       "mean    17403.103372   123.585202    16.395890    12.426506   103.229675   \n",
       "std     60225.827088   318.505254    60.082353    12.971814   218.406858   \n",
       "min         0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       400.000000     9.000000     1.000000     2.000000    11.000000   \n",
       "50%      2892.500000    34.000000     3.000000     7.000000    39.000000   \n",
       "75%     10311.000000   101.000000    11.000000    19.000000   108.000000   \n",
       "max    972280.000000  5027.000000  1682.000000    69.000000  5700.000000   \n",
       "\n",
       "            int_10       int_11       int_12       int_13  \n",
       "count  2554.000000  4428.000000  1067.000000  3604.000000  \n",
       "mean      0.590838     2.662150     0.841612     8.324362  \n",
       "std       0.679688     5.021584     4.446918    12.224514  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     1.000000     0.000000     2.000000  \n",
       "50%       1.000000     1.000000     0.000000     4.000000  \n",
       "75%       1.000000     3.000000     0.000000    10.000000  \n",
       "max       6.000000   114.000000   109.000000   351.000000  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_sample_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['int_01' 'int_02' 'int_03' 'int_04' 'int_05' 'int_06' 'int_07' 'int_08'\\n 'int_09'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-e4a132c6b3ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd_sample_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintColList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['int_01' 'int_02' 'int_03' 'int_04' 'int_05' 'int_06' 'int_07' 'int_08'\\n 'int_09'] not in index\""
     ]
    }
   ],
   "source": [
    "pd_sample_df[intColList].hist(figsize = (15,15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = [.8, .1, .1]\n",
    "seed = 1\n",
    "\n",
    "# Use randomSplit with weights and seed\n",
    "rawTrainDF, rawValidationDF, rawTestDF = rawDF.randomSplit(weights, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#25% sampling due to memory errors\n",
    "rawTrainNewDF = rawTrainDF.sample(withReplacement=False, fraction=0.25, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawTrainNewDF.cache()\n",
    "rawValidationDF.cache()\n",
    "rawTestDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9167896"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawTrainNewDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawTrainNewDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainWithColsDF=rawTrainNewDF.withColumn('tmp', split('text', '\\t')).select( col(\"tmp\").getItem(0).cast(\"double\").alias(\"label\")\n",
    "                                                                            ,col(\"tmp\").getItem(1).cast(\"double\").alias(\"int_1\")\n",
    "                                                                            ,col(\"tmp\").getItem(2).cast(\"double\").alias(\"int_2\")\n",
    "                                                                            ,col(\"tmp\").getItem(3).cast(\"double\").alias(\"int_3\")\n",
    "                                                                            ,col(\"tmp\").getItem(4).cast(\"double\").alias(\"int_4\")\n",
    "                                                                            ,col(\"tmp\").getItem(5).cast(\"double\").alias(\"int_5\")\n",
    "                                                                            ,col(\"tmp\").getItem(6).cast(\"double\").alias(\"int_6\")\n",
    "                                                                            ,col(\"tmp\").getItem(7).cast(\"double\").alias(\"int_7\")\n",
    "                                                                            ,col(\"tmp\").getItem(8).cast(\"double\").alias(\"int_8\")\n",
    "                                                                            ,col(\"tmp\").getItem(9).cast(\"double\").alias(\"int_9\")\n",
    "                                                                            ,col(\"tmp\").getItem(10).cast(\"double\").alias(\"int_10\")\n",
    "                                                                            ,col(\"tmp\").getItem(11).cast(\"double\").alias(\"int_11\")\n",
    "                                                                            ,col(\"tmp\").getItem(12).cast(\"double\").alias(\"int_12\")\n",
    "                                                                            ,col(\"tmp\").getItem(13).cast(\"double\").alias(\"int_13\")\n",
    "                                                                            ,col(\"tmp\").getItem(14).alias(\"categ_1\")\n",
    "                                                                            ,col(\"tmp\").getItem(15).alias(\"categ_2\")\n",
    "                                                                            ,col(\"tmp\").getItem(16).alias(\"categ_3\")\n",
    "                                                                            ,col(\"tmp\").getItem(17).alias(\"categ_4\")\n",
    "                                                                            ,col(\"tmp\").getItem(18).alias(\"categ_5\")\n",
    "                                                                            ,col(\"tmp\").getItem(19).alias(\"categ_6\")\n",
    "                                                                            ,col(\"tmp\").getItem(20).alias(\"categ_7\")\n",
    "                                                                            ,col(\"tmp\").getItem(21).alias(\"categ_8\")\n",
    "                                                                            ,col(\"tmp\").getItem(22).alias(\"categ_9\")\n",
    "                                                                            ,col(\"tmp\").getItem(23).alias(\"categ_10\")\n",
    "                                                                            ,col(\"tmp\").getItem(24).alias(\"categ_11\")\n",
    "                                                                            ,col(\"tmp\").getItem(25).alias(\"categ_12\")\n",
    "                                                                            ,col(\"tmp\").getItem(26).alias(\"categ_13\")\n",
    "                                                                            ,col(\"tmp\").getItem(27).alias(\"categ_14\")\n",
    "                                                                            ,col(\"tmp\").getItem(28).alias(\"categ_15\")\n",
    "                                                                            ,col(\"tmp\").getItem(29).alias(\"categ_16\")\n",
    "                                                                            ,col(\"tmp\").getItem(30).alias(\"categ_17\")\n",
    "                                                                            ,col(\"tmp\").getItem(31).alias(\"categ_18\")\n",
    "                                                                            ,col(\"tmp\").getItem(32).alias(\"categ_19\")\n",
    "                                                                            ,col(\"tmp\").getItem(33).alias(\"categ_20\")\n",
    "                                                                            ,col(\"tmp\").getItem(34).alias(\"categ_21\")\n",
    "                                                                            ,col(\"tmp\").getItem(35).alias(\"categ_22\")\n",
    "                                                                            ,col(\"tmp\").getItem(36).alias(\"categ_23\")\n",
    "                                                                            ,col(\"tmp\").getItem(37).alias(\"categ_24\")\n",
    "                                                                            ,col(\"tmp\").getItem(38).alias(\"categ_25\")\n",
    "                                                                            ,col(\"tmp\").getItem(39).alias(\"categ_26\")\n",
    "                                                            ).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(text='0\\t\\t-1\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t05db9164\\t38a947a1\\t\\t\\t25c83c98\\t\\t1d7560d9\\t64523cfa\\t7cc72ec2\\t3b08e48b\\t8951ed6a\\t\\t27dc8af3\\tb28479f6\\t4df46b2c\\t\\t2005abd1\\t40685634\\t\\t\\t\\t\\t32c7478e\\t\\t\\t')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawTrainNewDF.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, int_1=None, int_2=-1.0, int_3=None, int_4=None, int_5=None, int_6=None, int_7=None, int_8=None, int_9=None, int_10=None, int_11=None, int_12=None, int_13=None, categ_1='05db9164', categ_2='38a947a1', categ_3='', categ_4='', categ_5='25c83c98', categ_6='', categ_7='1d7560d9', categ_8='64523cfa', categ_9='7cc72ec2', categ_10='3b08e48b', categ_11='8951ed6a', categ_12='', categ_13='27dc8af3', categ_14='b28479f6', categ_15='4df46b2c', categ_16='', categ_17='2005abd1', categ_18='40685634', categ_19='', categ_20='', categ_21='', categ_22='', categ_23='32c7478e', categ_24='', categ_25='', categ_26='')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainWithColsDF.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelColList=[\"label\"]\n",
    "intColList=[\"int_1\", \"int_2\", \"int_3\", \"int_4\", \"int_5\", \"int_6\", \"int_7\", \"int_8\", \"int_9\", \"int_10\", \"int_11\", \"int_12\", \"int_13\"]\n",
    "categColList=[\"categ_1\", \"categ_2\", \"categ_3\", \"categ_4\", \"categ_5\", \"categ_6\", \"categ_7\", \"categ_8\", \"categ_9\", \"categ_10\", \"categ_11\", \"categ_12\", \"categ_13\", \"categ_14\", \"categ_15\", \"categ_16\", \"categ_17\", \"categ_18\", \"categ_19\", \"categ_20\", \"categ_21\", \"categ_22\", \"categ_23\", \"categ_24\", \"categ_25\", \"categ_26\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count_empty_string</th>\n",
       "      <th>count_unique_values</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>nulls_nans</th>\n",
       "      <th>pct_nulls_nans</th>\n",
       "      <th>skewness</th>\n",
       "      <th>stddev</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_1</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>456</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4159327</td>\n",
       "      <td>45.37</td>\n",
       "      <td>18.49</td>\n",
       "      <td>9.4</td>\n",
       "      <td>88.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_2</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>6850</td>\n",
       "      <td>35521.0</td>\n",
       "      <td>105.91</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.22</td>\n",
       "      <td>390.39</td>\n",
       "      <td>152401.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_3</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>5781</td>\n",
       "      <td>65535.0</td>\n",
       "      <td>26.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1966409</td>\n",
       "      <td>21.45</td>\n",
       "      <td>83.89</td>\n",
       "      <td>392.27</td>\n",
       "      <td>153878.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_4</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>877.0</td>\n",
       "      <td>7.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987342</td>\n",
       "      <td>21.68</td>\n",
       "      <td>3.94</td>\n",
       "      <td>8.77</td>\n",
       "      <td>76.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_5</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>256027</td>\n",
       "      <td>23159456.0</td>\n",
       "      <td>18563.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236154</td>\n",
       "      <td>2.58</td>\n",
       "      <td>13.23</td>\n",
       "      <td>69907.29</td>\n",
       "      <td>4887029138.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_6</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>7358</td>\n",
       "      <td>430898.0</td>\n",
       "      <td>115.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2050660</td>\n",
       "      <td>22.37</td>\n",
       "      <td>284.12</td>\n",
       "      <td>411.87</td>\n",
       "      <td>169638.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_7</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>2727</td>\n",
       "      <td>34536.0</td>\n",
       "      <td>16.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>397046</td>\n",
       "      <td>4.33</td>\n",
       "      <td>48.8</td>\n",
       "      <td>67.18</td>\n",
       "      <td>4513.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_8</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>747</td>\n",
       "      <td>5664.0</td>\n",
       "      <td>12.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4476</td>\n",
       "      <td>0.05</td>\n",
       "      <td>66.97</td>\n",
       "      <td>16.63</td>\n",
       "      <td>276.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_9</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>5142</td>\n",
       "      <td>29019.0</td>\n",
       "      <td>106.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>397046</td>\n",
       "      <td>4.33</td>\n",
       "      <td>8.55</td>\n",
       "      <td>220.01</td>\n",
       "      <td>48405.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_10</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4159327</td>\n",
       "      <td>45.37</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_11</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>181.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>397046</td>\n",
       "      <td>4.33</td>\n",
       "      <td>6.05</td>\n",
       "      <td>5.21</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_12</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>3770.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7013777</td>\n",
       "      <td>76.5</td>\n",
       "      <td>145.41</td>\n",
       "      <td>5.83</td>\n",
       "      <td>33.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_13</th>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>674</td>\n",
       "      <td>7393.0</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987342</td>\n",
       "      <td>21.68</td>\n",
       "      <td>120.81</td>\n",
       "      <td>16.3</td>\n",
       "      <td>265.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOTAL</th>\n",
       "      <td>9167896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_Empty_String</th>\n",
       "      <th>Count_Unique_Vals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categ_1</th>\n",
       "      <td>0</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_2</th>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_3</th>\n",
       "      <td>311243</td>\n",
       "      <td>2539621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_4</th>\n",
       "      <td>311243</td>\n",
       "      <td>701163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_5</th>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_6</th>\n",
       "      <td>1110211</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_7</th>\n",
       "      <td>0</td>\n",
       "      <td>12238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_8</th>\n",
       "      <td>0</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_9</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_10</th>\n",
       "      <td>0</td>\n",
       "      <td>64089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_11</th>\n",
       "      <td>0</td>\n",
       "      <td>5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_12</th>\n",
       "      <td>311243</td>\n",
       "      <td>2175829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_13</th>\n",
       "      <td>0</td>\n",
       "      <td>3184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_14</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_15</th>\n",
       "      <td>0</td>\n",
       "      <td>12973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_16</th>\n",
       "      <td>311243</td>\n",
       "      <td>1520386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_17</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_18</th>\n",
       "      <td>0</td>\n",
       "      <td>5061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_19</th>\n",
       "      <td>4034202</td>\n",
       "      <td>2107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_20</th>\n",
       "      <td>4034202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_21</th>\n",
       "      <td>311243</td>\n",
       "      <td>1893572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_22</th>\n",
       "      <td>6990570</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_23</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_24</th>\n",
       "      <td>311243</td>\n",
       "      <td>135984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_25</th>\n",
       "      <td>4034202</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categ_26</th>\n",
       "      <td>4034202</td>\n",
       "      <td>83237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation and Covariance w.r.t target field\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corr</th>\n",
       "      <th>Cov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>int_1</th>\n",
       "      <td>0.104506</td>\n",
       "      <td>0.326917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_2</th>\n",
       "      <td>0.044621</td>\n",
       "      <td>7.603534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_3</th>\n",
       "      <td>0.009372</td>\n",
       "      <td>1.422942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_4</th>\n",
       "      <td>-0.055757</td>\n",
       "      <td>-0.202735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_5</th>\n",
       "      <td>-0.076178</td>\n",
       "      <td>-2296.478111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_6</th>\n",
       "      <td>-0.051921</td>\n",
       "      <td>-8.296947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_7</th>\n",
       "      <td>0.083761</td>\n",
       "      <td>2.405540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_8</th>\n",
       "      <td>-0.027570</td>\n",
       "      <td>-0.200104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_9</th>\n",
       "      <td>0.024018</td>\n",
       "      <td>2.267424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_10</th>\n",
       "      <td>0.191403</td>\n",
       "      <td>0.049470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_11</th>\n",
       "      <td>0.158222</td>\n",
       "      <td>0.353766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_12</th>\n",
       "      <td>0.047553</td>\n",
       "      <td>0.059298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>int_13</th>\n",
       "      <td>-0.074932</td>\n",
       "      <td>-0.484548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_display_stats_int(trainWithColsDF)\n",
    "f_display_stats_categ(trainWithColsDF, categColList)\n",
    "print(\"Correlation and Covariance w.r.t target field\")\n",
    "f_display_corr(trainWithColsDF, intColList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(raw_feats, ohe_dict_broadcast, num_ohe_feats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "\n",
    "    Note:\n",
    "        You should ensure that the indices used to create a SparseVector are sorted, and that the\n",
    "        function handles missing features.\n",
    "\n",
    "    Args:\n",
    "        raw_feats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sample_one)\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "        num_ohe_feats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length num_ohe_feats with indices equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    #indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats if feat in ohe_dict_broadcast.value])\n",
    "    indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats])\n",
    "    values = np.ones(len(raw_feats))\n",
    "    return SparseVector(num_ohe_feats,indices,values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ohe_udf_generator(ohe_dict_broadcast):\n",
    "    \"\"\"Generate a UDF that is setup to one-hot-encode rows with the given dictionary.\n",
    "\n",
    "    Note:\n",
    "        We'll reuse this function to generate a UDF that can one-hot-encode rows based on a\n",
    "        one-hot-encoding dictionary built from the training data.  Also, you should calculate\n",
    "        the number of features before calling the one_hot_encoding function.\n",
    "\n",
    "    Args:\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "\n",
    "    Returns:\n",
    "        UserDefinedFunction: A UDF can be used in `DataFrame` `select` statement to call a\n",
    "            function on each row in a given column.  This UDF should call the one_hot_encoding\n",
    "            function with the appropriate parameters.\n",
    "    \"\"\"\n",
    "    length = len(ohe_dict_broadcast.value)\n",
    "    return udf(lambda x: one_hot_encoding(x, ohe_dict_broadcast, length), VectorUDT())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_one_hot_dict(input_df):\n",
    "    \"\"\"Creates a one-hot-encoder dictionary based on the input data.\n",
    "\n",
    "    Args:\n",
    "        input_df (DataFrame with 'features' column): A DataFrame where each row contains a list of\n",
    "            (featureID, value) tuples.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are\n",
    "            unique integers.\n",
    "    \"\"\"\n",
    "    input_distinct_feats_df = input_df.select(explode(input_df.features)).distinct()\n",
    "    input_ohe_dict = (input_distinct_feats_df\n",
    "                     .rdd\n",
    "                     .map(lambda r: tuple(r[0]))\n",
    "                     .zipWithIndex().collectAsMap())\n",
    "    return input_ohe_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parsed_train_df = parse_raw_df(rawTrainNewDF)\n",
    "parsed_validation_df = parse_raw_df(rawValidationDF)\n",
    "parsed_test_df = parse_raw_df(rawTestDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: array<struct<_1:bigint,_2:string>>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_train_df.cache()\n",
    "parsed_validation_df.cache()\n",
    "parsed_test_df.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9167896"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, features=[Row(_1=0, _2=''), Row(_1=1, _2='-1'), Row(_1=2, _2=''), Row(_1=3, _2=''), Row(_1=4, _2=''), Row(_1=5, _2=''), Row(_1=6, _2=''), Row(_1=7, _2=''), Row(_1=8, _2=''), Row(_1=9, _2=''), Row(_1=10, _2=''), Row(_1=11, _2=''), Row(_1=12, _2=''), Row(_1=13, _2='05db9164'), Row(_1=14, _2='38a947a1'), Row(_1=15, _2=''), Row(_1=16, _2=''), Row(_1=17, _2='25c83c98'), Row(_1=18, _2=''), Row(_1=19, _2='1d7560d9'), Row(_1=20, _2='64523cfa'), Row(_1=21, _2='7cc72ec2'), Row(_1=22, _2='3b08e48b'), Row(_1=23, _2='8951ed6a'), Row(_1=24, _2=''), Row(_1=25, _2='27dc8af3'), Row(_1=26, _2='b28479f6'), Row(_1=27, _2='4df46b2c'), Row(_1=28, _2=''), Row(_1=29, _2='2005abd1'), Row(_1=30, _2='40685634'), Row(_1=31, _2=''), Row(_1=32, _2=''), Row(_1=33, _2=''), Row(_1=34, _2=''), Row(_1=35, _2='32c7478e'), Row(_1=36, _2=''), Row(_1=37, _2=''), Row(_1=38, _2='')])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_categories = (parsed_train_df\n",
    "                    .select(explode('features').alias('features'))\n",
    "                    .distinct()\n",
    "                    .select(col('features').getField('_1').alias('featureNumber'))\n",
    "                    .groupBy('featureNumber')\n",
    "                    .sum()\n",
    "                    .orderBy('featureNumber')\n",
    "                    .collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(featureNumber=0, sum(featureNumber)=0),\n",
       " Row(featureNumber=1, sum(featureNumber)=6850),\n",
       " Row(featureNumber=2, sum(featureNumber)=11562),\n",
       " Row(featureNumber=3, sum(featureNumber)=876),\n",
       " Row(featureNumber=4, sum(featureNumber)=1024108),\n",
       " Row(featureNumber=5, sum(featureNumber)=36790),\n",
       " Row(featureNumber=6, sum(featureNumber)=16362),\n",
       " Row(featureNumber=7, sum(featureNumber)=5229),\n",
       " Row(featureNumber=8, sum(featureNumber)=41136),\n",
       " Row(featureNumber=9, sum(featureNumber)=99),\n",
       " Row(featureNumber=10, sum(featureNumber)=1470),\n",
       " Row(featureNumber=11, sum(featureNumber)=2915),\n",
       " Row(featureNumber=12, sum(featureNumber)=8088),\n",
       " Row(featureNumber=13, sum(featureNumber)=18954),\n",
       " Row(featureNumber=14, sum(featureNumber)=7868),\n",
       " Row(featureNumber=15, sum(featureNumber)=38094315),\n",
       " Row(featureNumber=16, sum(featureNumber)=11218608),\n",
       " Row(featureNumber=17, sum(featureNumber)=5185),\n",
       " Row(featureNumber=18, sum(featureNumber)=414),\n",
       " Row(featureNumber=19, sum(featureNumber)=232522),\n",
       " Row(featureNumber=20, sum(featureNumber)=12660),\n",
       " Row(featureNumber=21, sum(featureNumber)=63),\n",
       " Row(featureNumber=22, sum(featureNumber)=1409958),\n",
       " Row(featureNumber=23, sum(featureNumber)=124131),\n",
       " Row(featureNumber=24, sum(featureNumber)=52219896),\n",
       " Row(featureNumber=25, sum(featureNumber)=79600),\n",
       " Row(featureNumber=26, sum(featureNumber)=702),\n",
       " Row(featureNumber=27, sum(featureNumber)=350271),\n",
       " Row(featureNumber=28, sum(featureNumber)=42570808),\n",
       " Row(featureNumber=29, sum(featureNumber)=290),\n",
       " Row(featureNumber=30, sum(featureNumber)=151830),\n",
       " Row(featureNumber=31, sum(featureNumber)=65317),\n",
       " Row(featureNumber=32, sum(featureNumber)=128),\n",
       " Row(featureNumber=33, sum(featureNumber)=62487876),\n",
       " Row(featureNumber=34, sum(featureNumber)=612),\n",
       " Row(featureNumber=35, sum(featureNumber)=525),\n",
       " Row(featureNumber=36, sum(featureNumber)=4895424),\n",
       " Row(featureNumber=37, sum(featureNumber)=3552),\n",
       " Row(featureNumber=38, sum(featureNumber)=3163006)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an OHE dictionary from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9444472\n",
      "8499753\n"
     ]
    }
   ],
   "source": [
    "ctr_ohe_dict = create_one_hot_dict(parsed_train_df)\n",
    "num_ctr_ohe_feats = len(ctr_ohe_dict)\n",
    "print(num_ctr_ohe_feats)\n",
    "print(ctr_ohe_dict[(0, '')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply OHE to the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe_dict_broadcast = sc.broadcast(ctr_ohe_dict)\n",
    "ohe_dict_udf =  ohe_udf_generator(ohe_dict_broadcast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_train_df =  parsed_train_df.select(parsed_train_df.label, ohe_dict_udf(parsed_train_df.features).alias('features'))\n",
    "ohe_train_df.cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3f) Handling unseen features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding_v2(raw_feats, ohe_dict_broadcast, num_ohe_feats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "    The indices used to create a SparseVector are sorted. We consider previously seen features only.\n",
    "\n",
    "    Args:\n",
    "        raw_feats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sample_one)\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "        num_ohe_feats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length num_ohe_feats with indices equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats if feat in ohe_dict_broadcast.value])\n",
    "    values = np.ones(len([feat for feat in raw_feats if feat in ohe_dict_broadcast.value] ))\n",
    "    return SparseVector(num_ohe_feats,indices,values)\n",
    "\n",
    "def ohe_udf_generator_v2(ohe_dict_broadcast):\n",
    "    \"\"\"Generate a UDF that is setup to one-hot-encode rows with the given dictionary.\n",
    "\n",
    "    Args:\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "\n",
    "    Returns:\n",
    "        UserDefinedFunction: A UDF can be used in `DataFrame` `select` statement to call a\n",
    "            function on each row in a given column.  This UDF should call the one_hot_encoding\n",
    "            function with the appropriate parameters.\n",
    "    \"\"\"\n",
    "    length = len(ohe_dict_broadcast.value)\n",
    "    return udf(lambda x: one_hot_encoding_v2(x, ohe_dict_broadcast, length), VectorUDT())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ohe_dict_missing_udf = ohe_udf_generator_v2(ohe_dict_broadcast)\n",
    "\n",
    "ohe_test_df = parsed_test_df.select(parsed_test_df.label,  ohe_dict_missing_udf(parsed_test_df.features).alias('features')).cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4585725\n",
      "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0.0  |(9444472,[282595,424288,659969,706928,1320318,1557022,1557024,1604080,2264580,2406696,2500884,2736370,3113587,3255788,4010909,4058045,4153235,4200705,4578630,4814588,4909212,5146054,5524541,5808565,5855851,6091432,6233661,6611261,6705776,7602305,7884943,8074256,8358485,8405758,8452489,8499753,9161299,9350284,9350285],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ohe_test_df.count())\n",
    "print(ohe_test_df.show(1, truncate=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, features=SparseVector(9444472, {282595: 1.0, 424288: 1.0, 659969: 1.0, 706928: 1.0, 989935: 1.0, 1320318: 1.0, 1557022: 1.0, 1557023: 1.0, 1557024: 1.0, 2123496: 1.0, 2264580: 1.0, 2406696: 1.0, 2736370: 1.0, 3113587: 1.0, 3255788: 1.0, 4010909: 1.0, 4153235: 1.0, 4200705: 1.0, 4200706: 1.0, 4296513: 1.0, 4814588: 1.0, 4909212: 1.0, 5146054: 1.0, 5524541: 1.0, 5808565: 1.0, 5903003: 1.0, 6233661: 1.0, 6611261: 1.0, 6705776: 1.0, 6895237: 1.0, 7602305: 1.0, 8074256: 1.0, 8358485: 1.0, 8405758: 1.0, 8452489: 1.0, 8499753: 1.0, 9161299: 1.0, 9350284: 1.0, 9350285: 1.0}))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_train_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, features=SparseVector(9444472, {282595: 1.0, 424288: 1.0, 659969: 1.0, 706928: 1.0, 1320318: 1.0, 1557022: 1.0, 1557024: 1.0, 1604080: 1.0, 2264580: 1.0, 2406696: 1.0, 2500884: 1.0, 2736370: 1.0, 3113587: 1.0, 3255788: 1.0, 4010909: 1.0, 4058045: 1.0, 4153235: 1.0, 4200705: 1.0, 4578630: 1.0, 4814588: 1.0, 4909212: 1.0, 5146054: 1.0, 5524541: 1.0, 5808565: 1.0, 5855851: 1.0, 6091432: 1.0, 6233661: 1.0, 6611261: 1.0, 6705776: 1.0, 7602305: 1.0, 7884943: 1.0, 8074256: 1.0, 8358485: 1.0, 8405758: 1.0, 8452489: 1.0, 8499753: 1.0, 9161299: 1.0, 9350284: 1.0, 9350285: 1.0}))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_test_df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: CTR prediction and logloss evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4a) Logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: -1.0743401568315318\n",
      "length of coefficients: 9444472\n",
      "[-2.3933778261858674, -2.3640446886325717, -2.3606764183110305, -2.356334312584443, -2.345188385115328]\n"
     ]
    }
   ],
   "source": [
    "standardization = True\n",
    "elastic_net_param = 0.0\n",
    "reg_param = .01\n",
    "max_iter = 5\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", predictionCol=\"prediction\", maxIter=max_iter, regParam=reg_param, elasticNetParam=elastic_net_param, fitIntercept=True,  standardization=standardization)\n",
    "\n",
    "lr_model_basic = lr.fit(ohe_train_df)\n",
    "\n",
    "print('intercept: {0}'.format(lr_model_basic.intercept))\n",
    "print('length of coefficients: {0}'.format(len(lr_model_basic.coefficients)))\n",
    "sorted_coefficients = sorted(lr_model_basic.coefficients)[:5]\n",
    "print(sorted_coefficients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4b) Log loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, log, col\n",
    "epsilon = 1e-16\n",
    "\n",
    "def add_log_loss(df):\n",
    "    \"\"\"Computes and adds a 'log_loss' column to a DataFrame using 'p' and 'label' columns.\n",
    "\n",
    "    Note:\n",
    "        log(0) is undefined, so when p is 0 we add a small value (epsilon) to it and when\n",
    "        p is 1 we subtract a small value (epsilon) from it.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame with 'p' and 'label' columns): A DataFrame with a probability column\n",
    "            'p' and a 'label' column that corresponds to y in the log loss formula.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with an additional column called 'log_loss' where 'log_loss' column contains the loss value as explained above.\n",
    "        \n",
    "        if y == 1:\n",
    "          return -log(epsilon + p) if p == 0 else -log(p)\n",
    "        elif y == 0:\n",
    "          return -log(1 - p + epsilon) if p == 1 else -log(1 - p)         \n",
    "    \"\"\"\n",
    "    \n",
    "    return (df.select(df['p'],df['label'],\n",
    "                when(df['label']==1.0,\n",
    "                     (when(df['p']!=0,-log(df['p'])))\n",
    "                     .otherwise(-log(epsilon + df['p'])))\n",
    "               .when(df['label']==0.0,\n",
    "                     (when(df['p']!=1.0,-log(1.0-df['p'])))\n",
    "                     .otherwise(-log(1.0 - df['p'] + epsilon)))\n",
    "               .alias(\"log_loss\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4c) Baseline log loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class one fraction = 0.256\n",
      "Baseline Train Logloss = 0.569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "class_one_frac_train = ohe_train_df.select(F.sum('label')).collect()[0][0] / ohe_train_df.count()\n",
    "\n",
    "ohe_train_df = (ohe_train_df.withColumn(\"p\", lit(class_one_frac_train)))\n",
    "print('Training class one fraction = {0:.3f}'.format(class_one_frac_train))\n",
    "\n",
    "log_loss_tr_base = (add_log_loss(ohe_train_df).select(F.sum('log_loss')).collect()[0][0] / ohe_train_df.count())\n",
    "print('Baseline Train Logloss = {0:.3f}\\n'.format(log_loss_tr_base))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from math import exp #  exp(-t) = e^-t\n",
    "\n",
    "def add_probability(df, model):\n",
    "    \"\"\"Adds a probability column ('p') to a DataFrame given a model\n",
    "    Args:\n",
    "        df for which probability has to be calculated.\n",
    "        model with which probability has to be calculated\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with an additional column called p where p column contains the probability for an observation given a list of features.\n",
    "    \n",
    "    \"\"\"\n",
    "    coefficients_broadcast = sc.broadcast(model.coefficients)\n",
    "    intercept = model.intercept\n",
    "\n",
    "    def get_p(features):\n",
    "        \"\"\"Calculate the probability for an observation given a list of features.\n",
    "\n",
    "        Note:\n",
    "            We'll bound our raw prediction between 20 and -20 for numerical purposes.\n",
    "\n",
    "        Args:\n",
    "            features: the features\n",
    "\n",
    "        Returns:\n",
    "            float: A probability between 0 and 1.\n",
    "        \"\"\"\n",
    "        # Compute the raw value\n",
    "        raw_prediction = features.dot(coefficients_broadcast.value)+intercept\n",
    "        # Bound the raw value between 20 and -20\n",
    "        raw_prediction = min(raw_prediction, 20)\n",
    "        raw_prediction = max(raw_prediction, -20)\n",
    "        return 1.0 / (1.0 + exp(-raw_prediction))\n",
    "\n",
    "    get_p_udf = udf(get_p, DoubleType())\n",
    "    return df.withColumn('p', get_p_udf('features'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|label|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |p                   |\n",
      "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "|0.0  |(9444472,[282595,424288,659969,706928,989935,1320318,1557022,1557023,1557024,2123496,2264580,2406696,2736370,3113587,3255788,4010909,4153235,4200705,4200706,4296513,4814588,4909212,5146054,5524541,5808565,5903003,6233661,6611261,6705776,6895237,7602305,8074256,8358485,8405758,8452489,8499753,9161299,9350284,9350285],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]) |0.03797345839906773 |\n",
      "|0.0  |(9444472,[282595,424288,659969,706928,1232762,1320318,1557022,2264580,2406696,2736370,3113587,3255788,3538394,4010909,4153235,4200705,4200706,4437058,4578630,4767540,4814588,4909212,5146054,5288211,5524541,5808565,6233661,6611261,6705776,7225116,7602305,8074256,8358485,8405758,8452489,8499753,9161299,9350284,9350285],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.04075749313455165 |\n",
      "|0.0  |(9444472,[282595,424288,706928,894905,1320318,1557022,1557024,1604080,2264580,2264581,2406696,2500884,2547651,2736370,3113587,3160920,3255788,3538395,3821451,4010909,4153235,4200705,4814588,4909212,5146054,5524541,5808565,6091432,6233661,6611261,6705776,7602305,8074256,8358485,8405758,8452489,8499753,9350284,9350285],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.0602396726700737  |\n",
      "|0.0  |(9444472,[235571,282595,424288,612985,659969,706928,1133915,1320318,1557022,1557024,1651141,2264580,2406696,2547651,2736370,3113587,3255788,3585421,4010909,4153235,4200705,4814588,4909212,5146054,5524541,5808565,5808566,6233661,6233662,6611261,6705776,7602305,8074256,8358485,8405758,8452489,8499753,9350284,9350285],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])  |0.058502976931045676|\n",
      "|0.0  |(9444472,[282595,424288,471465,706928,1131695,1320318,1557022,1651142,2264580,2406696,2594745,2736370,3113587,3255788,3585421,4010909,4153235,4200705,4767541,4814588,4909212,5146054,5524541,5808565,5808567,6233661,6280595,6611261,6705776,7602305,8074256,8358485,8405758,8452489,8499753,8688750,9161300,9350284,9350285],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0])|0.09565946274868178 |\n",
      "+-----+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_probability_model_basic = lambda df: add_probability(df, lr_model_basic)\n",
    "training_predictions = add_probability_model_basic(ohe_train_df).cache()\n",
    "training_predictions.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            features|                   p|\n",
      "+-----+--------------------+--------------------+\n",
      "|  0.0|(9444472,[282595,...| 0.03797345839906773|\n",
      "|  0.0|(9444472,[282595,...| 0.04075749313455165|\n",
      "|  0.0|(9444472,[282595,...|  0.0602396726700737|\n",
      "|  0.0|(9444472,[235571,...|0.058502976931045676|\n",
      "|  0.0|(9444472,[282595,...| 0.09565946274868178|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_predictions.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_results(df, model, baseline=None):\n",
    "    \"\"\"Calculates the log loss for the data given the model.\n",
    "\n",
    "    Note:\n",
    "        If baseline has a value the probability should be set to baseline before\n",
    "        the log loss is calculated.  Otherwise, use add_probability to add the\n",
    "        appropriate probabilities to the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame with 'label' and 'features' columns): A DataFrame containing\n",
    "            labels and features.\n",
    "        model (LogisticRegressionModel): A trained logistic regression model. This\n",
    "            can be None if baseline is set.\n",
    "        baseline (float): A baseline probability to use for the log loss calculation.\n",
    "\n",
    "    Returns:\n",
    "        float: Log loss for the data.\n",
    "    \"\"\"\n",
    "    with_probability_df = add_probability(df, model)\n",
    "    with_log_loss_df = add_log_loss(with_probability_df)\n",
    "    log_loss = (with_log_loss_df.select(F.sum('log_loss')).collect()[0][0] / with_log_loss_df.count())\n",
    "    return log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE Features Train Logloss:\n",
      "\tBaseline = 0.569\n",
      "\tLogReg = 0.335\n"
     ]
    }
   ],
   "source": [
    "log_loss_train_model_basic = evaluate_results(ohe_train_df, lr_model_basic)\n",
    "print ('OHE Features Train Logloss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(log_loss_tr_base, log_loss_train_model_basic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4f) Test dataset log loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss_val = evaluate_results(ohe_test_df, lr_model_basic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4948208635641279"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------------+\n",
      "|label|            features|                  p|\n",
      "+-----+--------------------+-------------------+\n",
      "|  0.0|(9444472,[282595,...| 0.0758689589710484|\n",
      "|  0.0|(9444472,[235572,...| 0.0400414644520275|\n",
      "|  0.0|(9444472,[47175,1...|0.10946047756433618|\n",
      "|  0.0|(9444472,[95297,4...|0.03827244701048019|\n",
      "|  0.0|(9444472,[424288,...|0.13123500785370285|\n",
      "+-----+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = add_probability_model_basic(ohe_test_df).cache()\n",
    "test_predictions.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|Probability| count|\n",
      "+-----------+------+\n",
      "|       0.66| 14531|\n",
      "|       0.07|149394|\n",
      "|       0.84|  6620|\n",
      "|       0.87|  5837|\n",
      "|        0.0|  4639|\n",
      "|       0.16|110505|\n",
      "|       0.93|  5016|\n",
      "|       0.89|  5339|\n",
      "|       0.18|100581|\n",
      "|        0.2| 92191|\n",
      "|       0.05|149975|\n",
      "|       0.39| 39944|\n",
      "|       0.79|  8147|\n",
      "|       0.72| 11352|\n",
      "|        0.7| 12170|\n",
      "|       0.24| 76046|\n",
      "|       0.54| 22642|\n",
      "|       0.21| 87714|\n",
      "|        0.1|139554|\n",
      "|       0.45| 31639|\n",
      "+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions.withColumn(\"Probability\",F.round(col(\"p\"),2) ).groupBy(\"Probability\").agg(F.count(lit(1)).alias(\"count\")).show()\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# # Create ParamGrid for Cross Validation\n",
    "# paramGrid = (ParamGridBuilder()\n",
    "#              .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n",
    "#              .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "#              .addGrid(lr.maxIter, [1, 5, 10])\n",
    "#              .build())\n",
    "\n",
    "# # Evaluate model\n",
    "# evaluator = BinaryClassificationEvaluator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create 5-fold CrossValidator\n",
    "# cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# # Run cross validations\n",
    "# cvModel = cv.fit(ohe_train_df)\n",
    "# # this will likely take a fair amount of time because of the amount of models that we're creating and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cvModel uses the best model found from the Cross Validation\n",
    "# Evaluate best model\n",
    "# evaluator.evaluate(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
