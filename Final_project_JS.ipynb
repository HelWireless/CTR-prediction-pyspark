{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark_dist_explore\n",
      "  Downloading https://files.pythonhosted.org/packages/f0/c2/2f19468300f7c9d25dc526f0c11779d87e1a7c07d999347cf71a13282c0b/pyspark_dist_explore-0.1.4-py2.py3-none-any.whl\n",
      "Requirement not upgraded as not directly required: numpy in /opt/anaconda/lib/python3.6/site-packages (from pyspark_dist_explore) (1.15.0)\n",
      "Requirement not upgraded as not directly required: matplotlib in /opt/anaconda/lib/python3.6/site-packages (from pyspark_dist_explore) (2.2.2)\n",
      "Requirement not upgraded as not directly required: pandas in /opt/anaconda/lib/python3.6/site-packages (from pyspark_dist_explore) (0.23.3)\n",
      "Requirement not upgraded as not directly required: scipy in /opt/anaconda/lib/python3.6/site-packages (from pyspark_dist_explore) (1.1.0)\n",
      "Requirement not upgraded as not directly required: cycler>=0.10 in /opt/anaconda/lib/python3.6/site-packages (from matplotlib->pyspark_dist_explore) (0.10.0)\n",
      "Requirement not upgraded as not directly required: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda/lib/python3.6/site-packages (from matplotlib->pyspark_dist_explore) (2.2.0)\n",
      "Requirement not upgraded as not directly required: python-dateutil>=2.1 in /opt/anaconda/lib/python3.6/site-packages (from matplotlib->pyspark_dist_explore) (2.7.3)\n",
      "Requirement not upgraded as not directly required: pytz in /opt/anaconda/lib/python3.6/site-packages (from matplotlib->pyspark_dist_explore) (2018.5)\n",
      "Requirement not upgraded as not directly required: six>=1.10 in /opt/anaconda/lib/python3.6/site-packages (from matplotlib->pyspark_dist_explore) (1.11.0)\n",
      "Requirement not upgraded as not directly required: kiwisolver>=1.0.1 in /opt/anaconda/lib/python3.6/site-packages (from matplotlib->pyspark_dist_explore) (1.0.1)\n",
      "Requirement not upgraded as not directly required: setuptools in /opt/anaconda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->pyspark_dist_explore) (39.2.0)\n",
      "\u001b[31mdistributed 1.22.0 requires msgpack, which is not installed.\u001b[0m\n",
      "Installing collected packages: pyspark-dist-explore\n",
      "Successfully installed pyspark-dist-explore-0.1.4\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyspark_dist_explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import display, HTML, display_html #usefull to display wide tables\n",
    "from pyspark_dist_explore import Histogram, hist, distplot, pandas_histogram\n",
    "from pyspark.sql import functions as F, types, SQLContext\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifty_lines = ['0\\t1\\t1\\t5\\t0\\t1382\\t4\\t15\\t2\\t181\\t1\\t2\\t\\t2\\t68fd1e64\\t80e26c9b\\tfb936136\\t7b4723c4\\t25c83c98\\t7e0ccccf\\tde7995b8\\t1f89b562\\ta73ee510\\ta8cd5504\\tb2cb9c98\\t37c9c164\\t2824a5f6\\t1adce6ef\\t8ba8b39a\\t891b62e7\\te5ba7672\\tf54016b9\\t21ddcdc9\\tb1252a9d\\t07b5194c\\t\\t3a171ecb\\tc5c50484\\te8b83407\\t9727dd16',\n",
    " '0\\t2\\t0\\t44\\t1\\t102\\t8\\t2\\t2\\t4\\t1\\t1\\t\\t4\\t68fd1e64\\tf0cf0024\\t6f67f7e5\\t41274cd7\\t25c83c98\\tfe6b92e5\\t922afcc0\\t0b153874\\ta73ee510\\t2b53e5fb\\t4f1b46f3\\t623049e6\\td7020589\\tb28479f6\\te6c5b5cd\\tc92f3b61\\t07c540c4\\tb04e4670\\t21ddcdc9\\t5840adea\\t60f6221e\\t\\t3a171ecb\\t43f13e8b\\te8b83407\\t731c3655',\n",
    " '0\\t2\\t0\\t1\\t14\\t767\\t89\\t4\\t2\\t245\\t1\\t3\\t3\\t45\\t287e684f\\t0a519c5c\\t02cf9876\\tc18be181\\t25c83c98\\t7e0ccccf\\tc78204a1\\t0b153874\\ta73ee510\\t3b08e48b\\t5f5e6091\\t8fe001f4\\taa655a2f\\t07d13a8f\\t6dc710ed\\t36103458\\t8efede7f\\t3412118d\\t\\t\\te587c466\\tad3062eb\\t3a171ecb\\t3b183c5c\\t\\t',\n",
    " '0\\t\\t893\\t\\t\\t4392\\t\\t0\\t0\\t0\\t\\t0\\t\\t\\t68fd1e64\\t2c16a946\\ta9a87e68\\t2e17d6f6\\t25c83c98\\tfe6b92e5\\t2e8a689b\\t0b153874\\ta73ee510\\tefea433b\\te51ddf94\\ta30567ca\\t3516f6e6\\t07d13a8f\\t18231224\\t52b8680f\\t1e88c74f\\t74ef3502\\t\\t\\t6b3a5ca6\\t\\t3a171ecb\\t9117a34a\\t\\t',\n",
    " '0\\t3\\t-1\\t\\t0\\t2\\t0\\t3\\t0\\t0\\t1\\t1\\t\\t0\\t8cf07265\\tae46a29d\\tc81688bb\\tf922efad\\t25c83c98\\t13718bbd\\tad9fa255\\t0b153874\\ta73ee510\\t5282c137\\te5d8af57\\t66a76a26\\tf06c53ac\\t1adce6ef\\t8ff4b403\\t01adbab4\\t1e88c74f\\t26b3c7a7\\t\\t\\t21c9516a\\t\\t32c7478e\\tb34f3128\\t\\t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "app_name = \"hw5_notebook\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdd = sc.parallelize(fifty_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0\\t1\\t1\\t5\\t0\\t1382\\t4\\t15\\t2\\t181\\t1\\t2\\t\\t2\\t68fd1e64\\t80e26c9b\\tfb936136\\t7b4723c4\\t25c83c98\\t7e0ccccf\\tde7995b8\\t1f89b562\\ta73ee510\\ta8cd5504\\tb2cb9c98\\t37c9c164\\t2824a5f6\\t1adce6ef\\t8ba8b39a\\t891b62e7\\te5ba7672\\tf54016b9\\t21ddcdc9\\tb1252a9d\\t07b5194c\\t\\t3a171ecb\\tc5c50484\\te8b83407\\t9727dd16',\n",
       " '0\\t2\\t0\\t44\\t1\\t102\\t8\\t2\\t2\\t4\\t1\\t1\\t\\t4\\t68fd1e64\\tf0cf0024\\t6f67f7e5\\t41274cd7\\t25c83c98\\tfe6b92e5\\t922afcc0\\t0b153874\\ta73ee510\\t2b53e5fb\\t4f1b46f3\\t623049e6\\td7020589\\tb28479f6\\te6c5b5cd\\tc92f3b61\\t07c540c4\\tb04e4670\\t21ddcdc9\\t5840adea\\t60f6221e\\t\\t3a171ecb\\t43f13e8b\\te8b83407\\t731c3655',\n",
       " '0\\t2\\t0\\t1\\t14\\t767\\t89\\t4\\t2\\t245\\t1\\t3\\t3\\t45\\t287e684f\\t0a519c5c\\t02cf9876\\tc18be181\\t25c83c98\\t7e0ccccf\\tc78204a1\\t0b153874\\ta73ee510\\t3b08e48b\\t5f5e6091\\t8fe001f4\\taa655a2f\\t07d13a8f\\t6dc710ed\\t36103458\\t8efede7f\\t3412118d\\t\\t\\te587c466\\tad3062eb\\t3a171ecb\\t3b183c5c\\t\\t',\n",
       " '0\\t\\t893\\t\\t\\t4392\\t\\t0\\t0\\t0\\t\\t0\\t\\t\\t68fd1e64\\t2c16a946\\ta9a87e68\\t2e17d6f6\\t25c83c98\\tfe6b92e5\\t2e8a689b\\t0b153874\\ta73ee510\\tefea433b\\te51ddf94\\ta30567ca\\t3516f6e6\\t07d13a8f\\t18231224\\t52b8680f\\t1e88c74f\\t74ef3502\\t\\t\\t6b3a5ca6\\t\\t3a171ecb\\t9117a34a\\t\\t',\n",
       " '0\\t3\\t-1\\t\\t0\\t2\\t0\\t3\\t0\\t0\\t1\\t1\\t\\t0\\t8cf07265\\tae46a29d\\tc81688bb\\tf922efad\\t25c83c98\\t13718bbd\\tad9fa255\\t0b153874\\ta73ee510\\t5282c137\\te5d8af57\\t66a76a26\\tf06c53ac\\t1adce6ef\\t8ff4b403\\t01adbab4\\t1e88c74f\\t26b3c7a7\\t\\t\\t21c9516a\\t\\t32c7478e\\tb34f3128\\t\\t']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0\\t1\\t1\\t5\\t0\\t1382\\t4\\t15\\t2\\t181\\t1\\t2\\t\\t2\\t68fd1e64\\t80e26c9b\\tfb936136\\t7b4723c4\\t25c83c98\\t7e0ccccf\\tde7995b8\\t1f89b562\\ta73ee510\\ta8cd5504\\tb2cb9c98\\t37c9c164\\t2824a5f6\\t1adce6ef\\t8ba8b39a\\t891b62e7\\te5ba7672\\tf54016b9\\t21ddcdc9\\tb1252a9d\\t07b5194c\\t\\t3a171ecb\\tc5c50484\\te8b83407\\t9727dd16']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0\\t1\\t1\\t5\\t0\\t1382\\t4\\t15\\t2\\t181\\t1\\t2\\t\\t2\\t68fd1e64\\t80e26c9b\\tfb936136\\t7b4723c4\\t25c83c98\\t7e0ccccf\\tde7995b8\\t1f89b562\\ta73ee510\\ta8cd5504\\tb2cb9c98\\t37c9c164\\t2824a5f6\\t1adce6ef\\t8ba8b39a\\t891b62e7\\te5ba7672\\tf54016b9\\t21ddcdc9\\tb1252a9d\\t07b5194c\\t\\t3a171ecb\\tc5c50484\\te8b83407\\t9727dd16',\n",
       " '0\\t2\\t0\\t44\\t1\\t102\\t8\\t2\\t2\\t4\\t1\\t1\\t\\t4\\t68fd1e64\\tf0cf0024\\t6f67f7e5\\t41274cd7\\t25c83c98\\tfe6b92e5\\t922afcc0\\t0b153874\\ta73ee510\\t2b53e5fb\\t4f1b46f3\\t623049e6\\td7020589\\tb28479f6\\te6c5b5cd\\tc92f3b61\\t07c540c4\\tb04e4670\\t21ddcdc9\\t5840adea\\t60f6221e\\t\\t3a171ecb\\t43f13e8b\\te8b83407\\t731c3655']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_dict = {\n",
    "   \"Andrew\" : [1, 4, 8, 2.9, 1, \"Computer Science\", \"History\"],\n",
    "   \"Vikram\" : [0, 3, 9, 3.5, 0, \"Math\", \"French\"],\n",
    "   \"Samantha\" : [0, 2, 9, 3.4, 1, \"Math\", \"Computer Science\"],\n",
    "   \"Chris\" : [0, 2, 8, 3.7, 0, \"Data Science\", \"English\"],\n",
    "   \"Brenda\" : [0, 3, 7, 3.9, 0, \"Data Science\", \"Math\"],\n",
    "   \"Doug\" : [1, 3, 7, 3.2, 0, \"English\", \"Data Science\"],\n",
    "   \"Maria\" : [1, 4, 8, 2.9, 1, \"Computer Science\", \"History\"],\n",
    "   \"Tony\" : [0, 2, 7, 2.8, 1, \"Data Science\", \"French\"],\n",
    "   \"Tonya\" : [1, 4, 9, 3.7, 0, \"Computer Science\", \"German\"],\n",
    "   \"Ruth\" : [0, 3, 6, 3.1, 1, \"Astrophysics\", \"Math\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,4,8,2.9,1,Computer Science,History\n",
      "0,3,9,3.5,0,Math,French\n",
      "0,2,9,3.4,1,Math,Computer Science\n",
      "0,2,8,3.7,0,Data Science,English\n",
      "0,3,7,3.9,0,Data Science,Math\n",
      "1,3,7,3.2,0,English,Data Science\n",
      "1,4,8,2.9,1,Computer Science,History\n",
      "0,2,7,2.8,1,Data Science,French\n",
      "1,4,9,3.7,0,Computer Science,German\n",
      "0,3,6,3.1,1,Astrophysics,Math\n"
     ]
    }
   ],
   "source": [
    "for x in students_dict.values():\n",
    "    print(','.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyRDD = sc.parallelize(students_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyRDD1 = sc.parallelize([ ','.join(map(str, x)) for x in students_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyDF = toyRDD.map(lambda x: x).toDF([\"dropout\", \"int_1\", \"int_2\", \"int_3\", \"int_4\", \"categ_1\", \"categ_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyDF = toyDF.withColumn(\"int_1\", toyDF[\"int_1\"].cast(types.IntegerType()))\n",
    "toyDF = toyDF.withColumn(\"int_2\", toyDF[\"int_2\"].cast(types.IntegerType()))\n",
    "toyDF = toyDF.withColumn(\"int_3\", toyDF[\"int_3\"].cast(types.IntegerType()))\n",
    "toyDF = toyDF.withColumn(\"int_4\", toyDF[\"int_4\"].cast(types.IntegerType()))\n",
    "toyDF = toyDF.withColumn(\"dropout\", toyDF[\"int_4\"].cast(types.IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(dropout=1, int_1=4, int_2=8, int_3=2, int_4=1, categ_1='Computer Science', categ_2='History')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Data for manual OHE\n",
    "# Note: the first data point does not include any value for the optional third feature\n",
    "sample_one = [(0, 'mouse'), (1, 'black')]\n",
    "sample_two = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
    "sample_three =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]\n",
    "\n",
    "def sample_to_row(sample):\n",
    "    tmp_dict = defaultdict(lambda: None)\n",
    "    tmp_dict.update(sample)\n",
    "    return [tmp_dict[i] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-----+-----+----------------+----------------+\n",
      "|dropout|int_1|int_2|int_3|int_4|         categ_1|         categ_2|\n",
      "+-------+-----+-----+-----+-----+----------------+----------------+\n",
      "|      1|    4|    8|    2|    1|Computer Science|         History|\n",
      "|      0|    3|    9|    3|    0|            Math|          French|\n",
      "|      1|    2|    9|    3|    1|            Math|Computer Science|\n",
      "|      0|    2|    8|    3|    0|    Data Science|         English|\n",
      "|      0|    3|    7|    3|    0|    Data Science|            Math|\n",
      "|      0|    3|    7|    3|    0|         English|    Data Science|\n",
      "|      1|    4|    8|    2|    1|Computer Science|         History|\n",
      "|      1|    2|    7|    2|    1|    Data Science|          French|\n",
      "|      0|    4|    9|    3|    0|Computer Science|          German|\n",
      "|      1|    3|    6|    3|    1|    Astrophysics|            Math|\n",
      "+-------+-----+-----+-----+-----+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toyDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing toy.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile toy.txt\n",
    "1,4,8,2.9,1,Computer Science,History\n",
    "0,3,9,3.5,0,Math,French\n",
    "0,2,9,3.4,1,Math,Computer Science\n",
    "0,2,8,3.7,0,Data Science,English\n",
    "0,3,7,3.9,0,Data Science,Math\n",
    "1,3,7,3.2,0,English,Data Science\n",
    "1,4,8,2.9,1,Computer Science,History\n",
    "0,2,7,2.8,1,Data Science,French\n",
    "1,4,9,3.7,0,Computer Science,German\n",
    "0,3,6,3.1,1,Astrophysics,Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mouse', 'black', None, None]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_to_row(sample_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c02fe212f885>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoyDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"categ_1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "toyDF[\"categ_1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can not infer schema for type: <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-d84b8e77c204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoyRDD1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/context.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mPy4JJavaError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \"\"\"\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverifySchema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/session.py\u001b[0m in \u001b[0;36mcreateDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromRDD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_createFromLocal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_createFromRDD\u001b[0;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \"\"\"\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamplingRatio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mrdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_inferSchema\u001b[0;34m(self, rdd, samplingRatio, names)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msamplingRatio\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_has_nulltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pyspark-2.3.1-py3.6.egg/pyspark/sql/types.py\u001b[0m in \u001b[0;36m_infer_schema\u001b[0;34m(row, names)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can not infer schema for type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_infer_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can not infer schema for type: <class 'str'>"
     ]
    }
   ],
   "source": [
    "raw_df = sqlContext.createDataFrame(toyRDD1).withColumnRenamed(\"value\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+----------------+----------------+\n",
      "| _1| _2| _3| _4| _5|              _6|              _7|\n",
      "+---+---+---+---+---+----------------+----------------+\n",
      "|  1|  4|  8|2.9|  1|Computer Science|         History|\n",
      "|  0|  3|  9|3.5|  0|            Math|          French|\n",
      "|  0|  2|  9|3.4|  1|            Math|Computer Science|\n",
      "|  0|  2|  8|3.7|  0|    Data Science|         English|\n",
      "|  0|  3|  7|3.9|  0|    Data Science|            Math|\n",
      "|  1|  3|  7|3.2|  0|         English|    Data Science|\n",
      "|  1|  4|  8|2.9|  1|Computer Science|         History|\n",
      "|  0|  2|  7|2.8|  1|    Data Science|          French|\n",
      "|  1|  4|  9|3.7|  0|Computer Science|          German|\n",
      "|  0|  3|  6|3.1|  1|    Astrophysics|            Math|\n",
      "+---+---+---+---+---+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1,4,8,2.9,1,Computer Science,History',\n",
       " '0,3,9,3.5,0,Math,French',\n",
       " '0,2,9,3.4,1,Math,Computer Science',\n",
       " '0,2,8,3.7,0,Data Science,English',\n",
       " '0,3,7,3.9,0,Data Science,Math',\n",
       " '1,3,7,3.2,0,English,Data Science',\n",
       " '1,4,8,2.9,1,Computer Science,History',\n",
       " '0,2,7,2.8,1,Data Science,French',\n",
       " '1,4,9,3.7,0,Computer Science,German',\n",
       " '0,3,6,3.1,1,Astrophysics,Math']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyRDD1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(students_dict.values()), columns=[\"dropout\", \"int_1\", \"int_2\", \"int_3\", \"int_4\", \"categ_1\", \"categ_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>int_1</th>\n",
       "      <th>int_2</th>\n",
       "      <th>int_3</th>\n",
       "      <th>int_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.516398</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>1.032796</td>\n",
       "      <td>0.387155</td>\n",
       "      <td>0.527046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.950000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dropout      int_1      int_2      int_3      int_4\n",
       "count  10.000000  10.000000  10.000000  10.000000  10.000000\n",
       "mean    0.400000   3.000000   7.800000   3.310000   0.500000\n",
       "std     0.516398   0.816497   1.032796   0.387155   0.527046\n",
       "min     0.000000   2.000000   6.000000   2.800000   0.000000\n",
       "25%     0.000000   2.250000   7.000000   2.950000   0.000000\n",
       "50%     0.000000   3.000000   8.000000   3.300000   0.500000\n",
       "75%     1.000000   3.750000   8.750000   3.650000   1.000000\n",
       "max     1.000000   4.000000   9.000000   3.900000   1.000000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>int_1</th>\n",
       "      <th>int_2</th>\n",
       "      <th>int_3</th>\n",
       "      <th>int_4</th>\n",
       "      <th>categ_1</th>\n",
       "      <th>categ_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>Math</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>Math</td>\n",
       "      <td>Computer Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>English</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>German</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>Astrophysics</td>\n",
       "      <td>Math</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  int_1  int_2  int_3  int_4           categ_1           categ_2\n",
       "0        1      4      8    2.9      1  Computer Science           History\n",
       "1        0      3      9    3.5      0              Math            French\n",
       "2        0      2      9    3.4      1              Math  Computer Science\n",
       "3        0      2      8    3.7      0      Data Science           English\n",
       "4        0      3      7    3.9      0      Data Science              Math\n",
       "5        1      3      7    3.2      0           English      Data Science\n",
       "6        1      4      8    2.9      1  Computer Science           History\n",
       "7        0      2      7    2.8      1      Data Science            French\n",
       "8        1      4      9    3.7      0  Computer Science            German\n",
       "9        0      3      6    3.1      1      Astrophysics              Math"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer Science', 'Math', 'Data Science', 'English', 'Astrophysics']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df['categ_1'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      "dropout    10 non-null int64\n",
      "int_1      10 non-null int64\n",
      "int_2      10 non-null int64\n",
      "int_3      10 non-null float64\n",
      "int_4      10 non-null int64\n",
      "categ_1    10 non-null object\n",
      "categ_2    10 non-null object\n",
      "dtypes: float64(1), int64(4), object(2)\n",
      "memory usage: 640.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['categ_1'] = pd.Categorical(df['categ_1'], categories = list(df['categ_1'].unique())+['unk'])\n",
    "df['categ_2'] = pd.Categorical(df['categ_2'], categories = list(df['categ_2'].unique())+['unk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['categ_1', 'categ_2'], prefix = ['categ_1', 'categ_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>int_1</th>\n",
       "      <th>int_2</th>\n",
       "      <th>int_3</th>\n",
       "      <th>int_4</th>\n",
       "      <th>categ_1_Computer Science</th>\n",
       "      <th>categ_1_Math</th>\n",
       "      <th>categ_1_Data Science</th>\n",
       "      <th>categ_1_English</th>\n",
       "      <th>categ_1_Astrophysics</th>\n",
       "      <th>categ_1_unk</th>\n",
       "      <th>categ_2_History</th>\n",
       "      <th>categ_2_French</th>\n",
       "      <th>categ_2_Computer Science</th>\n",
       "      <th>categ_2_English</th>\n",
       "      <th>categ_2_Math</th>\n",
       "      <th>categ_2_Data Science</th>\n",
       "      <th>categ_2_German</th>\n",
       "      <th>categ_2_unk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout  int_1  int_2  int_3  int_4  categ_1_Computer Science  \\\n",
       "0        1      4      8    2.9      1                         1   \n",
       "1        0      3      9    3.5      0                         0   \n",
       "2        0      2      9    3.4      1                         0   \n",
       "3        0      2      8    3.7      0                         0   \n",
       "4        0      3      7    3.9      0                         0   \n",
       "5        1      3      7    3.2      0                         0   \n",
       "6        1      4      8    2.9      1                         1   \n",
       "7        0      2      7    2.8      1                         0   \n",
       "8        1      4      9    3.7      0                         1   \n",
       "9        0      3      6    3.1      1                         0   \n",
       "\n",
       "   categ_1_Math  categ_1_Data Science  categ_1_English  categ_1_Astrophysics  \\\n",
       "0             0                     0                0                     0   \n",
       "1             1                     0                0                     0   \n",
       "2             1                     0                0                     0   \n",
       "3             0                     1                0                     0   \n",
       "4             0                     1                0                     0   \n",
       "5             0                     0                1                     0   \n",
       "6             0                     0                0                     0   \n",
       "7             0                     1                0                     0   \n",
       "8             0                     0                0                     0   \n",
       "9             0                     0                0                     1   \n",
       "\n",
       "   categ_1_unk  categ_2_History  categ_2_French  categ_2_Computer Science  \\\n",
       "0            0                1               0                         0   \n",
       "1            0                0               1                         0   \n",
       "2            0                0               0                         1   \n",
       "3            0                0               0                         0   \n",
       "4            0                0               0                         0   \n",
       "5            0                0               0                         0   \n",
       "6            0                1               0                         0   \n",
       "7            0                0               1                         0   \n",
       "8            0                0               0                         0   \n",
       "9            0                0               0                         0   \n",
       "\n",
       "   categ_2_English  categ_2_Math  categ_2_Data Science  categ_2_German  \\\n",
       "0                0             0                     0               0   \n",
       "1                0             0                     0               0   \n",
       "2                0             0                     0               0   \n",
       "3                1             0                     0               0   \n",
       "4                0             1                     0               0   \n",
       "5                0             0                     1               0   \n",
       "6                0             0                     0               0   \n",
       "7                0             0                     0               0   \n",
       "8                0             0                     0               1   \n",
       "9                0             1                     0               0   \n",
       "\n",
       "   categ_2_unk  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "5            0  \n",
       "6            0  \n",
       "7            0  \n",
       "8            0  \n",
       "9            0  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "toySPDF = sqlContext.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-----+-----+------------------------+------------+--------------------+---------------+--------------------+-----------+---------------+--------------+------------------------+---------------+------------+--------------------+--------------+-----------+\n",
      "|dropout|int_1|int_2|int_3|int_4|categ_1_Computer Science|categ_1_Math|categ_1_Data Science|categ_1_English|categ_1_Astrophysics|categ_1_unk|categ_2_History|categ_2_French|categ_2_Computer Science|categ_2_English|categ_2_Math|categ_2_Data Science|categ_2_German|categ_2_unk|\n",
      "+-------+-----+-----+-----+-----+------------------------+------------+--------------------+---------------+--------------------+-----------+---------------+--------------+------------------------+---------------+------------+--------------------+--------------+-----------+\n",
      "|      1|    4|    8|  2.9|    1|                       1|           0|                   0|              0|                   0|          0|              1|             0|                       0|              0|           0|                   0|             0|          0|\n",
      "|      0|    3|    9|  3.5|    0|                       0|           1|                   0|              0|                   0|          0|              0|             1|                       0|              0|           0|                   0|             0|          0|\n",
      "|      0|    2|    9|  3.4|    1|                       0|           1|                   0|              0|                   0|          0|              0|             0|                       1|              0|           0|                   0|             0|          0|\n",
      "|      0|    2|    8|  3.7|    0|                       0|           0|                   1|              0|                   0|          0|              0|             0|                       0|              1|           0|                   0|             0|          0|\n",
      "|      0|    3|    7|  3.9|    0|                       0|           0|                   1|              0|                   0|          0|              0|             0|                       0|              0|           1|                   0|             0|          0|\n",
      "|      1|    3|    7|  3.2|    0|                       0|           0|                   0|              1|                   0|          0|              0|             0|                       0|              0|           0|                   1|             0|          0|\n",
      "|      1|    4|    8|  2.9|    1|                       1|           0|                   0|              0|                   0|          0|              1|             0|                       0|              0|           0|                   0|             0|          0|\n",
      "|      0|    2|    7|  2.8|    1|                       0|           0|                   1|              0|                   0|          0|              0|             1|                       0|              0|           0|                   0|             0|          0|\n",
      "|      1|    4|    9|  3.7|    0|                       1|           0|                   0|              0|                   0|          0|              0|             0|                       0|              0|           0|                   0|             1|          0|\n",
      "|      0|    3|    6|  3.1|    1|                       0|           0|                   0|              0|                   1|          0|              0|             0|                       0|              0|           1|                   0|             0|          0|\n",
      "+-------+-----+-----+-----+-----+------------------------+------------+--------------------+---------------+--------------------+-----------+---------------+--------------+------------------------+---------------+------------+--------------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toySPDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_rawDF = sqlContext.read.text('toy.txt').withColumnRenamed(\"value\", \"text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|1,4,8,2.9,1,Compu...|\n",
      "|0,3,9,3.5,0,Math,...|\n",
      "|0,2,9,3.4,1,Math,...|\n",
      "|0,2,8,3.7,0,Data ...|\n",
      "|0,3,7,3.9,0,Data ...|\n",
      "|1,3,7,3.2,0,Engli...|\n",
      "|1,4,8,2.9,1,Compu...|\n",
      "|0,2,7,2.8,1,Data ...|\n",
      "|1,4,9,3.7,0,Compu...|\n",
      "|0,3,6,3.1,1,Astro...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toy_rawDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 2 1 10\n"
     ]
    }
   ],
   "source": [
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "# Use randomSplit with weights and seed\n",
    "raw_train_df, raw_validation_df, raw_test_df = toy_rawDF.randomSplit(weights, seed)\n",
    "\n",
    "# Cache and count the DataFrames\n",
    "n_train = raw_train_df.cache().count()\n",
    "n_val = raw_validation_df.cache().count()\n",
    "n_test = raw_test_df.cache().count()\n",
    "print(n_train, n_val, n_test, str(n_train + n_val + n_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '4'), (1, '8'), (2, '2.9'), (3, '1'), (4, 'Computer Science'), (5, 'History')]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def parse_point(point):\n",
    "    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n",
    "\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    values = point.split(',')[1:]\n",
    "    #values = filter(None, values)\n",
    "    indices = range(len(values))\n",
    "    return zip(indices,values)\n",
    "\n",
    "print(list(parse_point(toy_rawDF.select('text').first()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1,4,8,2.9,1,Computer Science,History'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_rawDF.select('text').first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7f5aaf792d48>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_point(toy_rawDF.select('text').first()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, split\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField, LongType, StringType\n",
    "\n",
    "\n",
    "parse_point_udf = udf(parse_point, ArrayType(StructType([StructField('_1', LongType()),StructField('_2', StringType())])))\n",
    "\n",
    "def parse_raw_df(raw_df):\n",
    "    \"\"\"Convert a DataFrame consisting of rows of comma separated text into labels and feature.\n",
    "\n",
    "\n",
    "    Args:\n",
    "        raw_df (DataFrame with a 'text' column): DataFrame containing the raw comma separated data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with 'label' and 'feature' columns.   \n",
    "  \n",
    "    \"\"\"\n",
    "    return (raw_df.select(split(raw_df.text,',').getItem(0).cast(\"double\").alias('label'),\n",
    "                         parse_point_udf(raw_df.text).alias('features'))\n",
    "                        .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(label=0.0, features=[Row(_1=0, _2='2'), Row(_1=1, _2='7'), Row(_1=2, _2='2.8'), Row(_1=3, _2='1'), Row(_1=4, _2='Data Science'), Row(_1=5, _2='French')])\n"
     ]
    }
   ],
   "source": [
    "parsed_train_df = parse_raw_df(raw_train_df)\n",
    "print(parsed_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import (explode, col)\n",
    "num_categories = (parsed_train_df\n",
    "                    .select(explode('features').alias('features'))\n",
    "                    .distinct()\n",
    "                    .select(col('features').getField('_1').alias('featureNumber'))\n",
    "                    .groupBy('featureNumber')\n",
    "                    .sum()\n",
    "                    .orderBy('featureNumber')\n",
    "                    .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(featureNumber=0, sum(featureNumber)=0), Row(featureNumber=1, sum(featureNumber)=3), Row(featureNumber=2, sum(featureNumber)=12), Row(featureNumber=3, sum(featureNumber)=6), Row(featureNumber=4, sum(featureNumber)=16), Row(featureNumber=5, sum(featureNumber)=25)]\n"
     ]
    }
   ],
   "source": [
    "print(num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseVector\n",
    "def one_hot_encoding(raw_feats, ohe_dict_broadcast, num_ohe_feats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "\n",
    "    Note:\n",
    "        You should ensure that the indices used to create a SparseVector are sorted.\n",
    "\n",
    "    Args:\n",
    "        raw_feats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sample_one)\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "        num_ohe_feats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length num_ohe_feats with indices equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    indices = sorted([ohe_dict_broadcast.value[feat] for feat in raw_feats])\n",
    "    values = np.ones(len(raw_feats))\n",
    "    return SparseVector(num_ohe_feats,indices,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.mllib.linalg import VectorUDT\n",
    "\n",
    "def ohe_udf_generator(ohe_dict_broadcast):\n",
    "    \"\"\"Generate a UDF that is setup to one-hot-encode rows with the given dictionary.\n",
    "\n",
    "    Note:\n",
    "        We'll reuse this function to generate a UDF that can one-hot-encode rows based on a\n",
    "        one-hot-encoding dictionary built from the training data.  Also, you should calculate\n",
    "        the number of features before calling the one_hot_encoding function.\n",
    "\n",
    "    Args:\n",
    "        ohe_dict_broadcast (Broadcast of dict): Broadcast variable containing a dict that maps\n",
    "            (featureID, value) to unique integer.\n",
    "\n",
    "    Returns:\n",
    "        UserDefinedFunction: A UDF can be used in `DataFrame` `select` statement to call a\n",
    "            function on each row in a given column.  This UDF should call the one_hot_encoding\n",
    "            function with the appropriate parameters.\n",
    "    \"\"\"\n",
    "    length = len(ohe_dict_broadcast.value)\n",
    "    return udf(lambda x: one_hot_encoding(x, ohe_dict_broadcast, length), VectorUDT())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "def create_one_hot_dict(input_df):\n",
    "    \"\"\"Creates a one-hot-encoder dictionary based on the input data.\n",
    "\n",
    "    Args:\n",
    "        input_df (DataFrame with 'features' column): A DataFrame where each row contains a list of\n",
    "            (featureID, value) tuples.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are\n",
    "            unique integers.\n",
    "    \"\"\"\n",
    "    input_distinct_feats_df = input_df.select(explode(input_df.features)).distinct()\n",
    "    input_ohe_dict = (input_distinct_feats_df\n",
    "                     .rdd\n",
    "                     .map(lambda r: tuple(r[0]))\n",
    "                     .zipWithIndex().collectAsMap())\n",
    "    return input_ohe_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(1, '9'): 0,\n",
       " (3, '1'): 1,\n",
       " (4, 'Math'): 2,\n",
       " (4, 'Data Science'): 3,\n",
       " (5, 'History'): 4,\n",
       " (0, '4'): 5,\n",
       " (2, '3.9'): 6,\n",
       " (5, 'Data Science'): 7,\n",
       " (5, 'French'): 8,\n",
       " (2, '3.5'): 9,\n",
       " (3, '0'): 10,\n",
       " (2, '2.9'): 11,\n",
       " (0, '3'): 12,\n",
       " (5, 'German'): 13,\n",
       " (5, 'Math'): 14,\n",
       " (1, '7'): 15,\n",
       " (1, '8'): 16,\n",
       " (4, 'English'): 17,\n",
       " (4, 'Computer Science'): 18,\n",
       " (2, '2.8'): 19,\n",
       " (2, '3.7'): 20,\n",
       " (2, '3.2'): 21,\n",
       " (0, '2'): 22}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr_ohe_dict = create_one_hot_dict(parsed_train_df)\n",
    "num_ctr_ohe_feats = len(ctr_ohe_dict)\n",
    "print(num_ctr_ohe_feats)\n",
    "ctr_ohe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(23,[1,3,8,15,19,...|\n",
      "|  0.0|(23,[3,6,10,12,14...|\n",
      "|  0.0|(23,[0,2,8,9,10,1...|\n",
      "|  1.0|(23,[7,10,12,15,1...|\n",
      "|  1.0|(23,[1,4,5,11,16,...|\n",
      "|  1.0|(23,[1,4,5,11,16,...|\n",
      "|  1.0|(23,[0,5,10,13,18...|\n",
      "+-----+--------------------+\n",
      "\n",
      "None\n",
      "[Row(label=0.0, features=SparseVector(23, {1: 1.0, 3: 1.0, 8: 1.0, 15: 1.0, 19: 1.0, 22: 1.0}))]\n"
     ]
    }
   ],
   "source": [
    "ohe_dict_broadcast = sc.broadcast(ctr_ohe_dict)\n",
    "ohe_dict_udf =  ohe_udf_generator(ohe_dict_broadcast)\n",
    "ohe_train_df =  parsed_train_df.select(parsed_train_df.label, ohe_dict_udf(parsed_train_df.features).alias('features'))\n",
    "#ohe_train_df.show(1)                  \n",
    "\n",
    "print(ohe_train_df.count())\n",
    "print(ohe_train_df.show())\n",
    "print(ohe_train_df.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
